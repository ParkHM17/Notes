1:缺图目录，表目录，缩写目录，建议修改论文。
回复：在最新版的学位论文模板中关于图、表、缩略词目录的批注为：“均并非必要。”为了方便排版，故未加图、表、缩略词目录。

Q2:论文第三章3.1-3.4小节都是介绍性的内容，建议精简，同时增加一个章节内容，说明车载环境下语音对话的特点特征，结合这些特点，选用了数据集，建议修改论文。
回复：相关内容已精简。在节3.5开头，补充了关于为何选取这两个数据集的说明，同时增加关于后续章节对于车载环境下的专用驾驶数据集收集的说明。

Q3:论文第4章也存在类似问题，此类方法是针对在车载场景下那种情况下的语音对话特征特点进行数据集选取，对话内容选取的，在此部分中增加一些内容进行补充说明一下。
回复：和上一问题一样，相关内容已精简，关于数据集选取的说明已补充。

Q4:第5章在车载设备上的测试，建议最后算法分析，给出对比图表，关键对标指标，这样更具说服力和效果，建议修改论文。
回复：在节5.5.2增加了实车测试内容，包括测试界面和测试用例等，同时针对一些关键指标（通过率和响应时间）和近年文献作了比较。

1.文章3.4节和4.2节中，提到了砖石型缩放单元和标签映射模块，但没有充分说明这些方法提出的技术背景信息和动机，为什么要使用砖石型缩放单元和标签映射模块？它们与现有方法有什么区别？
回复：在第3章开头和节3.3.2补充了“钻石”型缩放单元所提出的背景、特征及对该方法在ASR上的改进；同样地，在第4章开头、节4.2和节4.3补充了标签映射模块和全局图交互模块所提出的背景和特征。

2.文章3.4节中，文章在构建轻量化的Transformer模型时，将原Transformer的前馈网络层换为轻量级的前馈网络层，它主要是通过改变全连接层的输出通道数降低参数运算，这样的替换是否有精度损失？相对于原通道数扩张的做法在这样改进是否可以达到精度与参数量的平衡？
回复：在节3.4.1补充了轻量级前馈网络层提出的动机和前提，同时在节3.5.5增加了关于前馈网络层类型的消融实验，实验结果表明该做法可以达到精度与参数量的平衡。

3.文章提出了两种轻量级的神经网络模型，分别用于自动语音识别和自然语言理解，并在多个数据集上对提出的模型进行了广泛的实验评估，并给出了详细的结果和分析但文章都是基于原大模型的框架进行对比，没有与现有的轻量化模型或者其他的适合嵌入式部署的模型进行比较，缺乏说服力。
回复：在节3.5.4增加两种轻量级同类模型，即SSAN和HA-Transformer作为对照组，实验结果结果表明针对自动语音识别的改进模型有较好的效果；而针对自然语言理解模型，由于所搭建模型的方法不同，当前研究难点不在于模型参数量而在于预测性能，在节4.5.4展现了详细的对比结果。

4.文章5.4节，对模型进行移植时，没有介绍Jetson TX2的软件环境版本信息，例如CUDA版本等，同时是否采用了其支持的硬件加速框架TensorRT？是否是在PyTorch框架下部署移植的？建议可以给出两种框架在Jetson TX2的对比结果。还有是否考虑输入音源时的存在的噪音问题？
回复：在节5.2补充了关于TX2刷机后的运行环境版本介绍，包括Python版本、PyTorch版本和CUDA版本等；系统运行未使用TensorRT框架，理由有以下三点：首先在尝试将自然语言理解模型运行在TensorRT框架下时，该模块的运行时间仅提高了10ms左右，在实际应用中并不明显；其次若要部署在TensorRT框架下，需要将.pt模型（PyTorch框架下）转换为ONXX通用模型，这一过程会使得模型参数量变大，以尝试的自然语言理解模型为例，.pt模型参数量为2.46M，转换后为52.17M，可能是由于ONXX中有大量重复的算子，这与论文的轻量级需求稍有偏差；最后由于TensorRT是半开源的，只含有一些经典网络模型的文档资料，而论文中涉及到的网络模型类型较多，在开发上难度较大。