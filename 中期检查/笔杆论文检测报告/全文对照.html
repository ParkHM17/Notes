<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<title>笔杆检测报告单（全文对照）</title>
	<meta name="keywords" content="" />
	<meta name="description" content="" />
    <meta content="0" http-equiv="Expires"/>
    <meta content="no-cache" http-equiv="Pragma"/>
    <meta content="no-cache" http-equiv="Cache-Control"/>
    <meta content="no-cache" http-equiv="Cache"/>
	<link href="css/report.css?v20180524" type="text/css" rel="stylesheet" />
	<script src="js/jquery.tools.pack.js" type="text/javascript"></script>
	<script type="text/javascript">
    function $ShowMore(n) {
        if ($("#simMore_" + n + " a").text() == '收起相似文献') {//收起
            $("#reportTable_" + n + " .trLike").hide();
            for (var i = 0; i < 5; i++) {
                $("#reportTable_" + n + " .trLike:eq("+i+")").show();
            }
            $("#simMore_" + n + " a").html('查看更多相似文献<span class="icons inlineBlock simDown"></span>');
        } else {
            $("#reportTable_" + n + " .trLike").show();
            $("#simMore_" + n + " a").html('收起相似文献<span class="icons inlineBlock simUp"></span>');
        }
}</script>
<style>
    em.similar{color:Red; font-style:normal;}
</style>
</head>
<body>
<div class="report_bg2">
  <div class="report_bg3">
    <div class="report_top">
      
      <h1>笔杆检测报告单<span>（全文对照）</span></h1>
    </div>
    <div class="report_Wrap">
      <div class="report_tab" id="report_tab">
      	<ul>
                                            <li><div><a href="全文标明引文.html" class="green">全文标明引文</a></div></li>
                                            <li class="rep_curr"><div><a href="全文对照" class="green">全文对照</a></div></li>
        </ul>
      	<div class="report_priSav">
          <a href="javascript:window.print();" class="print inlineBlock"><span class="icons inlineBlock"></span>打印</a>
          <a target="_blank" href="https://www.bigan.net/report/explain.html" class="report_explain inlineBlock"><span class="icons inlineBlock"></span>检测说明</a>
        </div>
      </div>
      <div class="report_content">
        <div class="report_main">
          <a id="toTop" title="回到顶部"></a><!-- 回到顶部 -->
          <script>
              $(document).ready(function () {
                  $("#toTop").hide();
                  //检测屏幕高度
                  var height = $(window).height();
                  //scroll() 方法为滚动事件
                  $(window).scroll(function () {
                      if ($(window).scrollTop() > height) {
                          $("#toTop").fadeIn(500);
                      } else {
                          $("#toTop").fadeOut(500);
                      }
                  });
                  $("#toTop").click(function () {
                      $('body,html').animate({ scrollTop: 0 }, 100);
                      return false;
                  });
              });
          </script>
           <div class="report_Mtop"></div>
          <div class="report_Mbot">
            <div class="report_result">
              <div class="report_info">
                <p><span>标题：</span>查重版.pdf</p>
                <p><span>作者：</span>黄子恒</p>
                <p><span>报告编号：</span>BG202303131111268318</p>
                <p><span>提交时间：</span>2023-03-13 11:31:40</p>
              </div>
              <div class="report_ratio">
                <ul>
                  <li style="display:none;"><span class="icons ratioIcon ratio1"></span>总复制比：<span class="green">19.4%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio2"></span>去除引用文献复制比：<span class="green">18.6%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio3"></span>去除本人已发表文献复制比：<span class="green">19.4%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio4"></span>单篇最大文字复制比：<span class="green">2.3%</span></li>
                </ul>
              </div>
               <div class="clear"></div>
              <div class="seal">
                <div class="SealArea">
                  <div class="SealBg"><img src="data:image/png;base64,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" /></div>
                  <div class="SealPercent"></div>
                </div>
              </div>
          	</div>
          	<div class="repeat_words">
          	  <div class="repWords_box1">
                <div class="repWords_row">
                  <div class="test_range"><a href="https://www.bigan.net/qa/?key=%E6%A3%80%E6%B5%8B%E8%8C%83%E5%9B%B4" target="_blank" class="green"><span class="icons inlineBlock"></span>检测范围</a></div>
                  <span>重复字数:<b class="red">9,513</b></span><span>总字数：<b>49,072</b></span> </div>
                <div class="clear"></div>
              </div>
              <div class="repWords_box2">
                <table width="960" class="reportTable">
                  <tr>
                    <th width="160">复制比部分</th>
                    <th width="*"  class="bdrNo">章</th>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:4.509%"></div>
                          <div class="perNum">4.509%</div>
                        </div>
                        <span class="wordsNum">（176）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">中英文摘要等<span>（总3,903字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:23.389%"></div>
                          <div class="perNum">23.389%</div>
                        </div>
                        <span class="wordsNum">（1,702）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第1章 绪论<span>（总7,277字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:54.606%"></div>
                          <div class="perNum">54.606%</div>
                        </div>
                        <span class="wordsNum">（735）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第2章 对话系统基础理论<span>（总1,346字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:79.807%"></div>
                          <div class="perNum">79.807%</div>
                        </div>
                        <span class="wordsNum">（992）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总1,243字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:61.49%"></div>
                          <div class="perNum">61.49%</div>
                        </div>
                        <span class="wordsNum">（586）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总953字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:29.349%"></div>
                          <div class="perNum">29.349%</div>
                        </div>
                        <span class="wordsNum">（356）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总1,213字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:60.228%"></div>
                          <div class="perNum">60.228%</div>
                        </div>
                        <span class="wordsNum">（739）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第3章 基于残差分组线性变换解码器的自动语音识别<span>（总1,227字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:54.99%"></div>
                          <div class="perNum">54.99%</div>
                        </div>
                        <span class="wordsNum">（810）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,473字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:37.862%"></div>
                          <div class="perNum">37.862%</div>
                        </div>
                        <span class="wordsNum">（340）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总898字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:48.636%"></div>
                          <div class="perNum">48.636%</div>
                        </div>
                        <span class="wordsNum">（642）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,320字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:25.912%"></div>
                          <div class="perNum">25.912%</div>
                        </div>
                        <span class="wordsNum">（341）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,316字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:36.972%"></div>
                          <div class="perNum">36.972%</div>
                        </div>
                        <span class="wordsNum">（657）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,777字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:8.494%"></div>
                          <div class="perNum">8.494%</div>
                        </div>
                        <span class="wordsNum">（159）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,872字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:3.051%"></div>
                          <div class="perNum">3.051%</div>
                        </div>
                        <span class="wordsNum">（50）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,639字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:5.729%"></div>
                          <div class="perNum">5.729%</div>
                        </div>
                        <span class="wordsNum">（99）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,728字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.345%"></div>
                          <div class="perNum">2.345%</div>
                        </div>
                        <span class="wordsNum">（31）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第4章 基于标签感知图交互的自然语言理解<span>（总1,322字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:25.335%"></div>
                          <div class="perNum">25.335%</div>
                        </div>
                        <span class="wordsNum">（227）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总896字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.993%"></div>
                          <div class="perNum">2.993%</div>
                        </div>
                        <span class="wordsNum">（29）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总969字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.625%"></div>
                          <div class="perNum">2.625%</div>
                        </div>
                        <span class="wordsNum">（32）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,219字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:7.737%"></div>
                          <div class="perNum">7.737%</div>
                        </div>
                        <span class="wordsNum">（121）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,564字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.679%"></div>
                          <div class="perNum">2.679%</div>
                        </div>
                        <span class="wordsNum">（48）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,792字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:0%"></div>
                          <div class="perNum">0%</div>
                        </div>
                        <span class="wordsNum">（0）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,608字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:4.03%"></div>
                          <div class="perNum">4.03%</div>
                        </div>
                        <span class="wordsNum">（49）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,216字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.308%"></div>
                          <div class="perNum">2.308%</div>
                        </div>
                        <span class="wordsNum">（43）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第5章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,863字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:1.397%"></div>
                          <div class="perNum">1.397%</div>
                        </div>
                        <span class="wordsNum">（20）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,432字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:1.393%"></div>
                          <div class="perNum">1.393%</div>
                        </div>
                        <span class="wordsNum">（23）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,651字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:6.155%"></div>
                          <div class="perNum">6.155%</div>
                        </div>
                        <span class="wordsNum">（93）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,511字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.056%"></div>
                          <div class="perNum">2.056%</div>
                        </div>
                        <span class="wordsNum">（22）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,070字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:22.041%"></div>
                          <div class="perNum">22.041%</div>
                        </div>
                        <span class="wordsNum">（391）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第6章 总结与展望<span>（总1,774字）</span></div></td>
                  </tr>
                </table>
              </div>
              <div class="repWords_box3">
                <div style="float: left;"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkwAAAASCAIAAAAmHRY6AAABUUlEQVR42u3VMQ7CMAwAwP6Dl/BZVn7CzCs6MzNRCamqEsdN1cB0koUgMYnrRrnpdbtfno8wlqliNkk+H+/5ukS+y3bqW15R5Ppz+6X+LGZ3Y02r83tG+tff9mHtRvjURQeKaM3mK4QjrYMRZtZbdNYcZibtDXcM33vrkNRnO39xRZGthFbr8n4eGj90nMYm9/8rP0KjYuAWvy71TD2jHvMPiyRX5fn3u3sphffGBDnIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOciOR+wC/wCDmayYYqQAAAABJRU5ErkJggg==" style="width:588px;height:18px;border:1px #19c2b9 solid;" /></div>
                <div class="percentTip"> （<span><b class="inlineBlock pert1"></b>无问题部分</span><span><b class="inlineBlock pert2"></b>复制比部分</span><span><b class="inlineBlock pert3"></b>引用部分</span>） </div>
              </div>
              </div>
              <div class="clear"></div>
              <div class="similarLiter">
                <h2 style="width:100%;text-align:center;margin-top:15px;">中英文摘要等</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_1" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=车用扁管式散热器传热耦合分析及优化" target="_blank">车用扁管式散热器传热耦合分析及优化</a></span>
                      <p>张岳 -
                        《广东工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(70字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于智能交互的车载语音系统的设计与实现" target="_blank">基于智能交互的车载语音系统的设计与实现</a></span>
                      <p>陈艳华 -
                        《北京交通大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">1.2%(46字)</span></td>
                  <td class="bdrNo">是</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="https://my.oschina.net/u/4330033/blog/4535922" target="_blank">智能手机的应用</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=上期荐读" target="_blank">上期荐读</a></span>
                      <p>None -
                        《自动化博览
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识嵌入和边界增强的嵌套命名实体识别研究" target="_blank">基于知识嵌入和边界增强的嵌套命名实体识别研究</a></span>
                      <p>廖晶晶 -
                        《西南大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于拓扑优化和深度学习的新型结构生成方法研究" target="_blank">基于拓扑优化和深度学习的新型结构生成方法研究</a></span>
                      <p>王英奇 -
                        《河南大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=电商领域女装商品知识图谱的构建及应用" target="_blank">电商领域女装商品知识图谱的构建及应用</a></span>
                      <p>黄渌澄 -
                        《华东师范大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能语音交互中的用户意图理解与反馈生成研究" target="_blank">智能语音交互中的用户意图理解与反馈生成研究</a></span>
                      <p>宁义双 -
                        《清华大学博士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_1" class="simMore"><a href="javascript:$ShowMore(1);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>车载语音交互已经成为继通讯社交、</em><em class='similar'>智能家居之后的第三大应用场景。</em>随着深度学习的发展,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>小冰、天猫精灵、小爱同学等智能语音助手的出现,人们与智能终端的交互方式正逐渐从传统的触摸屏幕转变为语音交互。在诸多的语音应用市场,<em class='similar'>汽车车载语音交互是继通讯社交、</em><em class='similar'>智能家居之后的第三大应用场景,</em>受到了各大厂商的关注和看重。但截至目前,基于智能交互的车载语音系统⁞仍处于起步和发展阶段,并未真正普及[2],其主要原因如下:⁞(1)不存在成熟的语音识别体系作为技术支撑⁞</p>
	                    <div class="textFrom">——北京交通大学硕士论文 陈艳华-《基于智能交互的车载语音系统的设计与实现》-2020 （是否引证：是）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>深度学习模型的高精度运行需消耗庞大的计算资源,</em><em class='similar'>而</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>同探讨智能工厂的应用与未来发展。⁞《边缘智能:边缘计算驱动的深度学习加速技术》⁞作为直接推动机器学习蓬勃发展的关键核心技术,深度学习已经迅⁞速成为学术界与工业界关注的焦点。<em class='similar'>然而,</em><em class='similar'>由于深度学习模型的高精度⁞需求往往会引发对计算资源的大量消耗,</em>因此将一个深度学习模型部署⁞到资源受限的移动设备面临着的巨大的挑战。本文介绍Edgent,一个基⁞于边端协同的按需加速深度学习模型推理的优化框架,通过深度学习模型⁞</p>
	                    <div class="textFrom">——自动化博览 None-《上期荐读》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>原数据中含有大量的噪声数据,数据清洗可以去除掉没有意义的、重复的文本数据。例如&quot;此用户没有填写评价。&quot;、&quot;评价方未及时做出评价,系统默认好评!&quot;等,<em class='similar'>这些脏数据没有应用价值而且会消耗大量的深度学习模型的计算资源,</em><em class='similar'>需要去重。</em>在评论文本中存在着大量复制粘贴他人评论的现象,这些重复的评论文本会影响本文的研究结果,本文根据产品_id、用户名称、评论内容组合的判断规则进行去重。</p>
	                    <div class="textFrom">——华东师范大学硕士论文 黄渌澄-《电商领域女装商品知识图谱的构建及应用》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>挥计算机的硬件优势来训练上亿数据量的机器学习模型。⁞2.3.2深度学习模型计算加速方案⁞由于深度学习模型的训练过程是对权重进行调优的过程,网络中的每个神经元的连接权重都要经过数值计算得出,<em class='similar'>导致训练深度学习模型需要消耗庞大的计算资源,</em>故本文采用 GPU 计算或 Goole Colab 云计算加速方案提升深度学习模型收敛速度。⁞(1)方案一:GPU 计算加速⁞相较于 CPU,GPU 拥有更多核心处理器与处理数据的晶体管,</p>
	                    <div class="textFrom">——河南大学硕士论文 王英奇-《基于拓扑优化和深度学习的新型结构生成方法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>CQUPT-DS,<em class='similar'>接着将上述提出的两个模型在驾驶数据集上进行了训练,</em>最后集成、</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>另外,为了研究推理时间的影响,作者使用了两个不同版本的MobileNet,即最初的MobileNetV1和最新的MobileNetV3。另外,<em class='similar'>这两个模型都在COCO数据集上进行训练。</em>⁞⁞驾驶策略的训练流程⁞在自主导航任务中,研究人员用了一个类似于&quot;条件模仿学习的命令输入变体(command-input variant of Conditional Imitation Learning)&quot;的神经网络,</p>
	                    <div class="textFrom">——网页 -《智能手机的应用》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>关键字:<em class='similar'>车载语音交互,</em><em class='similar'>自动语音识别,</em><em class='similar'>自然语言理解,</em>嵌入式设备,<em class='similar'>对话系统</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>音助手仅作为对未来世界的美好想象,存在于科幻小说或电影中。如今,随着人工智能的发展,我们正在一步一步接近这个智能语音的目标,<em class='similar'>即任务型对话系统。</em>一个完整的任务型对话系统包括5个模块:<em class='similar'>自动语音识别、</em><em class='similar'>自然语言理解、</em>对话管理、自然语言生成和语音合成。其中,自然语言理解模块可以被拆分为三个子任务:领域识别、意图识别和槽位填充。</p>
	                    <div class="textFrom">——西南大学硕士论文 廖晶晶-《基于知识嵌入和边界增强的嵌套命名实体识别研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音交互系统的使用变得越来越广泛。这些系统通常⁞支持特定领域的面向任务目标的人机语音对话,如旅游计划、预订航班以及询问⁞餐厅等。一般而言,<em class='similar'>语音交互系统集成了自动语音识别、</em><em class='similar'>自然语言理解、</em>对话建⁞模(Dialogue Modeling,DM)、信息或数据库访问、反馈生成(Feedback Generation)⁞以及文语转换(Text-To-Speech,TTS)等技术[105]。</p>
	                    <div class="textFrom">——清华大学博士论文 宁义双-《智能语音交互中的用户意图理解与反馈生成研究》-2017 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'> Due to the structure of the vehicle body and the cost of research and development,</em><em class='similar'> the </em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>(2)The simulation results of the model show that:<em class='similar'>1 due to the structure of the vehicle body and the arrangement of the front-end cooling module,</em></p>
	                    <div class="textFrom">——广东工业大学硕士论文 张岳-《车用扁管式散热器传热耦合分析及优化》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第1章 绪论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_2" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于自适应学习和多尺度前向注意力的语音识别研究" target="_blank">基于自适应学习和多尺度前向注意力的语音识别研究</a></span>
                      <p>唐海桃 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">16.5%(1,201字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于自适应学习和多尺度前向注意力的语音识别研究" target="_blank">基于自适应学习和多尺度前向注意力的语音识别研究</a></span>
                      <p>唐海桃 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">16.3%(1,189字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.3%(460字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于ERNIE的口语理解研究与应用" target="_blank">基于ERNIE的口语理解研究与应用</a></span>
                      <p>郑思露 -
                        《南京邮电大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4%(290字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="https://www.doc88.com/p%2D9069970870647.html" target="_blank">基于循环神经网络的语音识别声学建模研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(93字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=意图识别与槽位填充关键技术研究" target="_blank">意图识别与槽位填充关键技术研究</a></span>
                      <p>金朋 -
                        《哈尔滨工业大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.1%(78字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.docin.com/p%2D2286338283.html" target="_blank">基于学习算法的机器人触觉识别和语音交互的研究 - 豆...</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1%(73字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多种机器学习算法的车载语音文本分类研究" target="_blank">基于多种机器学习算法的车载语音文本分类研究</a></span>
                      <p>刘威;张森;宋冠谕;丁晓雯 -
                        《信息与电脑(理论版)
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1%(73字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="https://blog.csdn.net/yang_daxia/article/month/2018/11" target="_blank">2018年11月_yang_daxia的博客_CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(59字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.doc88.com/p%2D10259516441681.html" target="_blank">基于DA_GCN的煤矿人员行为识别方法_黄瀚</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(53字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=结合实体描述信息的跨句包关系抽取方法" target="_blank">结合实体描述信息的跨句包关系抽取方法</a></span>
                      <p>孙新;申长虹;姜景虎;崔家铭 -
                        《计算机工程
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=端到端语音识别研究综述" target="_blank">端到端语音识别研究综述</a></span>
                      <p>郭宗昱;刘博;吴可欣;李姝怡;蒋昊轩;李云洁 -
                        《科技风
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=知识驱动的个性化新闻推荐" target="_blank">知识驱动的个性化新闻推荐</a></span>
                      <p>李良才 -
                        《北方工业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://www.cinic.org.cn/xw/schj/1214598.html" target="_blank">2021年我国智能语音市场规模或达285亿元 - 市场环境 - 中国产业经济信息网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于智能交互的车载语音系统的设计与实现" target="_blank">基于智能交互的车载语音系统的设计与实现</a></span>
                      <p>陈艳华 -
                        《北京交通大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(41字)</span></td>
                  <td class="bdrNo">是</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的水下目标图像识别算法研究" target="_blank">基于深度神经网络的水下目标图像识别算法研究</a></span>
                      <p>方笑海 -
                        《杭州电子科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=脑电情感识别中多特征融合与分类研究" target="_blank">脑电情感识别中多特征融合与分类研究</a></span>
                      <p>韩小娟 -
                        《重庆邮电大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于机器视觉的大型环锻件缺陷检测系统关键技术研究" target="_blank">基于机器视觉的大型环锻件缺陷检测系统关键技术研究</a></span>
                      <p>李家富 -
                        《江苏科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于语义场景分析的文本表情分析方法研究" target="_blank">基于语义场景分析的文本表情分析方法研究</a></span>
                      <p>孙晓雨 -
                        《南京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">20.</strong> <span><a href="https://www.doc88.com/p%2D31973083020321.html" target="_blank">端到端语音识别研究综述</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">21.</strong> <span><a href="https://shunliz.gitbooks.io/machine-learning/content/dl/introduction/introduction.html" target="_blank">第二十五课：深度学习 · Machine Learning</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">22.</strong> <span><a href="http://www.doc88.com/p-0093899022985.html" target="_blank">基于石墨烯的吸波器电磁特性研究 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">23.</strong> <span><a href="http://xueshu.baidu.com/s?wd=联合对话行为识别与情感分类的多任务网络" target="_blank">联合对话行为识别与情感分类的多任务网络</a></span>
                      <p>林鸿辉;刘建华;郑智雄;胡任远;罗逸轩 -
                        《计算机工程与应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">24.</strong> <span><a href="https://www.docin.com/p%2D2351210064.html" target="_blank">基于中弧面的模具型腔高质量重构方法研究硕士研究生学位</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">25.</strong> <span><a href="http://xueshu.baidu.com/s?wd=融合语言模型的端到端语音识别算法研究" target="_blank">融合语言模型的端到端语音识别算法研究</a></span>
                      <p>吕坤儒 -
                        《吉林大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">26.</strong> <span><a href="http://www.doc88.com/p%2D05629292282798.html" target="_blank">基于视觉和肌肉系统的驾驶员转向行为建模</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">27.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Jetson TX1处理器平台的智能视频广告展示系统设计和实现" target="_blank">基于Jetson TX1处理器平台的智能视频广告展示系统设计和实现</a></span>
                      <p>陈杰华 -
                        《浙江工业大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">28.</strong> <span><a href="https://www.docin.com/p%2D2594742824.html" target="_blank">汽车行业智能驾驶系列专题报告（2021）：全球车载语音交互龙头Cerence（CRNC）</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">29.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于单字级深度神经网络的中文主观题自动评分研究" target="_blank">基于单字级深度神经网络的中文主观题自动评分研究</a></span>
                      <p>龚云 -
                        《广西师范大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">30.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法" target="_blank">基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法</a></span>
                      <p>杜文风;王英奇;王辉;赵艳男;高博青;董石麟 -
                        《建筑结构学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">31.</strong> <span><a href="http://xueshu.baidu.com/s?wd=GNSS空间服务空域性能评估及辅助增强技术研究" target="_blank">GNSS空间服务空域性能评估及辅助增强技术研究</a></span>
                      <p>荆帅 -
                        《上海交通大学博士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">32.</strong> <span><a href="http://xueshu.baidu.com/s?wd=车载蓝牙语音交互系统的设计与实现" target="_blank">车载蓝牙语音交互系统的设计与实现</a></span>
                      <p>刘伟 -
                        《西安电子科技大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_2" class="simMore"><a href="javascript:$ShowMore(2);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>语音交互作为人机通信中最自然、</em><em class='similar'>直接的交互方式,</em>具有天然的优势<em class='similar'>[1]。</em><em class='similar'>随着智能汽车的兴起,</em><em class='similar'>车载语音交互成为继通讯社交、</em><em class='similar'>智能家居之后的第三大应用场景。</em><em class='similar'>截止2020年9月,</em><em class='similar'>我国乘用车车载语音装配率为64.8%,</em><em class='similar'>预计2025年国内前装车载语音市场规模约32亿元,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>智能手机、可穿戴设备、智能家居等领域大有可为。《白皮书》显示,<em class='similar'>语音交互是智能车载的核心模块,</em>智能车载正在从后装向前装市场渗透,语音识别及交互功能前装标配搭载率从2019年的49.82%提升至63.25%,<em class='similar'>预计2025年国内前装车载语音市场规模约为32亿元。</em>中国语音产业联盟理事长、科大讯飞董事长刘庆峰认为,人类正在进入人机物万物智能互联时代,<em class='similar'>语音将成为最重要的人机交互方式。</em></p>
	                    <div class="textFrom">——网页 -《2021年我国智能语音市场规模或达285亿元 - 市场环境 - 中国产业经济信息网》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>小冰、天猫精灵、小爱同学等智能语音助手的出现,人们与智能终端的交互方式正逐渐从传统的触摸屏幕转变为语音交互。在诸多的语音应用市场,<em class='similar'>汽车车载语音交互是继通讯社交、</em><em class='similar'>智能家居之后的第三大应用场景,</em>受到了各大厂商的关注和看重。但截至目前,基于智能交互的车载语音系统⁞仍处于起步和发展阶段,并未真正普及[2],其主要原因如下:<em class='similar'>⁞(1)</em>不存在成熟的语音识别体系作为技术支撑⁞</p>
	                    <div class="textFrom">——北京交通大学硕士论文 陈艳华-《基于智能交互的车载语音系统的设计与实现》-2020 （是否引证：是）</div>
						<p class="paragraph"><strong>3.</strong>齐达魏⁞工程硕士(专业学位)⁞随着车载电子产品的应用越来越广泛,车载系统已经成为现代汽车重要的组成部分。传统的触摸和按键的人车交互方式操作繁琐,容易分散驾驶员注意力,从而影响驾驶的安全性。<em class='similar'>而语音交互作为人机通信最自然直接的交互方式,</em>只要语义表达的意思足够精确,就可以根据需求直接推送最需要的结果。本文针对驾驶场景下车载免提电话和车载蓝牙音箱的实际应用需求,结合语音合成技术和语音识别技术,</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 刘伟-《车载蓝牙语音交互系统的设计与实现》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>还未分拆Cerence上市的母公司Nuance占据全球智能语音市场份额第一,市占率为32%,谷歌紧随其后,市占率约28%,同期科大讯飞市占率约5%。2019年,<em class='similar'>中国乘用车车载语音装配率为48.8%;</em><em class='similar'>2020年1-9月,</em>装配率提升至64.8%。目前在中国区车载语音交互市场,科大讯飞市占率超过40%,Cerence市占率超过30%排名第二。BAT也已分别入局车载语音,其中百度发展更为迅速,</p>
	                    <div class="textFrom">——网页 -《汽车行业智能驾驶系列专题报告（2021）：全球车载语音交互龙头Cerence（CRNC）》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>Speech Recognition,</em><em class='similar'>ASR)</em><em class='similar'>和自然语言理解</em><em class='similar'>(Natural Language Understanding,</em><em class='similar'>NLU)</em><em class='similar'>是智能语音交互的核心技术。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>不论是从提升使用便捷性的角度,还是从增强汽车企业行业竞争力的角度,语音交互⁞都需要深入学习研究。⁞目前,<em class='similar'>语音交互的主要技术包括语音识别</em><em class='similar'>(Automatic Speech Recognition,</em><em class='similar'>ASR)、</em><em class='similar'>自然语言理解</em><em class='similar'>(Natural Language Understanding,</em><em class='similar'>NLU)、</em>自然语言生成(Natural Language Generation,NLG)以及语音合成(Text To Speech,TTS)等⁞4种[6]。语音识别是将人类的声音信号转化为相应的文本或指令;</p>
	                    <div class="textFrom">——信息与电脑(理论版) 刘威；张森；宋冠谕；丁晓雯-《基于多种机器学习算法的车载语音文本分类研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>旨在平衡机器人与未知环境相互作用时的交互力和偏差;迭代更新的轨迹趋于围绕力场的轮廓,可用于实现触觉识别。第一章绪论1.2.2机器人语音交互研究状况语音交互系统技术主要包括语音识别<em class='similar'>(automatic speech recognition,</em><em class='similar'> ASR)、</em><em class='similar'>自然语言理解</em><em class='similar'>(natural language understanding,</em><em class='similar'> NLU)、</em>会话管理(dialog management, DM)、自然语言生成(natural language generation, NLG)、语音合成(text speech,TTS),</p>
	                    <div class="textFrom">——网页 -《基于学习算法的机器人触觉识别和语音交互的研究 - 豆...》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>然而,<em class='similar'>高精度的深度学习模型需要消耗庞大的计算资源才能快速运行。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>多是集中于离线的情感识别研究,在已有的数据集中进行模型的训练[61,62]。但是在情感识别应用中,需要对用户实时上传的数据进行分析处理,<em class='similar'>并进行快速识别。</em><em class='similar'>由于深度学习模型的高精度需求往往需要大量计算,</em><em class='similar'>会引发对计算资源的大量消耗,</em>因此基于深度学习的情感识别模型通常部署在远程云计算中心,而不是客户端。在实时预测任务中,客户端通过移动设备将数据发送到远程云计算数据中心,</p>
	                    <div class="textFrom">——重庆邮电大学硕士论文 韩小娟-《脑电情感识别中多特征融合与分类研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>001。⁞2.2.2配置 GPU 加速计算⁞由于 BEGAN 深度学习模型的训练过程是对权重进行调优的过程,网络中的每个神经元的连接权重都要经过数值计算得出,<em class='similar'>故训练 BEGAN 深度学习模型需要占用庞大的计算资源。</em>⁞配置 GPU 计算加速深度学习模型的收敛进程。相较于 CPU,GPU 拥有更多核心处理器与处理数据的晶体管,带宽更高,高度并行且多线程,</p>
	                    <div class="textFrom">——建筑结构学报 杜文风；王英奇；王辉；赵艳男；高博青；董石麟-《基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>以分为三个阶段:<em class='similar'>第一阶段主要使用高斯混合模型-隐马尔可夫模型</em><em class='similar'>(Gaussian Mixture Model-Hidden Markov Model,</em><em class='similar'>GMM-</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>这些方法主要以连接时序分类(Connectionist Temporal Classification, CTC)模型和拥有编解码结构的注意力(Attention)<em class='similar'>模型为主。</em><em class='similar'>其性能优于传统的高斯混⁞合-隐马尔科夫模型</em><em class='similar'>(Gaussian Mixture Model-Hidden Markov Model,</em><em class='similar'> GMM-HMM)</em>,但是由于端到端的语音识别模型被提出的时间不长,其结构还不完善。为此,本文主要从算法层面进一步改进端到端模型,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>losses =[]⁞def on_batch_end(self, batch, logs={}):⁞self.losses ⁞原创⁞语音识别的发展趋势及主要模型⁞以前的语<em class='similar'>音识别系统基于高斯混合模型</em><em class='similar'>(Gaussian Mixture Model,</em><em class='similar'> GMM)</em>和隐马尔可夫模型<em class='similar'>(Hidden Markov Model)</em>,即 GMM-HMM 模型。发展到端对端目前的端到端系统基本上基于两个框架,一个是 CTC(Connectionist Temporal Classification)框架,</p>
	                    <div class="textFrom">——网页 -《2018年11月_yang_daxia的博客_CSDN博客》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>HMM)进行建模,<em class='similar'>基于 GMM-HMM 的语音识别框架在上世纪得到广泛应用</em>[5];</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>e⁞Model, GMM)对语音状态生成某种声学单元的发射概率进行建模,采用 HMM 对⁞语音内部的时序状态转换进行建模,此后该统计建模的框架一直沿用到今天<em class='similar'>[6]。⁞进入90年代后基于 GMM-HMM 的语音识别框架得到了广泛应用,</em>语音识别技⁞术也逐渐趋于成熟,为了进一步提升语音识别系统的性能基于此框架提出了很多⁞改进的方法,出现了最大后验概率准则估计、</p>
	                    <div class="textFrom">——吉林大学硕士论文 吕坤儒-《融合语言模型的端到端语音识别算法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>络-隐马尔可夫模型</em><em class='similar'>(Deep Neural Network- Hidden Markov Model,</em><em class='similar'>DNN-HMM)</em>为主要方法的第二阶段;</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>得重大进展和突破[24]。2011年,微软使用 DNN直接替代 GMM-⁞哈尔滨工业大学工学硕士学位论文⁞-4-⁞⁞HMM 中的 GMM 部分,以音素为建模单位,提出了基于上下文相关的深度神经网络-隐马尔可夫模型<em class='similar'>(Context-Dependent-Deep Neural Network-Hidden ⁞Markov Model,</em><em class='similar'> CD-DNN-HMM)</em>模型[25,26],相比传统 GMM-HMM,其性能有⁞显著提升。至此,GMM-HMM 框架被打破,大量研究人员投入到深度学习研⁞究中,并取得较大的成功[27,28]。此后,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音识别的发展按照时间顺序可以分为三个主要阶段:第一个阶段是以GMM-HMM框架为代表的时代,该框架在当时得到了广泛的应用[8,9]<em class='similar'>。第二个阶段是深度神经网络-隐马尔可夫模型</em><em class='similar'>(Deep Neural Network- Hidden Markov Model,</em><em class='similar'> DNN-HMM)</em>的时代[10]。上世纪提出的GMM-HMM框架被沿用了相当长一段时间,同时也暴露出模型泛化能力差、建模流程冗长等难以解决的问题。因此,研究者们当时的研究内容聚焦于对该框架的改进</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>E2E 的语音识别普遍采用深度学习的方法,</em><em class='similar'>它不需要提前进行语音帧对齐,</em><em class='similar'>而是直接采用带标签的语音进行训练。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>大量研究人员投入到对于深度学习的研究中,并取得了丰富的成果[13,14]。第三个阶段是当下的端到端时代。<em class='similar'>端到端的语音识别普遍使用深度学习方法</em>[15],<em class='similar'>不需要提前进行语音帧对齐,</em><em class='similar'>而是直接使用各种神经网络对带标签的语音数据进行拟合。</em>端到端方法解决的是输入序列长度远大于输出序列长度的问题,与传统方法相比,面向端到端的语音识别更加简洁,具有较强通用性,能够减少对专业语音、语言知识的依赖,大大降低了系统搭建难度。其总体上可以分为两类:一类是基于联结时序分类(Connectionist Temporal Classfication, CTC)[16]的端到端模型,CTC模型不需要像传统方法那样对语音数据预先进行对齐操作,只需根据输出序列和真实序列的损失在训练的过程中自动进行对齐。另一类是以编码器</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>,它们凭借各自的优势逐渐受到广泛的关注。⁞1.2.2端到端的语音识别的研究进展⁞虽然基于深度学习框架的语音识别模型比较完善,但是以 CTC 和注意力机制为主的两种端到端模型在训练语音数据时,<em class='similar'>不需要提前进行语音帧对齐操作,</em><em class='similar'>直接可以采用带标签的语音进行训练。</em>与深度学习模型相比,其训练更加简洁,对参数的优化更加直接,具有较强的通用性,能够减少对专业语音、语言知识的依赖,大大降低了系统搭建难度[29]。⁞对于这种端到端语音识别模型,如图1-1所示。其中,时域的语音信号被转化为特征序列,然后让其经过序列到序列模型来得到音素序列,最后将输出的音素序列与发音字典匹配</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>与经典方法相比,</em><em class='similar'>它更加简洁且具有较强的通用性,</em><em class='similar'>能够减少对专业语音、</em><em class='similar'>语言知识的依赖,</em><em class='similar'>大大降低了系统搭建难度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>大量研究人员投入到对于深度学习的研究中,并取得了丰富的成果[13,14]。第三个阶段是当下的端到端时代。端到端的语音识别普遍使用深度学习方法[15],不需要提前进行语音帧对齐,而是直接使用各种神经网络对带标签的语音数据进行拟合。端到端方法解决的是输入序列长度远大于输出序列长度的问题,<em class='similar'>与传统方法相比,</em>面向端到端的语音识别更加简洁,<em class='similar'>具有较强通用性,</em><em class='similar'>能够减少对专业语音、</em><em class='similar'>语言知识的依赖,</em><em class='similar'>大大降低了系统搭建难度。</em>其总体上可以分为两类:一类是基于联结时序分类(Connectionist Temporal Classfication, CTC)[16]的端到端模型,CTC模型不需要像传统方法那样对语音数据预先进行对齐操作,只需根据输出序列和真实序列的损失在训练的过程中自动进行对齐。另一类是以编码器</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>,它们凭借各自的优势逐渐受到广泛的关注。⁞1.2.2端到端的语音识别的研究进展⁞虽然基于深度学习框架的语音识别模型比较完善,但是以 CTC 和注意力机制为主的两种端到端模型在训练语音数据时,不需要提前进行语音帧对齐操作,直接可以采用带标签的语音进行训练。与深度学习模型相比,其训练更加简洁,对参数的优化更加直接,<em class='similar'>具有较强的通用性,</em><em class='similar'>能够减少对专业语音、</em><em class='similar'>语言知识的依赖,</em><em class='similar'>大大降低了系统搭建难度</em>[29]。⁞对于这种端到端语音识别模型,如图1-1所示。其中,时域的语音信号被转化为特征序列,然后让其经过序列到序列模型来得到音素序列,最后将输出的音素序列与发音字典匹配</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>总体可分为两类:</em><em class='similar'>一类是基于联结时序分类</em><em class='similar'>(Connectionist Temporal Classification,</em>CTC)[8]<em class='similar'>的 E2E 模型,</em><em class='similar'>另一类是基于注意力机制</em><em class='similar'>(Attention)</em><em class='similar'>的序列到序列</em>(Sequence-to-Sequence,S2S)<em class='similar'>模型</em>[9],<em class='similar'>二者模型结构如图1-1所示。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>结合的混合语音识别模型,其中 DNN 用于计算每个 HMM 状态的后验概率;另一种是端到端的语音识别模型,其主要有两类:<em class='similar'>一类是连接时序分类</em><em class='similar'>(Connectionist Temporal Classification,</em> CTC)[28]<em class='similar'>模型,</em><em class='similar'>另一类是基于注意力</em><em class='similar'>(Attention)</em>机制的编码-解码⁞重庆邮电大学硕士学位论文第1章绪论4(Encoder-Decoder)<em class='similar'>模型</em>[29]。对于上述两种框架,循环神经网络都十分适用,</p>
	                    <div class="textFrom">——网页 -《基于循环神经网络的语音识别声学建模研究》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>大量研究人员投入到对于深度学习的研究中,并取得了丰富的成果[13,14]。第三个阶段是当下的端到端时代。端到端的语音识别普遍使用深度学习方法[15],不需要提前进行语音帧对齐,而是直接使用各种神经网络对带标签的语音数据进行拟合。端到端方法解决的是输入序列长度远大于输出序列长度的问题,与传统方法相比,面向端到端的语音识别更加简洁,具有较强通用性,能够减少对专业语音、语言知识的依赖,大大降低了系统搭建难度。<em class='similar'>其总体上可以分为两类:</em><em class='similar'>一类是基于联结时序分类</em>(Connectionist Temporal Classfication, CTC)[16]的端到端模型,CTC模型不需要像传统方法那样对语音数据预先进行对齐操作,只需根据输出序列和真实序列的损失在训练的过程中自动进行对齐。另一类是以编码器</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>⁞2.1 Transformer ⁞Transformer模型出自于2017年6月谷歌发表的《Attention is All You Need》⁞[25]论文中,<em class='similar'>其原始的 Vanilla Transformer 模型结构如图2-1所示。</em><em class='similar'>⁞Transformer 是一个序列到序列的模型,</em>包含 encoder 和 decoder 两个部分。两者都是由一个多头自注意力模块和一个前馈网络结构组成的堆栈。Transformer 采用 Query-Key-Value(QKV)型的注意力机制。</p>
	                    <div class="textFrom">——北方工业大学硕士论文 李良才-《知识驱动的个性化新闻推荐》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>型能够度量输入和输出序列的相似度,</em><em class='similar'>并且能刻画语音特征和字符序列的相关性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>哈尔滨工业大学工学硕士学位论文⁞-5-⁞⁞⁞图1-1端到端的语音识别系统⁞⁞⁞图1-2序列到序列模型⁞⁞图1-2的子图(a)为 CTC 模型。在无先验性对齐情况下,<em class='similar'>该模型能够度量输入和输出序列的相似度,</em><em class='similar'>并且能刻画语音特征和音素序列的相关性。</em>基于CTC 的语音识别系统由 RNN 编码模块和 CTC 损失函数模块组成。首先,输入的特征序列通过 RNN 进行编码,并由 CTC 的帧独立假设得到音素序列的后验概率。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>基于联结时序分类的语音识别由卷积神经网络</em><em class='similar'>(Convolutional Neural Network,</em><em class='similar'>CNN)/循环神经网络</em><em class='similar'>(Recurrent Neural Network,</em><em class='similar'>RNN)</em><em class='similar'>编码模块和</em> CTC 损失函数模块组成。<em class='similar'>2006年 Graves 等人利用空白字符对不同长度的序列进行对齐,</em><em class='similar'>首次提出 CTC 模型来解决 MINIST 数据集上的手写数字识别和 TIMIT </em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>更新模型参数⁞特征序列⁞RNN CTC ⁞音素(字符)序列⁞特征序列编码网络注意力网络⁞解码网络⁞音素(字符)序列(a) CTC 模型(b)注意力模型⁞哈尔滨工业大学工学硕士学位论文⁞-6-⁞⁞对于 CTC 的研究,2006年 Alex Graves 利用空白(Blank)<em class='similar'>字符对不同长度的序列进行对齐,</em><em class='similar'>首次提出 CTC 模型来解决 MINIST 手写数字识别和 TIMIT语料库音素分类的问题。</em>该模型利用 RNN 挖掘输入序列的时序信息,摆脱了⁞HMM 传统模型,同时也取得较好的效果[30]。2012年 Alex 对 CTC 的语音识别⁞模型进一步改进,将 RNN 作为转化模型。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>煤矿监控场景的智能行为识别技术有利于推进煤矿产业的智能化发展,但煤矿人员行为识别易受背景信息、光照强度、摄像机视角等因素的影响〔2-5〕。随着深度学习的发展,通过<em class='similar'>卷积神经网络</em><em class='similar'>(Convolutional Neural Network ,</em><em class='similar'> CNN )</em><em class='similar'>和循环神经网络</em><em class='similar'>( Recurrent Neural Network ,</em><em class='similar'> RNN )</em>学习人体行为特征逐渐成为主流。文献〔6〕提出一种端对端的时间卷积网络来实现动作识别,使用 CNN将骨架数据建模为伪图像,并对伪图像进行卷积操作。</p>
	                    <div class="textFrom">——网页 -《基于DA_GCN的煤矿人员行为识别方法_黄瀚》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>而且泛化性能较差,虽然也有对 SVM 进行优化的 AdaBoost-PSOSVM 强分类器,同样还是无法准确理解深层次的语义信息。⁞近年来,许多神经网络被应用在文本分类上,如<em class='similar'>卷积神经网络</em><em class='similar'>(Convolutional Neural ⁞Network,</em><em class='similar'>CNN)、</em><em class='similar'>循环神经网络</em><em class='similar'>(Recurrent Neural Network,</em><em class='similar'>RNN)</em>和胶囊网络(Capsule-Net)。⁞2013年,Xu[14]等人利用卷积神经网络提取5-gram 特征,利用 Max-Pooling 来获取单词表示,该方法可以有效提取意图特征进行意图识别。2015年,</p>
	                    <div class="textFrom">——南京邮电大学硕士论文 郑思露-《基于ERNIE的口语理解研究与应用》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>,稀疏编码(Sparse Coding)和自编码器(Auto-encoder)等。另一方面,面对实际问题的科学家们一直在凭借直觉设计深度学习模型的结构来解决这些问题。这方面出现了许多成功的例子,<em class='similar'>比如用于视觉和语音识别的卷积神经网络</em><em class='similar'>(Convolutional Neural Network)</em>,以及能够进行自我演绎的深度回归神经网络<em class='similar'>(Recurrent Neural Network)</em>和会自主玩游戏的深度强化学习(Reinforcement Learning)模型。</p>
	                    <div class="textFrom">——网页 -《第二十五课：深度学习 · Machine Learning》- （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>和实体描述信息后整个模型在句子级关系抽取方面的性能优势,比较不同方法针对特定句子识别实体对的关系类型的性能。在文献[2]所使用的数据集上,分别以 PCNN、<em class='similar'>循环神经网络</em><em class='similar'>(Recurrent⁞Neural Network,</em><em class='similar'>RNN)</em><em class='similar'>为编码模块</em>,替换普通注意力网络 ATT、跨关系注意力 CRSA、跨关系跨包注意力C2SA 以及加入实体描述信息后的模型,以此进行实⁞验对比,实验结果如表2所示。⁞从表2可以看出:⁞1)以 PCNN 和 RNN </p>
	                    <div class="textFrom">——计算机工程 孙新；申长虹；姜景虎；崔家铭-《结合实体描述信息的跨句包关系抽取方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>2012年 Graves 对 CTC 语音识别模型进一步改进,</em><em class='similar'>将RNN 作为转化模型</em>[11],</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>该模型利用 RNN 挖掘输入序列的时序信息,摆脱了⁞HMM 传统模型,同时也取得较好的效果<em class='similar'>[30]。2012年 Alex 对 CTC 的语音识别⁞模型进一步改进,</em><em class='similar'>将 RNN 作为转化模型。</em>该模型中拥有两个 RNN,第一个RNN 相当于传统语音识别中的声学模型,在给定输入语音特征序列的情况下,能够计算输出音素后验概率。第二个 RNN 相当于语言模型,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong><em class='similar'>Graves等人利用多层的长短时记忆</em><em class='similar'>(Long Short-Term Memory,</em><em class='similar'>LSTM)</em><em class='similar'>神经网络进行建</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>数据集上取得比 DNN-HMM 更好的效果[31]。Zweig 还尝试在⁞CTC 模型之后加入不同的语言模型,发现语言模型对识别效果有较大的影响[32]。2013年,<em class='similar'>Alex 利用多层的长短时记忆</em><em class='similar'>(Long Short-Term Memory,</em><em class='similar'> LSTM)</em><em class='similar'>神⁞经网络进行建模,</em>进一步提升 TIMIT 语料库上的识别效果[33]。与此同时,产⁞业界也陆续开始对 CTC 进行研究。2015年,百度提出基于 CTC 的语音识别系统——DeepSpeech,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>14.</strong>模,<em class='similar'>进一步提升 TIMIT 语料库上的识别效果</em>[12],达到了17.7%的 PER。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>发现语言模型对识别效果有较大的影响[32]。2013年,Alex 利用多层的长短时记忆(Long Short-Term Memory, LSTM)神⁞经网络进行建模,<em class='similar'>进一步提升 TIMIT 语料库上的识别效果</em>[33]。与此同时,产⁞业界也陆续开始对 CTC 进行研究。2015年,百度提出基于 CTC 的语音识别系统——DeepSpeech,使用长达10000小时的训练数据,将英语广播语音语料⁞集的错误率降至10%,并对说话人、</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>15.</strong>Graves <em class='similar'>首次提出</em>,<em class='similar'>并被用于 MINIST 数据集的手写数字识别任务中</em><em class='similar'>[13]。2014年,</em><em class='similar'>Bahdanau等人在此基础上进一步完善,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>采用解码算法可以产生音素序列。注意力模型在识别过程中既不需要每一帧的强制对齐,也不需要帧的独立假设。⁞对于注意力模型,它是2013年由 Alex Graves 首次提出,<em class='similar'>并应用于 MINIST⁞数据集的手写数字识别任务中</em><em class='similar'>[38]。2014年 Bahdanau 进一步完善,</em>提出基于注⁞哈尔滨工业大学工学硕士学位论文⁞意力机制的编解码模型,并将其应用于机器翻译中[36]。同年,Bahdanau 还将注意力模型进一步应用于语音识别任务中,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>M)在翻译过程中能够让不同字符文本自动进行对齐。语音识别任务可以类比为机器翻译任务,识别过程可以视为将语音特征序列翻译成字符序列,因此序列到序列模型能够应用于语音识别中[28]。该模型由J. K. Chorowski等人于2013年<em class='similar'>首次提出</em>,<em class='similar'>在MINIST数据集的手写数字识别任务中显示出一定的效果。</em><em class='similar'>2014年,</em>D. Bahdanau等人提出了基于注意力机制的&quot;编码器-解码器&quot;框架(Encoder-Decoder Structure, EDS),进一步完善了该模型[29]。此后,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>16.</strong>18.57%。<em class='similar'>至此,</em><em class='similar'>大量的研究人员开始投入到基于 Attention 的语音识别研究中,</em><em class='similar'>并提出多种改进模型。</em><em class='similar'>根据改进方法可分为三类:</em><em class='similar'>对 Encoder 的改进、</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并在目标函数中加入约束,使得输出音素和语音帧能保证严格单调对齐,相比 HMM 语音识别模型,在 TIMIT 数⁞据集上取得较好的效果[39]。<em class='similar'>至此,</em><em class='similar'>大量的研究人员开始投入到注意力模型的语音识别研究中,</em><em class='similar'>并提出各种各样的改进模型。</em><em class='similar'>本文将注意力模型的改进方法分为三类,</em><em class='similar'>分别为对编码器的改进方法、</em>对注意力机制的改进方法,以及对语言⁞模型的改进方法。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>17.</strong>对 Encoder 的改进方面,<em class='similar'>Bahar 等人采用更复杂的二维长短时记忆网络</em><em class='similar'>(Two-Dimensional Long Short Term Memory,</em><em class='similar'>2DLSTM)</em><em class='similar'>作为</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Zhang 等采用更加复杂的编码器,利用 CNN 和 LSTM混合成更深的神经网络,并将输出的高层特征作为注意力模型的输入,能挖掘更深层次的语音信息,大幅度提高识别效果[42]。除了采用传统的 RNN 之外,<em class='similar'>⁞Bahar 等还采用更复杂的二维长短时记忆网络</em><em class='similar'>(Two-Dimensional Long Short ⁞Term Memory,</em><em class='similar'>2DLSTM)</em><em class='similar'>作为</em>编码模型,从多维的角度增加语音时序信息的辨⁞认能力[43]。⁞对注意力机制部分的改进,Bahdanau 等将注意力模型应用于 LVCSR 任务中,采用卷积窗来减少对语音帧的关注区域,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>18.</strong><em class='similar'>编码模型,</em><em class='similar'>从多维的角度增加语音时序信息的辨认能力</em>[16]。近几年,研究者们热</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>能挖掘更深层次的语音信息,大幅度提高识别效果[42]。除了采用传统的 RNN 之外,⁞Bahar 等还采用更复杂的二维长短时记忆网络(Two-Dimensional Long Short ⁞Term Memory,2DLSTM)<em class='similar'>作为编码模型,</em><em class='similar'>从多维的角度增加语音时序信息的辨⁞认能力</em>[43]。⁞对注意力机制部分的改进,Bahdanau 等将注意力模型应用于 LVCSR 任务中,采用卷积窗来减少对语音帧的关注区域,还将 CNN 作为编码器,让高层特征提取更加的精确,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>19.</strong><em class='similar'>采用全连接网络,</em><em class='similar'>因而相较于 RNN 等结构,</em><em class='similar'>其训练效率高,</em><em class='similar'>模型收敛效果好</em>[18];</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并使用Transformer对特征序列和标签序列进行序列化建模,完成了全部建模流程的端到端化,也实现了错误率的大幅降低。<em class='similar'>由于Transformer模型采用全连接网络,</em><em class='similar'>因而相较于RNN等结构,</em><em class='similar'>其训练效率高,</em><em class='similar'>模型收敛效果好</em>[33]。⁞在对注意力机制的改进方面,文献[34]通过在注意力得分计算过程中引入窗函数,剔除了无效的注意力得分,大幅提高了中文语音识别系统的识别性能。文献[35]等人设计了一种混合注意力机制,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>20.</strong>对 Attention 的改进方面,<em class='similar'>Merboldt 等人提出局部注意力机制,</em><em class='similar'>对其添加约束,</em><em class='similar'>同时还考虑最大注意力得分,</em><em class='similar'>之后采用启发式搜索对模型进行训练,</em><em class='similar'>最终在</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>机对语言模型打分,以提高解码速度[44]。Chan 等在计算注意力模型的注意力得分时也引入窗函数,应用于⁞在线中文的识别,其识别性能取得大幅度提高[45]。<em class='similar'>Merboldt 等提出局部注意力机制,</em><em class='similar'>对其添加约束,</em><em class='similar'>同时还考虑最大注意力得分,</em><em class='similar'>之后采用启发式搜索对模型进行训练,</em><em class='similar'>最终在</em> SwitchBoard 和 LibriSpeech 数据集上取得较好的效果[46]。Shan 在注意力模型中加入二范正则项和高斯噪声来增加模型的鲁棒性,同时还采用跳帧技术进一步提高模型的训练速度。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>21.</strong><em class='similar'>SwitchBoard 和 LibriSpeech 数据集上取得较好的效果</em>[19];对语言模型的改进方面,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>得分时也引入窗函数,应用于⁞在线中文的识别,其识别性能取得大幅度提高[45]。Merboldt 等提出局部注意力机制,对其添加约束,同时还考虑最大注意力得分,之后采用启发式搜索对模型进行训练,<em class='similar'>最终在 SwitchBoard 和 LibriSpeech 数据集上取得较好的效果</em>[46]。Shan 在注意力模型中加入二范正则项和高斯噪声来增加模型的鲁棒性,同时还采用跳帧技术进一步提高模型的训练速度。该系统目前已经应用于小米电视的中文语音检索中[47]。除了采用单头的注意力机制,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>22.</strong><em class='similar'>除了传统的语言模型,</em><em class='similar'>Zeyer 等人采用 LSTM 作为语言模型,</em><em class='similar'>并采用字节对编码</em><em class='similar'>(Byte Pair Encoding,</em><em class='similar'>BPE)</em><em class='similar'>输出不同的识别基元,</em><em class='similar'>相比于传统语言模型,</em><em class='similar'>取得</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>等尝试分别采用3-gram 和5-gram 语言模型应用于注意力模型中,以词和字符作为输出序列,相比于未采用语言模型,其取得了一定的提升效果[49]。<em class='similar'>除了传统的语言模型,</em><em class='similar'>Zeyer 采用 LSTM 作为语言⁞哈尔滨工业大学工学硕士学位论文⁞模型,</em><em class='similar'>并采用字节对编码</em><em class='similar'>(Byte Pair Encoding,</em><em class='similar'> BPE)</em><em class='similar'>输出不同的识别基元,</em><em class='similar'>相比⁞于传统语言模型,</em><em class='similar'>取得</em>较好的性能提升[50]。⁞1.3目前方法存在的问题⁞从对上述已有研究工作的分析可知,在端到端的语音识别模型中,基于CTC 的语音识别模型需要帧的独立假设。实际中,分帧阶段相邻帧之间都有相互重叠的部分,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>23.</strong><em class='similar'>速度慢等缺点,</em><em class='similar'>而基于Attention 的 S2S 模型具有模型简单、</em><em class='similar'>联合训练、</em><em class='similar'>直接输出和无需强制数据对齐等优点。</em>但是,该类模型存在参数量庞大、</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>注意力机制和互注意力机制。⁞基于联结时序分类的端到端模型具有解码过程复杂、<em class='similar'>速度慢等缺点,</em><em class='similar'>而基于序列到序列模型的方法具有模型简单、</em><em class='similar'>联合训练、</em><em class='similar'>直接输出和无需强制进行数据对齐等优点。</em>因此,后者是未来重要的研究方向。基于注意力机制的序列到序列模型虽然对全局信息的捕获能力十分优秀,但对于同样重要的局部信息的捕获能力却稍显不足。同时,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>同时,经过多年的发展,HMM-GMM模型已达到瓶颈,并且几乎没有进一步改进性能的空间。而深度学习的技术推动了HMM-DNN模型和端到端模型的兴起和发展,这些模型在某些方面的性能已超越HMM-GMM。<em class='similar'>端到端模型则具有简化模型、</em><em class='similar'>联合训练、</em><em class='similar'>直接输出和无需要强制数据对齐等优点,</em>且学习曲线较为平缓。因此,端到端模型是LVCSR的当前重点,也是未来的重要研究方向。端到端语音识别研究综述@郭宗昱$中国民航大学!天津300000⁞</p>
	                    <div class="textFrom">——科技风 郭宗昱；刘博；吴可欣；李姝怡；蒋昊轩；李云洁-《端到端语音识别研究综述》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>并且几乎没有进一步改进性能的空间&amp;而深度学习的技术推动了 HMM-DNN 模型和端到端模型的兴起和发展,这些模型在某些方面的性能已超越 HMM-GMM &amp;端到端模<em class='similar'>型则具有简化模型</em>、<em class='similar'>联合训练、</em><em class='similar'>直接输岀和无需要强制数据对齐等优点,</em>且学习曲线较为平缓&amp;因此,端到端模型是 LVCSR 的当前重点,也是未来的重要研究方向&amp;参考文献:[1] Rao , K.; Sak , H.‘ PrabhavakaeR.</p>
	                    <div class="textFrom">——网页 -《端到端语音识别研究综述》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>24.</strong><em class='similar'>此外还研究了命名实体、</em><em class='similar'>句法特征和词类信息等</em>[24]。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>语义槽填充可以表述为一种序列标注任务,常用的语义槽填充方法包括 CRF、RNN 以及基于 RNN 的变体模型。2013年 Yao[34]等人采用 RNN 语言模型(RNN-LM)来预测语义槽标⁞签而不是单词,<em class='similar'>RNN-LM 还研究了未来词、</em><em class='similar'>命名实体、</em><em class='similar'>句法特征和词类信息。</em>2016年 Vu[35]等人在语义槽填充的 Bi-RNN 模型上使用了排序损失函数,进一步提高了 ATIS 数据集上语义槽填充的性能。⁞2020年 Wu[36]</p>
	                    <div class="textFrom">——南京邮电大学硕士论文 郑思露-《基于ERNIE的口语理解研究与应用》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>25.</strong><em class='similar'>隐式联合建模是一种直接整合共享信息的方法,</em><em class='similar'>但后续未对交互关系进行显式建模,</em><em class='similar'>导致模型可解释性</em>不足,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>图识别错误率比独立任务训练模型提高了22.3%,而槽填充 Fl 分数略有下降。<em class='similar'>虽然隐式关节建模是一种直接整合共享知识的方法,</em><em class='similar'>但它没有对交互进行显式建模,</em><em class='similar'>导致可解释性和性</em>能低下。⁞越来越多的研究提出使用显式交互模块对意图与槽之间的交互进行显式建模,这种显式建模模式具有显式控制交互过程的优点,现有的显式联合建模方法可分为单向交互和双向交互两种类型。⁞</p>
	                    <div class="textFrom">——南京邮电大学硕士论文 郑思露-《基于ERNIE的口语理解研究与应用》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>26.</strong><em class='similar'>Qin 等人提出 Stack-Propagation 模型</em>[31],<em class='similar'>直接使用意图检测结果来指导槽位填充,</em>并使</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>ted),使得槽位填充可以学习⁞意图信息。C Li 等人[38]提出将自注意力机制融入到意图识别与槽位填充联合模型中,使用意图增强门来引导槽位填充,取得了不错的效果。<em class='similar'>L Qin等人</em><em class='similar'>[39]⁞提出了 Stack-Propagation框架,</em><em class='similar'>使用意图检测结果指导槽位填充,</em>进一步提高了性能。⁞Y Wang等人[40]提出使用双向 LSTM来对意图识别与槽位填充之间的影响⁞进行建模。P Niu等人[41]同时考虑了从意图识别到槽位填充以及从槽位填充到⁞</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 金朋-《意图识别与槽位填充关键技术研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>27.</strong>(Capsule-NLU)[33],<em class='similar'>将两个任务之间的分层和相关关系纳入其中,</em>在 ATIS 和</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>2019年 Niu[47]等人考虑到 SF-to-ID 和 ID-to-SF 的影响,提出了一种新颖的 SF-ID 网络,为 SF 和 ID 任务提供了双向关联机制。同年 Zhang C[48]等人引入了动态路由胶囊网络,<em class='similar'>将两个任务之间的分层和相关关系纳入其中,</em>取得了不错的效果。2020年Zhang L[49]等人将图LSTM引入 SLU进行了探索,取得了很好的性能。Qin[50]等人通过在两个相关任务之间建立双向联系,提出了一种协同交互转换来考虑交叉</p>
	                    <div class="textFrom">——南京邮电大学硕士论文 郑思露-《基于ERNIE的口语理解研究与应用》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>28.</strong><em class='similar'>Qin 等人通过建立两个任务之间的双向连接,</em><em class='similar'>提出了一种考虑交叉影响的 Co-interactive Transformer 模型</em>[36],</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>16], AGIF⁞[17]以及⁞GL-GIN⁞[18]模型迚行对比,为了契合数据集对模型迚行微⁞调,<em class='similar'>其中 Co-Interactive Transformer 模型通过建立相关仸务乊间的双向连接考虑交叉影响,</em>而不是采用普通的Transformer 中的自注意力机制,幵且提出一种协同交互模块实现仸务间的特性传递。AGIF 模型提出了一种交互层,该层可以提取其中一个仸务的信息集成到另一个仸务中,</p>
	                    <div class="textFrom">——计算机工程与应用 林鸿辉；刘建华；郑智雄；胡任远；罗逸轩-《联合对话行为识别与情感分类的多任务网络》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>来对意图识别与槽位填充进行联合建模。L Zhang等人[44]尝试将图 LSTM(G-LSTM)引入,取得了不错的性能。L Qin等人[45]更进一步提出将协同交互 Transformer与 BERT相结合,<em class='similar'>通过在这两个任务之间建立双向连接来对交叉影响进行建模。</em>对于意图识别与槽位填充任务,显式联合模型可以捕获跨任务的共享知识,而不仅仅只是共享特征表示,因此在性能表现上更加优秀,同时也具有更好的可解释性。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 金朋-《意图识别与槽位填充关键技术研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>29.</strong>ase-uncased[37]为例,<em class='similar'>其网络层数为12,</em><em class='similar'>隐藏层维度为768,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>而注意力机制可以根据单词对句子的重要性进行调权。⁞(4) BERT[48]:BERT 作为近几年自然语言处理先进技术的集大成者,同样可以用于情⁞感回归任务。本实验使用 BERT-Base 模型,<em class='similar'>其网络层数为12,</em><em class='similar'>隐藏层维度为768,</em>多头注意力个数为12,总参数量为110M。⁞3.2.3实验环境⁞本文中所有实验的软硬件环境及其配置如表3.3所示。⁞南京邮电大学专业学位硕士研究生学位论文第三章基于 </p>
	                    <div class="textFrom">——南京邮电大学硕士论文 孙晓雨-《基于语义场景分析的文本表情分析方法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>30.</strong><em class='similar'>论文共分为六章,</em><em class='similar'>如图1-3所示,</em><em class='similar'>各章节安排如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>到一个最终结果作为广告的匹配对象。最终根据系统需求完成相关软件的设计,并采用⁞CUDA 编程对核函数进行调优,优化算法并行效率。⁞1.4本文结构安排⁞本<em class='similar'>文共分为六章</em>,<em class='similar'>结构安排如图1-3所示,</em><em class='similar'>具体章节安排如下:</em>⁞第1章绪论阐述了本课题研究的背景和意义,调研了智能视频广告展示系统相关技术⁞在国内外的研究现状。介绍了本文主要的研究内容和结构安排。⁞第2章对智能视频广告展示系统进行了性能需</p>
	                    <div class="textFrom">——浙江工业大学硕士论文 陈杰华-《基于Jetson TX1处理器平台的智能视频广告展示系统设计和实现》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>所处的困境以及突破这些困境的可能出路,从用户服务性能评价、INS 辅助下的高动⁞态弱信号处理和轨道外推器辅助下的高性能定轨三个方面促进未来 GNSS 在 SSV 中发⁞挥更大作用。<em class='similar'>本文的章节安排如图1-3所示。</em><em class='similar'>⁞全文共分为六章,</em>各章的研究内容具体安排如下:⁞第一章,简要描述研究的背景情况,从中引出 SSV 定义的内涵和外延,回溯过往⁞的 SSV 议题发展历程和人类相关发射试验,分三个方面概括了 </p>
	                    <div class="textFrom">——上海交通大学博士论文 荆帅-《GNSS空间服务空域性能评估及辅助增强技术研究》-2017 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>与逼近相结合的方法实现中弧面的光顺重构;叶片型腔重构基于反变形优化后的中弧面模型和厚度模型,通过型线复原,建立优化的模具型腔模型。结果验证:采用数值模拟手段对重构的模具型腔进行验证。1.5.3<em class='similar'>章节安排论文共分六章,</em><em class='similar'>各章节的组织结构如图1-3所示。</em>第一章,绪论。分析涡轮叶片精铸模具型腔优化设计的需求背景和研究意义。阐述国内外研究现状,在此基础上指出本论文的研究内容。第二章,网格模型截面数据的预处理。</p>
	                    <div class="textFrom">——网页 -《基于中弧面的模具型腔高质量重构方法研究硕士研究生学位》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>31.</strong><em class='similar'>最后通过一系列对比实验和消融实验论证所提模型的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其中,分别讲解了 Siamese网络的整体架构,ESIM网络的整体⁞架构及计算公式,本文评分模型的整体架构、计算公式和训练流程;⁞(3)<em class='similar'>最后,</em><em class='similar'>通过多组对比实验和消融实验论证了本文提出的基于 Siamese和 ESIM网络的中文主观题自动评分模型的有效性。</em>其中,对比实验主要说明了本文自动评分模型在定义类学生答案、顺序类学生答案和一般类学生答案三个数据集上的准确率、F1值、</p>
	                    <div class="textFrom">——广西师范大学硕士论文 龚云-《基于单字级深度神经网络的中文主观题自动评分研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>是引入图像增强的EIRCNN水下图像目标检测算法部分。结合第三章提出的IRCNN和第四章提出的三种水下图像增强算法,本章将三个水下图像增强算法与IRCNN结合提出了EIRCNN算法,并与其他检测方法进行对比实验,<em class='similar'>最后还通过消融实验论证各个增强模块的有效性,</em>最终证明了EIRCNN 对海洋生物的检测精度有显著提升。⁞第六章是引入图像增强的ESSD水下图像目标算法部分。本章在SSD算法中引入第四章提出的三种水下图像增强算法进行实验,最终证明了针对水</p>
	                    <div class="textFrom">——杭州电子科技大学硕士论文 方笑海-《基于深度神经网络的水下目标图像识别算法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>32.</strong>高,<em class='similar'>最后通过一系列对比实验和消融实验论证所提模型的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其中,分别讲解了 Siamese网络的整体架构,ESIM网络的整体⁞架构及计算公式,本文评分模型的整体架构、计算公式和训练流程;⁞(3)<em class='similar'>最后,</em><em class='similar'>通过多组对比实验和消融实验论证了本文提出的基于 Siamese和 ESIM网络的中文主观题自动评分模型的有效性。</em>其中,对比实验主要说明了本文自动评分模型在定义类学生答案、顺序类学生答案和一般类学生答案三个数据集上的准确率、F1值、</p>
	                    <div class="textFrom">——广西师范大学硕士论文 龚云-《基于单字级深度神经网络的中文主观题自动评分研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>33.</strong><em class='similar'>第六章,</em><em class='similar'>总结与展望。</em><em class='similar'>总结论文研究内容,</em><em class='similar'>并对后续研究工作做出展望。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对大型环锻件表面缺陷检测系统的检测指标进行了验证,并且通过实验对比分析,总结出该缺陷检测系统满足了生产中的实际需求。<em class='similar'>⁞第六章为总结与展望。</em><em class='similar'>总结了本文的研究内容,</em><em class='similar'>并对后续的研究工作做出了展望。</em>⁞第2章大型环锻件缺陷检测系统总体方案设计⁞2.1引言⁞大型环锻件检测系统包括硬件与软件部分,硬件提供了系统的基础条件,软件则将系统变得更加的灵活与智能,</p>
	                    <div class="textFrom">——江苏科技大学硕士论文 李家富-《基于机器视觉的大型环锻件缺陷检测系统关键技术研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>。通过在 Simulink 和 CarSim 平台仿真,依次验证了模型搭建的合理性、两点预瞄相较于单点预瞄的优点以及视觉补偿控制和神经肌肉系统各参数变化对车辆状态输出的影响。<em class='similar'>第六章为总结与展望,</em><em class='similar'>总结本文的研究内容,</em><em class='similar'>并展望后续的研究工作。</em>⁞大连理工大学专业学位硕士学位论文-11-2车辆道路系统建模2.1车辆建模2.1.1运动学建模运动学主要是用来描述运动的物体在惯性坐标系下的车辆速度、横摆角速度与车体航向</p>
	                    <div class="textFrom">——网页 -《基于视觉和肌肉系统的驾驶员转向行为建模》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>最后对实测数据进行处理,并结合仿真结果进行比较分析,为后续更加复杂结构的石墨烯吸波器或金属石墨烯混合表面吸波器的加工与实测提供引导与借鉴作用。<em class='similar'>第六章总结与展望对全文的研究内容做出总结,</em><em class='similar'>同时展望本课题的后续研究工作。</em>⁞基于石墨烯的吸波器电磁特性研究10第二章基本理论§2.1石墨烯基本概念石墨烯是人们发现的第一种由单层原子构成的二维材料,且单层厚度为0.34nm,</p>
	                    <div class="textFrom">——网页 -《基于石墨烯的吸波器电磁特性研究 - 道客巴巴》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第2章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_3" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的对话系统研究与应用" target="_blank">基于深度学习的对话系统研究与应用</a></span>
                      <p>赵新颜 -
                        《中国科学技术大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">26.8%(361字)</span></td>
                  <td class="bdrNo">是</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">21.5%(290字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向开放域对话系统的多样性回复研究" target="_blank">面向开放域对话系统的多样性回复研究</a></span>
                      <p>毕胜 -
                        《南京大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">17.8%(240字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Transformer的对话系统模型设计与压缩方法研究" target="_blank">基于Transformer的对话系统模型设计与压缩方法研究</a></span>
                      <p>白宇 -
                        《浙江大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">16.3%(220字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于序列学习的任务型对话系统模型研究" target="_blank">基于序列学习的任务型对话系统模型研究</a></span>
                      <p>虞兵 -
                        《合肥工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">11.3%(152字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人民邮电  深度学习原理与实践" target="_blank">人民邮电  深度学习原理与实践</a></span>
                      <p>陈仲铭，彭凌西著 -
                        《
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">10.5%(142字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=聊天机器人的分类标准和评估标准综述" target="_blank">聊天机器人的分类标准和评估标准综述</a></span>
                      <p>王艳秋;管浩言;张彤 -
                        《工程(英文)
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">8.2%(110字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://www.elecfans.com/d/888112.html" target="_blank">结合NLU在面向任务的对话系统中的具体应用进行介绍-电子发烧友网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.9%(79字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的口语理解技术研究" target="_blank">基于深度学习的口语理解技术研究</a></span>
                      <p>于沛霖 -
                        《西北师范大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">5.3%(72字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于PAD情感状态模型的对话生成研究" target="_blank">基于PAD情感状态模型的对话生成研究</a></span>
                      <p>刘磊 -
                        《华中师范大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">4.9%(66字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于卷积神经网络的宫颈病变图像分类方法研究" target="_blank">基于卷积神经网络的宫颈病变图像分类方法研究</a></span>
                      <p>宋丹 -
                        《华侨大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(65字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://cache.baiducontent.com/c?m=9f65cb4a8c8507ed4fece763105392230e54f7356186da1f68d4e419ce3b4603506695b02d251107d0c67a6307ab4b59fdf04128715c7ea3de95c81cd2ace42c38fc2223016d913612c418dfdc3621d657924d9faf0e90bde74491b9a4d5&p=82769a4791934eac5ab6d32f1c4f&newp=8c73c64ad4934eac5a9fdf2c5c4792695d0fc20e3dd7d601298ffe0cc4241a1a1a3aecbf23241104d3c2766c07aa4b5de0f73376330434f1f689df08d2ecce7e&user=baidu&fm=sc&query=site%3Adoc88%2Ecom+%D6%F7%CC%E2%B6%E0%D2%E5%D0%D4&qid=8d08078a000670ce&p1=7" target="_blank">基于主题模型的多示例多标记学习方法.doc</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.6%(62字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://www.docin.com/p-2387560873.html" target="_blank">基于深度学习的对话领域意图分类方法研究 - 豆丁网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.4%(59字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人工神经网络基础" target="_blank">人工神经网络基础</a></span>
                      <p>韩敏编著 -
                        《
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.4%(59字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="https://blog.csdn.net/Avery123123/article/details/103366822" target="_blank">第四章 前馈神经网络_Avery123123的博客-CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(51字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://www.doc88.com/p%2D70187799111050.html" target="_blank">分布式协作神经网络中的隐私保护研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(51字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=分类方法在钓鱼网站数据鉴别中的应用" target="_blank">分类方法在钓鱼网站数据鉴别中的应用</a></span>
                      <p>苏春晶 -
                        《兰州大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于边缘计算的交通目标检测与识别" target="_blank">基于边缘计算的交通目标检测与识别</a></span>
                      <p>詹鹏基 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://www.doc88.com/p%2D7018723512940.html" target="_blank">基于深度学习的开放领域对话系统研究综述</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">20.</strong> <span><a href="http://xueshu.baidu.com/s?wd=循环神经网络在内蒙古地区沙尘暴预测中的应用研究" target="_blank">循环神经网络在内蒙古地区沙尘暴预测中的应用研究</a></span>
                      <p>张唯铭 -
                        《内蒙古工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(48字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">21.</strong> <span><a href="http://xueshu.baidu.com/s?wd=任务型对话中少样本意图分析研究" target="_blank">任务型对话中少样本意图分析研究</a></span>
                      <p>司志博文 -
                        《哈尔滨工业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(44字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">22.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于卷积神经网络的语音识别研究" target="_blank">基于卷积神经网络的语音识别研究</a></span>
                      <p>梅俊杰 -
                        《北京交通大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">23.</strong> <span><a href="https://www.jiqizhixin.com/articles/2019-01-11" target="_blank">30年前的“CNN梦”在这颗芯片落地，能效比高出Tesla10倍 | 机器之心</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">24.</strong> <span><a href="http://xueshu.baidu.com/s?wd=任务型对话系统研究综述" target="_blank">任务型对话系统研究综述</a></span>
                      <p>赵阳洋;王振宇;王佩;杨添;张睿;尹凯 -
                        《《计算机学报》
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">25.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的视频个性化推荐系统研究" target="_blank">基于深度神经网络的视频个性化推荐系统研究</a></span>
                      <p>高睿 -
                        《深圳大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">26.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度强化学习的小行星探测器跳跃轨迹规划研究" target="_blank">基于深度强化学习的小行星探测器跳跃轨迹规划研究</a></span>
                      <p>陈康 -
                        《哈尔滨工业大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">27.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于音视频双模态信息融合的语音分离研究" target="_blank">基于音视频双模态信息融合的语音分离研究</a></span>
                      <p>李晨达 -
                        《上海交通大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">28.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于POCT的宫颈癌细胞图像识别研究" target="_blank">基于POCT的宫颈癌细胞图像识别研究</a></span>
                      <p>黄云奎 -
                        《大连理工大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">29.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于BP神经网络PID控制的温室环境控制系统的仿真研究" target="_blank">基于BP神经网络PID控制的温室环境控制系统的仿真研究</a></span>
                      <p>涂川川 -
                        《吉林农业大学硕士论文
                        》- 2012 
                      </p>
                    </div></td>
                  <td><span class="green">2%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">30.</strong> <span><a href="http://xueshu.baidu.com/s?wd=深度学习框架PyTorch快速开发与实战" target="_blank">深度学习框架PyTorch快速开发与实战</a></span>
                      <p>邢梦来，王硕，孙洋洋编著 -
                        《北京：电子工业出版社,2018.08
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">31.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络的古诗词自动生成研究" target="_blank">基于神经网络的古诗词自动生成研究</a></span>
                      <p>李争 -
                        《北京邮电大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_3" class="simMore"><a href="javascript:$ShowMore(3);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>对话系统历经半个多世纪的发展,</em>取得了很大的研究成果。<em class='similar'>现有对话系统按类型主要可分为闲聊型对话系统</em><em class='similar'>(Chatbot)</em><em class='similar'>和任务驱动型对话系统</em>(</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>第2章研究现状与相关工作⁞近些年,旨在使用户能以自然简洁的方式与机器进行交互获取信息服务的对话系统引起了研究人员和科技巨头的广泛关注PM]<em class='similar'>。对话系统的研究经历了半个多世纪的发展,</em>取得了不少的进展。<em class='similar'>现有的对话系统主要可分为闲聊型</em><em class='similar'>(Chatbot)</em><em class='similar'>和任务型对话系统</em>(Task-oriented Dialogue System)两大类口习。另外,知识的使用作为对话系统中的关键一环,对前述两大类对话系统都至关重要。此外,按照对话系统在进行回复时考虑的轮数进行区分,可以将对话系统分为单轮对话系统和多轮对话系统。单轮对话系统简化对话回复任务,只考虑最近一轮的用户输入,而不考虑历史对话信息。多轮对话系统需要综合考虑包括用户输入和系统回复在内的所有对话历史,是更复杂但符合</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 赵新颜-《基于深度学习的对话系统研究与应用》-2022 （是否引证：是）</div>
						<p class="paragraph"><strong>2.</strong>但是当前的对话系统中仍然有很多需要完善的地方,现有的对话系统还不够那么&quot;智能&quot;,对话系统中的意图分类则是对话系统中的重要研究问题之一。<em class='similar'>根据对话系统的不同应用场景可以将对话系统分为闲聊式的对话系统</em><em class='similar'>(chatbot)</em><em class='similar'>和任务型导向的对话系统</em>(task-orientated dialogue system)。闲聊式对话系统的只要可以一直和用户交流就可以,它的实际目的就是用户陪伴。任务型导向的对话指特定条件下提供信息或服务的对话。通常情况下是为了满足用户明</p>
	                    <div class="textFrom">——网页 -《基于深度学习的对话领域意图分类方法研究 - 豆丁网》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>入外部情感信息并针对源语句和目标语句中情感的匹配性进行算法优化和改进具⁞有非常重要的理论和实践意义。⁞1.2国内外研究现状⁞按照功能来分,<em class='similar'>人机对话系统主要分为两类:</em><em class='similar'>&quot;任务驱动型对话系统&quot;</em>(Task-⁞driven Dialogue System)和&quot;开放域对话系统&quot;(或称为 Chatbot 和&quot;聊天机器人&quot;⁞等)。任务驱动型对话系统的主要用途在于辅助用户完成特定的任务,例如:预定机⁞票,查找商品,预定餐厅等,</p>
	                    <div class="textFrom">——华中师范大学硕士论文 刘磊-《基于PAD情感状态模型的对话生成研究》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>互联网中产生了海量对话相关数据,基于数据驱动的对话系统逐渐成为了研究和开发的主流方法。根据任务目标的不同,对话系统可以分为两大类:任务驱动型对话系统( task-oriented dialogue system)<em class='similar'>和非任务驱动型对话系统</em>( non-task-orienteddialogue system),或称限定域对话系统和开放域对话系统[4]。非任务型对话系统又被称为聊天机器人,该类系统通常以与用户进行多轮闲聊为主要目标;</p>
	                    <div class="textFrom">——西北师范大学硕士论文 于沛霖-《基于深度学习的口语理解技术研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>Task-oriented Dialogue System)</em>两类[39]。<em class='similar'>此外,</em><em class='similar'>按照对话系统回复时需考虑的轮数还可以将其分为单轮对话系统和多轮对话系统。</em>值得注意的是,<em class='similar'>不管是闲聊对话系统还是任务驱动型对话系统都可以考虑单轮或多轮对话,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong><em class='similar'>Task-oriented Dialogue System)</em>两大类口习。另外,知识的使用作为对话系统中的关键一环,对前述两大类对话系统都至关重要。<em class='similar'>此外,</em><em class='similar'>按照对话系统在进行回复时考虑的轮数进行区分,</em><em class='similar'>可以将对话系统分为单轮对话系统和多轮对话系统。</em>单轮对话系统简化对话回复任务,只考虑最近一轮的用户输入,而不考虑历史对话信息。多轮对话系统需要综合考虑包括用户输入和系统回复在内的所有对话历史,是更复杂但符合人类对话逻辑的思路。<em class='similar'>不管是闲聊对话系统还是任务型对话系统在回复时均可以考虑单轮对话或多轮对话,</em>所以本文下面从闲聊对话系统、任务型对话系统和结合知识的对话系统这三个角度对对话系统的研究进行回顾。⁞闲聊对话系统⁞图2.1中文闲聊对话系统小冰的例子,来自四⁞闲聊型对话系统只是对用户的输入产生一</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 赵新颜-《基于深度学习的对话系统研究与应用》-2022 （是否引证：是）</div>
						<p class="paragraph"><strong>2.</strong>首先将其形式化描述为:在历史对话信息背景下,人将无领域限制的话语作为查询(也可称为消息或问题等)输入计算机,计算机返回对应的回复语句(也可称为响应或回答).以场景设置为标准,<em class='similar'>对话系统可以分为单轮对话系统和多轮对话系统.</em>单轮对话系统将对话问题简化,只考虑找到给定查询的回复.多轮对话系统需要综合考虑对话上下文(包括历史对话信息和查询),建立对话的长期依赖关系,给出更加符合对话逻辑的回复.</p>
	                    <div class="textFrom">——网页 -《基于深度学习的开放领域对话系统研究综述》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>但是当前的对话系统中仍然有很多需要完善的地方,现有的对话系统还不够那么&quot;智能&quot;,对话系统中的意图分类则是对话系统中的重要研究问题之一。<em class='similar'>根据对话系统的不同应用场景可以将对话系统分为闲聊式的对话系统</em>(chatbot)和任务型导向的对话系统<em class='similar'>(task-orientated dialogue system)</em>。闲聊式对话系统的只要可以一直和用户交流就可以,它的实际目的就是用户陪伴。任务型导向的对话指特定条件下提供信息或服务的对话。通常情况下是为了满足用户明</p>
	                    <div class="textFrom">——网页 -《基于深度学习的对话领域意图分类方法研究 - 豆丁网》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>互联网中产生了海量对话相关数据,基于数据驱动的对话系统逐渐成为了研究和开发的主流方法。根据任务目标的不同,<em class='similar'>对话系统可以分为两大类:</em><em class='similar'>任务驱动型对话系统</em><em class='similar'>( task-oriented dialogue system)</em>和非任务驱动型对话系统( non-task-orienteddialogue system),或称限定域对话系统和开放域对话系统[4]。非任务型对话系统又被称为聊天机器人,该类系统通常以与用户进行多轮闲聊为主要目标;</p>
	                    <div class="textFrom">——西北师范大学硕士论文 于沛霖-《基于深度学习的口语理解技术研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>力,<em class='similar'>而且限制了对话系统的扩展应用。</em><em class='similar'>近年来,</em><em class='similar'>研究人员热衷于研究基于深度学习的对话系统,</em><em class='similar'>其通过学习特征的高维表示来缓解这些问题。</em><em class='similar'>目前</em>,<em class='similar'>基于深度学习的任务型对话系统有两种方法:</em><em class='similar'>流水线</em><em class='similar'>(Pipeline)</em><em class='similar'>方法端到端</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>则来表示状态和动作空间、意图检测和槽填充。这不仅使得对话系统的部署既耗时又昂贵,<em class='similar'>而且还限制了任务型对话系统无法扩展到更多的领域。</em><em class='similar'>⁞近年来,</em><em class='similar'>许多基于深度学习的对话系统被开发出来。</em><em class='similar'>基于深度学习的对话系统通过学习特征的高维表示的方式来缓解这些问题,</em>并在取得了显著的效果。如图2.2所示,一般来说,<em class='similar'>基于深度学习的任务型对话系统有两种主要方法:</em>(1)<em class='similar'>流水线方法和</em>(2)<em class='similar'>端到端方法</em>(End-to-End)。下面分别对两大类方法展开介绍。⁞流水线方法通常包括自然语言理解(Nature language understanding)&gt;对话状态追踪(Dialogue state tracking)&gt;对话管理(</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 赵新颜-《基于深度学习的对话系统研究与应用》-2022 （是否引证：是）</div>
						<p class="paragraph"><strong>2.</strong>意图识别槽填充⁞对话管理(DM)⁞对话状态⁞跟踪(DST)⁞对话策略⁞(DP)⁞外部知识库⁞(Knowledge Base)⁞自然语言生成(NLG)⁞核心模块⁞图1-1任务型对话流水线框架⁞<em class='similar'>目前</em>,<em class='similar'>任务型的对话系统主流研究方法通常包括流水线</em><em class='similar'>(pipeline)</em><em class='similar'>方法和整体端到端</em>(End to End)方法[12]。<em class='similar'>基于流水线的对话系统如图1-1所示,</em>主要包括三大部分,分别为语言理解(NLU),对话管理(DM)和自然语言生成(NLG),除此之外,还有外部知识库进行数据支撑。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 司志博文-《任务型对话中少样本意图分析研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>.本文首先回顾了人机对话系统的发展历程,介绍了人机对话系统的两种类型,任务型对话系统和非任务型对话系统.其次,本文从理论模型、研究进展、<em class='similar'>可用性及存在的问题与挑战等角度深度剖析了任务型对话系统的两种方法,</em>即管道方法和端到端方法.重点分析深度学习技术和强化学习技术中具有代表性的前沿算法,并与传统方法进行对比.最后,对任务型人机对话系统目前的评估方法和存在的问题进行总结,并展望了任务型对话系</p>
	                    <div class="textFrom">——《计算机学报》 赵阳洋；王振宇；王佩；杨添；张睿；尹凯-《任务型对话系统研究综述》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>自然语言理解</em><em class='similar'>(NLU)、</em><em class='similar'>对话状态跟踪</em><em class='similar'>(Dialogue State Tracking,</em><em class='similar'>DST)、</em><em class='similar'>对话策略学习</em><em class='similar'>(Dialogue Policy Learning,</em><em class='similar'>DPL)、</em><em class='similar'>自然语言生成</em><em class='similar'>(Nature Language Generation,</em><em class='similar'>NLG)、</em>语音合成(Text-to-Speech,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>类似任务型对话的框架来实现,而任务型对话任务在框架中算作一个特殊的对话技能。对话系统框架主要由四个模块组成:<em class='similar'>自然语言理解</em>(Natural Language Un-⁞derstanding,<em class='similar'>NLU)、</em><em class='similar'>对话状态跟踪</em><em class='similar'>(Dialogue State tracking,</em><em class='similar'>DST)、</em><em class='similar'>对话策略学习⁞</em><em class='similar'>(Dialogue Policy Learning,</em><em class='similar'>DPL)</em><em class='similar'>和自然语言生成</em>(Natural Language Generation,<em class='similar'>⁞NLG)。</em>通常,在一轮完整的人机交互话中,系统会逐个执行四个模块。自然语言理解模块解析用户输入的自然语言,识别为计算机可处理的数据。</p>
	                    <div class="textFrom">——南京大学硕士论文 毕胜-《面向开放域对话系统的多样性回复研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>每个模块负责处理特定的任务,并将结果作为下一模块的输入。如图1.1所示,基于管道方法的任务型对话系统主要由四个模块组成:<em class='similar'>自然语言理解</em>(Natural Language Understanding,<em class='similar'> NLU)、</em><em class='similar'>对话状态跟踪</em><em class='similar'>(Dialogue state tracking,</em><em class='similar'>DST)、</em><em class='similar'>对话策略学习</em><em class='similar'>(Dialogue Policy Learning,</em><em class='similar'> DPL)</em><em class='similar'>和自然语言生成</em>(Natural Language Generation,<em class='similar'> NLG)。</em>通常,用户与系统完成一轮完整的对话需要依次执行这四个模块。</p>
	                    <div class="textFrom">——合肥工业大学硕士论文 虞兵-《基于序列学习的任务型对话系统模型研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>包含四个主要模块:<em class='similar'>自然语言理解</em>(Natural Language Understanding,<em class='similar'>NLU)、</em><em class='similar'>对话状态追踪</em><em class='similar'>(Dialogue State Tracking,</em><em class='similar'>DST)、</em><em class='similar'>对话策略学习</em><em class='similar'>(Dialogue Policy Learning,</em><em class='similar'>DPL)、</em><em class='similar'>自然语言生成</em>(Natural Language Generation,<em class='similar'>NLG)。</em>这种构建方式容易实现,可解释性强,但模块之间误差会逐层积累,又因各模块之间相互独立导致无法联合调优。End-to-end即基于深度学习的端到端系统,</p>
	                    <div class="textFrom">——工程(英文) 王艳秋；管浩言；张彤-《聊天机器人的分类标准和评估标准综述》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>分模块串行处理对话任务,每一个模块负责特定的任务,并将结果传递给下一个模块,通常由NLU(Natural Language Unde⁞rs⁞tanding,<em class='similar'>自然语言理解)</em>、DST(⁞Dialog⁞ue State Tracking,<em class='similar'>对话状态追踪)</em><em class='similar'>、DPL(</em><em class='similar'>Dialogue Policy Learning,</em><em class='similar'>对话策略学习)</em><em class='similar'>、NLG(</em>Natural Language Genera⁞ti⁞on,<em class='similar'>自然语言生成)</em>4个部分构成。在具体的实现上,可以针对任一模块采用基于规则的人工设计方式,或者基于数据驱动的模型方式。</p>
	                    <div class="textFrom">——网页 -《结合NLU在面向任务的对话系统中的具体应用进行介绍-电子发烧友网》- （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>因此任务型对话系统设计更加复杂,任务型对话系统⁞整体框架包括自然语言理解(Nature language understanding,<em class='similar'>NLU)、</em><em class='similar'>对话状态跟⁞踪</em><em class='similar'>(Dialogue state tracking,</em><em class='similar'>DST)、</em><em class='similar'>策略学习</em><em class='similar'>(Policy learning,</em>DP)、<em class='similar'>自然语言生成⁞</em><em class='similar'>(Nature language generation,</em><em class='similar'>NLG)</em>等模块。⁞对话上下文编码技术广泛应用于各种不同类型的对话系统中。任务型对话系⁞统中的 NLU、<em class='similar'>DST、</em>DP、<em class='similar'>NLG,</em></p>
	                    <div class="textFrom">——浙江大学硕士论文 白宇-《基于Transformer的对话系统模型设计与压缩方法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>使用不同类型的神经网络进行各种拓扑组合,</em><em class='similar'>从而提升模型的各种性能。</em><em class='similar'>鉴于此,</em>在介绍常见的ASR和NLU建模方法之前,<em class='similar'>本节先介绍在其中常用的前馈神经网络、</em><em class='similar'>卷积神经网络和循环神经网络及其变种。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>幅简化的声学模型建模流程。现代的&quot;编码器—解码器&quot;结构甚至能够在不需要发音字典的情况下,将声学模型和语言简化为一个融合模型。端到端方法的一个主要特征是使用庞大而复杂的神经网络,<em class='similar'>对不同类型的神经网络进行各种拓扑组合来提升模型的识别性能。</em><em class='similar'>鉴于此,</em><em class='similar'>本节介绍在端到端语音识别方法中常用的前馈神经网络、</em><em class='similar'>卷积神经网络以及循环神经网络与其变种。</em>⁞2.2.1前馈神经网络⁞前馈神经网络(Feedforward Neural Network, FNN)[41]是最简单的神经网络之一,也是卷积神经网络和循环神经网络的基本构成。一个典型的三层前馈神经网络结构如图2.2所示。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>并在当年的各项图像任务中取得了第一⁞名的成绩[49]。目前的深度学习使用的神经网络主要分为前馈神经网络、<em class='similar'>卷积神经⁞网络、</em><em class='similar'>循环神经网络三种,</em><em class='similar'>本节主要对前馈神经网络和卷积神经网络进行介绍。</em>⁞2.4.1前馈神经网络⁞前馈神经网络实际就是多层感知机。一般是由输入层、隐藏层、输出层组成,⁞每层均由若干个神经元组成。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 陈康-《基于深度强化学习的小行星探测器跳跃轨迹规划研究》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>PyTorch是一个较新的、容易上手的深度学习开源框架,目前已得到广泛应用。本书从PyTorCh框架结构出发,通过案例主要介绍了线性回归、逻辑回归、<em class='similar'>前馈神经网络、</em><em class='similar'>卷积神经网络、</em><em class='similar'>循环神经网络、</em>自编码模型、以及生成对抗网络。本书作为深度学习的入门教材,省略了大量的数学模型推导,适合深度学习初学者,人工智能领域的从业者,以及深度学习感兴趣的人阅读。</p>
	                    <div class="textFrom">——北京：电子工业出版社,2018.08 邢梦来，王硕，孙洋洋编著-《深度学习框架PyTorch快速开发与实战》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>⁞后续相关工作[49]将置换排列的复杂度从𝑆!降低到为了线性复杂度𝑆。⁞2.3本章小结⁞在本章中,首先介绍了深度神经网络的理论基础以及几种常见的深度神经网络结构,<em class='similar'>包括前馈神经网络、</em><em class='similar'>循环神经网络、</em><em class='similar'>卷积神经网络以及它们的变种,</em>并介绍了深度神经网络的优化方式。随后介绍了基于深度神经网络的几种语音分离的方法,包括时频遮掩方法和深度分割聚类的方法。最后,介绍了基于深度神经⁞</p>
	                    <div class="textFrom">——上海交通大学硕士论文 李晨达-《基于音视频双模态信息融合的语音分离研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>这一领域的研究者通常被称为「联结主义者(Connectionist)」,因为这种模型模拟了人脑的功能。神经网络模型通常是通过反向传播算法应用梯度下降训练的。目前神经网络有两大主要类型,<em class='similar'>它们都是前馈神经网络:</em><em class='similar'>卷积神经网络</em><em class='similar'>(CNN)</em><em class='similar'>和循环神经网络</em><em class='similar'>(RNN),</em>其中 RNN 又包含长短期记忆(LSTM)、门控循环单元(GRU)等等。深度学习是一种主要应用于神经网络帮助其取得更好结果的技术。尽管神经网络主要用于监督学习,</p>
	                    <div class="textFrom">——网页 -《30年前的“CNN梦”在这颗芯片落地，能效比高出Tesla10倍 | 机器之心》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>前馈神经网络</em><em class='similar'>(Feedforward Neural Network,</em><em class='similar'>FNN)[43]</em><em class='similar'>是最简单的神经网络之一,</em><em class='similar'>同时也是卷积神经网络和循环神经网络的基本组成单元。</em><em class='similar'>以经典的三层前馈神经网络为例,</em><em class='similar'>其结构如图2-2所示。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对不同类型的神经网络进行各种拓扑组合来提升模型的识别性能。鉴于此,本节介绍在端到端语音识别方法中常用的前馈神经网络、卷积神经网络以及循环神经网络与其变种。⁞2.2.1<em class='similar'>前馈神经网络⁞前馈神经网络</em><em class='similar'>(Feedforward Neural Network,</em> FNN)[41]<em class='similar'>是最简单的神经网络之一,</em><em class='similar'>也是卷积神经网络和循环神经网络的基本构成。</em><em class='similar'>一个典型的三层前馈神经网络结构如图2.2所示。</em><em class='similar'>在前馈神经网络中,</em>数量众多的神经元按层组织,前一层的每个神经元会向下一层所有与之相连接的神经元传输信号。由于前层所有神经元和下层所有神经元都是&quot;全连接&quot;的,因此前馈神经网络也被称为全连接神经网络。在该网络中,第一层通常也被称为输入层,最后一层被称为输出层。⁞⁞图2.2一个简单三层前馈神经网络⁞前馈神经网络通过式(2.4)进行信息的前向传播。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>对论文涉及到的相关算法和技术进行说明,<em class='similar'>主要介绍循环神经网络、</em><em class='similar'>卷积神⁞经网络以及 Stacking 集成策略的相关概念和理论基础。</em><em class='similar'>⁞2.1神经网络算法⁞</em>2.1.1<em class='similar'>前馈神经网络⁞前馈神经网络</em><em class='similar'>(Feedforward Neural Network,</em><em class='similar'>FNN)</em><em class='similar'>是一种最简单的神经网络,</em>各神经元分层排列。其每个神经元只与前一层的神经元相连,接收前一层的输出,并输出给下一层,各层间没有反馈。它定义了从输入 Input 到输出 Output </p>
	                    <div class="textFrom">——内蒙古工业大学硕士论文 张唯铭-《循环神经网络在内蒙古地区沙尘暴预测中的应用研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>tanh函⁞数、Relu函数等。⁞9⁞北京邮电大学工学硕士学位论文⁞23.2前馈神经网络⁞前馈神经网络(Feed Forward Neural Network)<em class='similar'>是一种最简单的神经网络结⁞构。</em><em class='similar'>常用的三层前馈神经网络的结构如图2-2所示:</em>⁞桑⁞输入层隐藏层输出层⁞图2-2三层前馈神经网络⁞如图2-2所示,<em class='similar'>一般的前馈神经网络由输入层、</em>隐藏层和输出层构成。每一⁞层都是由1个或多个神经元组成。</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 李争-《基于神经网络的古诗词自动生成研究》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>给定一组神经元,我们可以以神经元为节点来构建一个网络。不同的神经网络模型有着不同网络连接的拓扑结构。一种比较直接的拓扑结构是前馈网络。<em class='similar'>前馈神经网络</em><em class='similar'>(Feedforward Neural Network,</em><em class='similar'>FNN)</em><em class='similar'>是最早发明的简单人工神经网络。</em><em class='similar'>⁞在前馈神经网络中,</em><em class='similar'>各神经元分别属于不同的层。</em>每一层的神经元可以接收前一层神经元的信号,并产生信号输出到下一层。</p>
	                    <div class="textFrom">——网页 -《第四章 前馈神经网络_Avery123123的博客-CSDN博客》- （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>经网络模型已被广泛使用。其中,前馈神经网络就是一种已经被证明有相当强大的机器学习能力,并且在实践中取得广泛应用的神经⁞网络模型。<em class='similar'>⁞2.2前馈神经网络⁞前馈神经网络</em><em class='similar'>(Feedforward Neural Network,</em><em class='similar'>FNN)</em><em class='similar'>是结构最简单的一种神经网络,</em>采用单向多层结构,其中每一层都包含若干感知机(Perceptron)作为神经⁞元,因此也可以称其为多层感知机(Multi-layer perceptron,MLP)。⁞2.2.</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 詹鹏基-《基于边缘计算的交通目标检测与识别》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>其中输入层包含8个节点,输出层包含2个节点,2个隐含层分别包含3个和2个节点,各层节点之间采用全连接方式。请给出该神经网络的拓扑结构图。<em class='similar'>前馈神经网络⁞前馈神经网络</em><em class='similar'>(FeedfOrWard Neural NetWork,</em><em class='similar'> FNN)</em>是一种最基本的人工神经网络模型,其结构简单、易于实现,是目前应用最为广泛的一类神经网络。感知器(PerCePtron)<em class='similar'>是最简单的前馈神经网络,</em>其在模式识别、函数拟合、</p>
	                    <div class="textFrom">—— 韩敏编著-《人工神经网络基础》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>所有神经元按层组织排列,</em><em class='similar'>第一层称为输入层,</em><em class='similar'>中间层称为隐藏层,</em><em class='similar'>最后一层称为输出层。</em><em class='similar'>前一层的每个神经元会向后一层所有与之相连接的神经元传输信号。</em><em class='similar'>由于前、</em><em class='similar'>后层的神经元都是&quot;全连接&quot;的,</em><em class='similar'>故前馈神经网络也称为全连接神经网络。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对不同类型的神经网络进行各种拓扑组合来提升模型的识别性能。鉴于此,本节介绍在端到端语音识别方法中常用的前馈神经网络、卷积神经网络以及循环神经网络与其变种。⁞2.2.1前馈神经网络⁞前馈神经网络(Feedforward Neural Network, FNN)[41]是最简单的神经网络之一,也是卷积神经网络和循环神经网络的基本构成。一个典型的三层前馈神经网络结构如图2.2所示。在前馈神经网络中,<em class='similar'>数量众多的神经元按层组织,</em><em class='similar'>前一层的每个神经元会向下一层所有与之相连接的神经元传输信号。</em><em class='similar'>由于前层所有神经元和下层所有神经元都是&quot;全连接&quot;的,</em><em class='similar'>因此前馈神经网络也被称为全连接神经网络。</em>在该网络中,<em class='similar'>第一层通常也被称为输入层,</em><em class='similar'>最后一层被称为输出层。</em>⁞⁞图2.2一个简单三层前馈神经网络⁞前馈神经网络通过式(2.4)进行信息的前向传播。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong><em class='similar'>需要先了解一下神经网络。</em><em class='similar'>神经网络,</em>顾名思义,与人类⁞大脑的神经网络类似,由神经网络层组成,每一个神经网络层又由不同的单元组成。⁞在组成神经网络的这些神经网络层中,<em class='similar'>第一层称为输入层,</em><em class='similar'>中间层称为隐藏层,</em><em class='similar'>最⁞后一层称为输出层。</em>在BP神经网络中,只有相邻的各神经层的单元间有联系,也⁞就是说,<em class='similar'>相邻神经层之间的神经元是全连接的,</em>而每个神经层内部的神经元之间是⁞没有连接的。</p>
	                    <div class="textFrom">——兰州大学硕士论文 苏春晶-《分类方法在钓鱼网站数据鉴别中的应用》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong><em class='similar'>层与层之间的神经元⁞全连接,</em>层内无连接,<em class='similar'>也没有跨层的连接。</em><em class='similar'>通常称这样的网络为前馈神经网络,</em>⁞其中第一层为输入层用于接收网络的输入,该层并不由神经元构成只是形象的称⁞为输入层;<em class='similar'>中间层是由许多神经元排列组成称为隐藏层,</em><em class='similar'>最后一层为输出层,</em>对⁞于多分类任务而言输出层的激活函数会选择softmax,此时又称为softmax层。前⁞馈神经网络层与层之间存在大量的连接,这些连接代表着不同的权值,</p>
	                    <div class="textFrom">——北京交通大学硕士论文 梅俊杰-《基于卷积神经网络的语音识别研究》-2017 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>2.3.1前向网络⁞前向网络即前馈型神经网络。网络可分为无数层,每一层按信号的传输先后顺序顺次⁞排列,<em class='similar'>下一层的神经元只接受来自上一层神经元传递的信号,</em>而每个神经元之间没有反馈⁞信号。其结构图如图2-2所示,<em class='similar'>每-层的神经元都顺次的排列着,</em><em class='similar'>其中第一层为输入层、</em><em class='similar'>⁞中间的隐层以及最后一层为输出层神经元丨321。</em>⁞7⁞吉林农业大学硕士学位论文堆十BP神经M络PID控制的温室环境控制系统的仿真研究⁞</p>
	                    <div class="textFrom">——吉林农业大学硕士论文 涂川川-《基于BP神经网络PID控制的温室环境控制系统的仿真研究》-2012 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>网络神经网络[14]由于其在信息处理中具有非线性的自适应能力,已经在人工智能领域中取得了广泛的应用。算法通过具有三层结构的前向神经网络模型[15]来得到样本的标记集合,每层由不同的神经元组成,<em class='similar'>第一层叫输入层,</em><em class='similar'>中间层叫隐藏层,</em><em class='similar'>最后一层叫输出层。</em>在每一层中的每个神经元都连接着下一层的所有神经元,<em class='similar'>但在同一层中的神经之间是没有连接的,</em>当信息从一层传到下一层时,前层中的每个神经元都会有一个激活函数对⁞</p>
	                    <div class="textFrom">——网页 -《基于主题模型的多示例多标记学习方法.doc》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>式中,表示当前层数;<em class='similar'>表示第层神经元的输出向量;</em><em class='similar'>表示第层到第层的权重矩阵;</em><em class='similar'>表示第层神经元的激活函数;</em><em class='similar'>表示第层的偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>即使不按照243节的公式推导,也可以进一步理解反向传播算法的代码实现。⁞BP算法推导⁞(1)符号说明,⁞nl:表示网络的层数,仏为输入层,々为输出层。⁞5:<em class='similar'>表示第/层网络神经元的个数。</em>⁞/:<em class='similar'>表示神经元的激活函数。</em>⁞W(<em class='similar'>J表示第/层到第/+1层的权重矩阵,</em>其中w[wR表示从/层的第i个神经元到第7+1层第j个神经元之间的权重。⁞心:<em class='similar'>表示第/层的偏置向量,</em>其中叱)表示/层第,个神经元的偏置。⁞严:<em class='similar'>表示第/层的输入向量,</em>其中Z,为/层第,个神经元的输入。⁞。⑴:<em class='similar'>表示第/层的输出向量,</em>其中。,为/层第,个神经元的输出。⁞虽然上述符号定义有些琐碎,需要点时间去了解,但是对于后面的公式推导却起着很重要的作用。其中,/一般代表第/层神经网络,</p>
	                    <div class="textFrom">—— 陈仲铭，彭凌西著-《人民邮电  深度学习原理与实践》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>将⁞⁞7⁞⁞上一层的神经元激活值通过加权求和的方式结合起来,与偏置项相加,然后通过激活函数再进行计算。公式如下:()=(()∙()+)(2.1)其中()<em class='similar'>表示第层的输出向量,</em>()表示第−1层的输出向量。()<em class='similar'>表示第−1层神经元连接到第层神经元的权重矩阵,</em><em class='similar'>表示第层的偏置,</em>(∙)<em class='similar'>表示激活函数。</em>某一层的激活函数根据数据和任务的特征以及训练过程中的需要进行⁞选择,常见的激活函数如 ReLU 和 tanh。⁞当神经网络中网络的深度过深时,</p>
	                    <div class="textFrom">——华侨大学硕士论文 宋丹-《基于卷积神经网络的宫颈病变图像分类方法研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>并映射成两个低维的语义相关的特征向量。⁞最后根据余弦距离来计算用户与视频的相关性大小,以此作为推荐的评分依据。⁞此网络的具体描述如下:假设用表示输入向量,<em class='similar'>表示输出向量,</em><em class='similar'>表示神经⁞网络中的隐含层表示网络中第层的权重矩阵,</em><em class='similar'>表示第层⁞的偏置。</em>则有以下公式:⁞(3-4)⁞(3-5)⁞(3-6)⁞其中,<em class='similar'>表示激活函数,</em>在本文中用作为隐藏层和输出层的激活函数。</p>
	                    <div class="textFrom">——深圳大学硕士论文 高睿-《基于深度神经网络的视频个性化推荐系统研究》-2017 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>这样对于目标函数的拟合也越好,下图为 DNN 网络的示意图:输入层隐藏层1隐藏层v 输出层图2.3 DNN 网络我们用以下图标表示 DNN 的结构:(layer):神经网络的层数;:第层神经网络的个数:<em class='similar'>第层神经元的激活函数:</em><em class='similar'>第层到第层的权重矩阵;</em>:层到第层的偏置:<em class='similar'>层神经元的净输入:</em>层神经元的输出 DNN 属于前馈神经网络,网络中信息是从前到后进行传播。第层神经元的输入由第层神经元的输出决定,</p>
	                    <div class="textFrom">——网页 -《分布式协作神经网络中的隐私保护研究》- （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>前向传播公式如式(4.5)所示:⁞第一层⁞第二层⁞第三层⁞图4.15前向传播过程⁞Fig.4.15 Forward dissemination process ⁞(4.5)<em class='similar'>⁞其中代表层数,</em><em class='similar'>代表第层神经元,</em><em class='similar'>代表第层</em>神经元,为偏置,为激活函数的输出。⁞反向传播是指通过输出与理想结果的差异从后逐渐反馈到前面,从而对权值更新的⁞一个过程。所图4.16所示为反向传播过程,公式如式(4.6)所示:⁞</p>
	                    <div class="textFrom">——大连理工大学硕士论文 黄云奎-《基于POCT的宫颈癌细胞图像识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>对神经网络进行训练就是通过一些特定的算法不断更新网络参数和,</em>使得其</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>层数⁞——层到层的权重矩阵⁞——层的偏置向量⁞——层神经元的输出向量⁞——层神经元的激活函数⁞通过引入更多层数,前馈神经网络能对&quot;输入—输出&quot;之间的依赖关系进行更好的建模。<em class='similar'>对神经网络进行训练本质上就是通过特定算法不断更新一系列网络参数和,</em>使得网络在某一组参数配置下对于输入的拟合能力达到最优。目前最为常见的参数更新算法是反向传播(Back Propagation, BP)算法[42]。BP算法根据网络输出结果与参考结果的偏差得到损失函</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_4" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">81.4%(1,012字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://www.docin.com/p%2D934092221.html" target="_blank">离散卷积在图像处理中的应用</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(63字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.doc88.com/p%2D9894810472515.html" target="_blank">改进的文本主题表示及学习方法</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(53字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图卷积和LSTM网络的行人通行意图预测方法" target="_blank">基于图卷积和LSTM网络的行人通行意图预测方法</a></span>
                      <p>许晓君 -
                        《大连理工大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://www.doc88.com/p%2D59999031841827.html" target="_blank">基于CEEMDAN_LSTM的股票市场指数预测建模研究_贺毅岳</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202010322789.html" target="_blank">一种面向无线电信号识别对抗攻击的防御方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的人体姿态估计及预测算法研究" target="_blank">基于深度学习的人体姿态估计及预测算法研究</a></span>
                      <p>刘亚欣 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="https://www.doc88.com/p%2D35229061470879.html" target="_blank">基于深度迁移学习的跨领域细粒度情感分析 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于集成学习的跨数据域文本倾向性分析研究" target="_blank">基于集成学习的跨数据域文本倾向性分析研究</a></span>
                      <p>么素素 -
                        《天津大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的离线手写签名真伪识别方法" target="_blank">基于深度学习的离线手写签名真伪识别方法</a></span>
                      <p>胥玉龙;张永梅;滑瑞敏 -
                        《电脑知识与技术
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110806287.html" target="_blank">基于AdaptGAN的低照度语义分割方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(41字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于LIC矢量场可视化算法的研究" target="_blank">基于LIC矢量场可视化算法的研究</a></span>
                      <p>余永胜 -
                        《江南大学硕士论文
                        》- 2007 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于LSTM循环神经网络的横波预测方法" target="_blank">基于LSTM循环神经网络的横波预测方法</a></span>
                      <p>周恒;武中原;张欣;张春雷;马乔雨 -
                        《断块油气田
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向餐饮系统的用户评论文本分类算法的研究与实现" target="_blank">面向餐饮系统的用户评论文本分类算法的研究与实现</a></span>
                      <p>刘逸 -
                        《西安电子科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="https://blog.51cto.com/u_15127603/3452207" target="_blank">卷积神经网络若干概念理解【图文】_mob604756f6b718_51CTO博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的图像超分辨率重建算法研究" target="_blank">基于深度学习的图像超分辨率重建算法研究</a></span>
                      <p>周杨浩 -
                        《南京大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习在医疗领域的中文命名实体识别" target="_blank">基于深度学习在医疗领域的中文命名实体识别</a></span>
                      <p>罗俊宇 -
                        《广东工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110134629.html" target="_blank">动作识别方法、装置、设备以及存储介质与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于卷积神经网络识别子宫肌电信号宫缩的研究" target="_blank">基于卷积神经网络识别子宫肌电信号宫缩的研究</a></span>
                      <p>王莹 -
                        《北京工业大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">20.</strong> <span><a href="http://xueshu.baidu.com/s?wd=一种基于深度学习的中文自然语言查询生成SQL语句技术研究" target="_blank">一种基于深度学习的中文自然语言查询生成SQL语句技术研究</a></span>
                      <p>曹金超 -
                        《浙江大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">21.</strong> <span><a href="http://xueshu.baidu.com/s?wd=局部感知递归神经网络在语言模型中的应用" target="_blank">局部感知递归神经网络在语言模型中的应用</a></span>
                      <p>王刚;刘惠义 -
                        《信息技术
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">22.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的短期电力负荷预测研究" target="_blank">基于深度学习的短期电力负荷预测研究</a></span>
                      <p>麻英杰 -
                        《内蒙古大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">23.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于注意力循环卷积网络的关系提取研究" target="_blank">基于注意力循环卷积网络的关系提取研究</a></span>
                      <p>王晓霞 -
                        《江南大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">24.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于EEMD-LSTM的需求响应终端DDoS攻击检测方法" target="_blank">基于EEMD-LSTM的需求响应终端DDoS攻击检测方法</a></span>
                      <p>李彬;魏吟娬;祁兵;孙毅;陈宋宋 -
                        《电力建设
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">25.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于注意力机制与时间卷积的短期电力负荷预测研究" target="_blank">基于注意力机制与时间卷积的短期电力负荷预测研究</a></span>
                      <p>周朝勉 -
                        《南昌大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">26.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能运维与健康管理" target="_blank">智能运维与健康管理</a></span>
                      <p>陈雪峰，訾艳阳 -
                        《北京：机械工业出版社,2018.11
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">27.</strong> <span><a href="http://xueshu.baidu.com/s?wd=双向单排配筋带洞口混凝土剪力墙抗震性能试验与分析" target="_blank">双向单排配筋带洞口混凝土剪力墙抗震性能试验与分析</a></span>
                      <p>孙超 -
                        《北京工业大学硕士论文
                        》- 2008 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">28.</strong> <span><a href="http://m.toutiao.com/i6650259921331814915/" target="_blank">循环神经网络（RNN）和LSTM初学者指南</a></span>
                      <p>AI先锋号 -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">29.</strong> <span><a href="http://xueshu.baidu.com/s?wd=卷积神经网络的结构及发展方向分析" target="_blank">卷积神经网络的结构及发展方向分析</a></span>
                      <p>赵黎[1] -
                        《移动信息
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_4" class="simMore"><a href="javascript:$ShowMore(4);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>在某一组参数配置下对于输入的拟合能力达到最优。</em><em class='similar'>目前最常见的参数更新算法是反向传播</em><em class='similar'>(Back Propagation,</em><em class='similar'>BP)</em><em class='similar'>算法</em>[44]。<em class='similar'>BP 算法首先根据输出结果与参考结果的偏差计算损失函数的值,</em><em class='similar'>然后使用链式法则从输出层往输入层方向逐层求取各参数梯度,</em><em class='similar'>最后将学习率与所求梯度相乘以更新参数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>前馈神经网络能对&quot;输入—输出&quot;之间的依赖关系进行更好的建模。对神经网络进行训练本质上就是通过特定算法不断更新一系列网络参数和,<em class='similar'>使得网络在某一组参数配置下对于输入的拟合能力达到最优。</em><em class='similar'>目前最为常见的参数更新算法是反向传播</em><em class='similar'>(Back Propagation,</em><em class='similar'> BP)</em><em class='similar'>算法</em>[42]。<em class='similar'>BP算法根据网络输出结果与参考结果的偏差得到损失函数的值,</em><em class='similar'>再使用链式法则从输出层方向往输入层方向逐层求取各层参数的梯度,</em><em class='similar'>最后利用学习率与求得梯度的乘积去更新原来的参数。</em>目前,Pytorch、TensorFlow等主流的深度学习框架都包含了自动梯度计算的功能,研究人员只需考虑如何用代码实现相关的网络结构,梯度的计算将交由这些框架自动进</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>研究发现随着网络层数的增加,训练集上的误差和验证集上的误差呈现先⁞减小后增加的现象。目前普遍认为造成这种现象的原因是梯度消失/爆炸导致⁞的训练困难以及冗余层导致的模型退化。<em class='similar'>在使用链式法则求解权重参数的梯度⁞时,</em><em class='similar'>由于计算的方向是从输出层逐层到输入层,</em>浅层权重的梯度会出现很长的⁞连乘项,从而可能引起梯度值过大或者趋近于零的数值计算问题,使得浅层权⁞重无法被很好地调整。此外,假定对于指定的任务网络存在一个最佳的层数⁞</p>
	                    <div class="textFrom">——南京大学硕士论文 周杨浩-《基于深度学习的图像超分辨率重建算法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>卷积神经网络</em>[45]是一种特殊的 FNN,<em class='similar'>具有局部连接和权值共享等特点。</em>相较</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>将其视为一张单通道的二维频谱图。通常把频谱图视为图片并使用卷积神经网络对其进行深层次抽象特征提取。⁞卷积神经网络是一种特殊的前馈神经网络,<em class='similar'>具有局部连接、</em><em class='similar'>权值共享的特点。</em>相较于前馈神经网络,其能以较少的参数量实现局部不变特征的提取。<em class='similar'>卷积神经网络中,</em>卷积层中一个简单的卷积操作如图2.3所示。卷积滤波器又称为卷积核,它是一组可学习权值的集合,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>即把原始特征映射到各个隐语义节点(hidden node)。对于最后一层全连接而言,就是分类的显示表达。⁞3卷积神经网络的结构特点⁞卷积神经网络由多层感知机(MLP)演化,<em class='similar'>具有局部区域连接、</em><em class='similar'>权值共享、</em>降采样的结构特点。⁞3.1局部区域连接⁞局部区域连接的思想来源于视觉神经元的结构。在传统的神经网络结构中,神经元之间呈现全连接状态,即第 n-1层的神经元均与第 n 层的各个神经元连接。</p>
	                    <div class="textFrom">——移动信息 赵黎[1]-《卷积神经网络的结构及发展方向分析》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>和Wiesel的层级模型提出了结构与之类似的神经认知机。随后, LeCUn等人〔闾基于前人的研究基础提出了着名的CNN结构:LeNet-5,奠定了现代CNN的基础。<em class='similar'>⁞CNN具有局部连接、</em><em class='similar'>权值共享、</em>池化操作及多层结构等特点[⑼。局部连接使CNN能够有效地提取局部特征〔⑸;权值共享大大减少了网络的参数数量,降低了网络的训练难度;池化操作在实现数据降维的同时使网络对特征的平移、缩放和扭曲等具有一定的不变性;</p>
	                    <div class="textFrom">——北京：机械工业出版社,2018.11 陈雪峰，訾艳阳-《智能运维与健康管理》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>较少的参数量实现对局部特征的提取,</em><em class='similar'>其中一个简单的卷积操作如图2-3所示。</em><em class='similar'>其中卷积滤波器又称为卷积核,</em><em class='similar'>是一组可学习权值的集合,</em><em class='similar'>主要作用是将输入图像中的一个小区域像素加权平均为输出图像中的每个对应像素。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>卷积神经网络是一种特殊的前馈神经网络,具有局部连接、权值共享的特点。相较于前馈神经网络,<em class='similar'>其能以较少的参数量实现局部不变特征的提取。</em>卷积神经网络中,<em class='similar'>卷积层中一个简单的卷积操作如图2.3所示。</em><em class='similar'>卷积滤波器又称为卷积核,</em><em class='similar'>它是一组可学习权值的集合,</em>可视为参数量较少的一组全连接网络。卷积核通过在图片上按照特定的顺序移动,扫描视野范围内的图片信息进而提取特征。每个卷积核提取得到的特征是尺寸更小的单通道图片,该图片也被称为特征图(Feature </p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(x)的定义域相交的元素进行乘积并且求和,得出新的图像一点,<em class='similar'>就是被卷积后的图像。</em><em class='similar'>模板又称为卷积核。</em>算法描述2.1卷积核的概念卷积是图像处理中常用的方法,给定输入图像,<em class='similar'>输出图像中的每一个像素是输入图像中的一个小区域中像素的加权平均,</em>其中权值由一个函数定义,这个函数称为卷积核。2.2卷积滤波将卷积核矩阵的中心一次放在图像矩阵的每一个像素位置上,将卷积核的每一个元素分别和图像矩阵对应位置</p>
	                    <div class="textFrom">——网页 -《离散卷积在图像处理中的应用》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>Caffenet 模型结构的网络参数有学习率(lr_mult),其中包含两个学习率,分⁞别是 filter 和 bias 的学习率;衰减系数(decay_mult),同样对应学习率有两个;<em class='similar'>⁞输出图像中每一个像素是输入图像中一个小区域中像素的加权平均,</em>其中权值由⁞一个函数定义,<em class='similar'>这个函数称为卷积核;</em><em class='similar'>卷积核个数</em>(num_output),表示经过这一⁞层后输出的特征图个数,</p>
	                    <div class="textFrom">——北京工业大学硕士论文 王莹-《基于卷积神经网络识别子宫肌电信号宫缩的研究》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>使得卷积神经网络参数量大大减少。⁞(二)权值共享⁞卷积神经网络中,对于给定的一个图片作为输入,会用卷积核去滑行扫这个输入图片。卷积核的定义为在进行图像处理时,给定的一个输入图像,<em class='similar'>将此图像中一个局部小区域中的像素进行加权平均后作为输出图像中对应位置的单个像素,</em>其中权值由卷积核进行定义。而卷积核设计的数字就是权重,这些数字不会因为在图像内的位置不同而发生改变,</p>
	                    <div class="textFrom">——大连理工大学硕士论文 许晓君-《基于图卷积和LSTM网络的行人通行意图预测方法》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>1卷积核⁞卷积核就是图像处理时,给定输入图像,<em class='similar'>输入图像中一个小区域中像素加权平均后成为输出图像中的每个对应像素,</em>其中权值由一个函数定义(或自定义),这个函数称为卷积核。如下图中间部分所示。⁞2特征图⁞经过卷积核运算之后的图成为特征图⁞</p>
	                    <div class="textFrom">——网页 -《卷积神经网络若干概念理解【图文】_mob604756f6b718_51CTO博客》- （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>度和图像的质量两个方面加以改进的。⁞18⁞第四章加速的线积分卷积技术⁞4.1快速的线积分卷积方法⁞LIC方法使用图像卷积来合成反映流线的纹理。卷积是图像处理常用的方法,给定输入图像,<em class='similar'>在输出⁞图像中每一个像素是输入图像中一个小区域中像素的加权平均,</em>其中权值由一个函数定义,这个函数称为⁞卷积核。LIC方法对定义在网格上的速度数据进行处理,输出图像中每一个像素对应一个网格。算法还需⁞</p>
	                    <div class="textFrom">——江南大学硕士论文 余永胜-《基于LIC矢量场可视化算法的研究》-2007 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>首先卷积核在输入图像上按照特定的方向移动,</em><em class='similar'>扫描视野范围内的像素信息进而提取特征。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>卷积层中一个简单的卷积操作如图2.3所示。卷积滤波器又称为卷积核,它是一组可学习权值的集合,可视为参数量较少的一组全连接网络。<em class='similar'>卷积核通过在图片上按照特定的顺序移动,</em><em class='similar'>扫描视野范围内的图片信息进而提取特征。</em>每个卷积核提取得到的特征是尺寸更小的单通道图片,该图片也被称为特征图(Feature Map, FM)。再使用非线性激活函数对每张特征图进行处理,并对得到激活特征图按照顺序进行通道上的堆叠,即可得到卷积操作的输出结果。在卷积神经网络中,在进行卷积操作后,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>每个卷积核提取得到的特征是尺寸更小的单通道图片,</em><em class='similar'>即为特征图;</em><em class='similar'>然后在非线性激活函数的作用下,</em><em class='similar'>对每张特征图进行处理并对得到的激活特征图按顺序进行通道维度上的堆叠,</em><em class='similar'>即可得到最后的输出结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>卷积核通过在图片上按照特定的顺序移动,扫描视野范围内的图片信息进而提取特征。<em class='similar'>每个卷积核提取得到的特征是尺寸更小的单通道图片,</em>该图片也被称为特征图(Feature Map, FM)。<em class='similar'>再使用非线性激活函数对每张特征图进行处理,</em><em class='similar'>并对得到激活特征图按照顺序进行通道上的堆叠,</em><em class='similar'>即可得到卷积操作的输出结果。</em>在卷积神经网络中,在进行卷积操作后,通常还会使用池化操作对特征图进行裁剪,进一步压缩特征图的大小。通过对卷积核数、卷积核尺寸等超参数进行合适的设置,可实现语音信号频谱图时间步压缩以及频域信息的扩展与丰富。⁞2.2.3循环神经网络及其变种⁞循环神经网络RNN[43]是一类用于处理时序相关输入序列的</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>填充为1、输出填充为1,卷积后接着采用批归一化层和relu激活层;[0122]7‑2)将步骤6‑2)<em class='similar'>得到的特征图用卷积层提取特征,</em>卷积层的卷积核大小为5×5、填充为2、输入通道数64、输出通道数为3,<em class='similar'>然后采用tanh激活函数进行非线性激活得到最终的特征图,</em>最后将最终的特征图与步骤4‑2)中3通道的rgb图像逐元素相加,获得光照正则化后的图像。[0123]步骤3)中所述的高分辨率残差网络结构如表1所示,依次设有:[0124]第四卷积块,</p>
	                    <div class="textFrom">——网页 -《基于AdaptGAN的低照度语义分割方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>得到多个多通道特征图,每个视频帧对应于一个多通道特征图,每个通道代表一个维度。99.在一种可能的实施方式中,对于任一视频帧,终端采用多个卷积核对该视频帧进行特征提取,<em class='similar'>得到多个卷积核对应的多个单通道特征图,</em>每个卷积核用于提取一个维度的特征图。终端将多个单通道特征图进行拼接,得到该视频帧的多通道特征图。100.在这种实施方式下,终端能够采用不同的卷积核来提取视频帧不同维度的特征,多个卷积核能够并行运算,</p>
	                    <div class="textFrom">——网页 -《动作识别方法、装置、设备以及存储介质与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>通道特征图和确定的多个第一注意力权重,确定动作的类型。[0232]在一种可能的实施方式中,第一特征提取单元用于,对于任一视频帧,采用多个卷积核对任一视频帧进行特征提取,<em class='similar'>得到多个卷积核分别对应的多个单通道特征图,</em>每个卷积核用于提取一个维度的特征图。将多个单通道特征图进行拼接,得到任一视频帧的多通道特征图。[0233]在一种可能的实施方式中,第一注意力权重确定单元,用于对多个多通道特征图进行降维处理,</p>
	                    <div class="textFrom">——网页 -《动作识别方法、装置、设备以及存储介质与流程》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>通常,<em class='similar'>在进行卷积操作后,</em><em class='similar'>还会使用池化操作对特征图进行裁剪,</em><em class='similar'>进一步压缩特征图大小。</em><em class='similar'>通过对卷积核数、</em><em class='similar'>尺寸等超参数进行合适的设置,</em><em class='similar'>可实现CNN对图像信息特征的扩展与丰富。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>卷积核通过在图片上按照特定的顺序移动,扫描视野范围内的图片信息进而提取特征。每个卷积核提取得到的特征是尺寸更小的单通道图片,该图片也被称为特征图(Feature Map, FM)。再使用非线性激活函数对每张特征图进行处理,并对得到激活特征图按照顺序进行通道上的堆叠,即可得到卷积操作的输出结果。在卷积神经网络中,<em class='similar'>在进行卷积操作后,</em><em class='similar'>通常还会使用池化操作对特征图进行裁剪,</em><em class='similar'>进一步压缩特征图的大小。</em><em class='similar'>通过对卷积核数、</em><em class='similar'>卷积核尺寸等超参数进行合适的设置,</em><em class='similar'>可实现语音信号频谱图时间步压缩以及频域信息的扩展与丰富。</em>⁞2.2.3循环神经网络及其变种⁞循环神经网络RNN[43]是一类用于处理时序相关输入序列的</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>出值。⁞如图5所示,本文采用一个含有两层卷积的神经网络,卷积神经网络对输入的笔迹图像特征进行自动提取,在C1卷积层得到一定数量的特征图(如纹理、几何、灰度等)并通过一个ReLU激活函数得到其非线性特征映射,<em class='similar'>然后对激活后的特征图进行采样操作计算得到池化层 P2,</em>之后再经过C3卷积层得到新的一定数量的特征图,这时先对该特征图进行批量归一化处理(Batch normalization,BN)后,再进行ReLu激活,最后进行⁞</p>
	                    <div class="textFrom">——电脑知识与技术 胥玉龙；张永梅；滑瑞敏-《基于深度学习的离线手写签名真伪识别方法》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>循环神经网络</em>[46]<em class='similar'>是一种处理序列数据或时序数据的递归神经网络,</em><em class='similar'>其网络拓</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>⁞(0)(1)(,)(())Z=f X A softmax Atanh AXW W=(2-4)⁞其中,(0)W 和(1)W 分别是每一层 GCN 中线性变换的参数矩阵。<em class='similar'>⁞2.4循环神经网络及其变体⁞</em>2.4.1<em class='similar'>循环神经网络⁞RNN 是一种专门处理时序数据的递归神经网络,</em>通过建立循环单元之间的通讯,实现对时序数据的传递,从而达到长距离信息的特征学习。这种结构导致 RNN 输入与CNN 不同,</p>
	                    <div class="textFrom">——江南大学硕士论文 王晓霞-《基于注意力循环卷积网络的关系提取研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>深度学习的核心是利用参数庞大的神经网络进行特征提取,典型的深度神经网络有卷积神经网络(cnn)、<em class='similar'>循环神经网络</em>(rnn)和长短期记忆神经网络(lstm)等,卷积神经网络适用于处理图像数据,循环神经网络适用于处理时序数据。长短期记忆神经网络(lstm)<em class='similar'>是一种时间递归神经网络,</em>被广泛地应用于时间序列的处理。随着无线通信技术的发展,无线电波已经成为连通万物的重要载体,无线电信号识别技术最初主要用于军事电子战</p>
	                    <div class="textFrom">——网页 -《一种面向无线电信号识别对抗攻击的防御方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>所以可以通过1DCNN将长时间序列转变成由高维特征组成的短时间序列。然后在其后加入池化层,并将输出特征输入到下一层网络中进行训练。⁞2.2.2循环神经网络⁞循环神经网络又名递归神经网络。<em class='similar'>它是一种专门处理序列数据的神经网络,</em>而且其能够建立历史信息与时间维度之间的关系。对时序问题而言,RNN 在当前时刻所做出的决定会对后续到达该时刻的输入产生影响。⁞</p>
	                    <div class="textFrom">——内蒙古大学硕士论文 麻英杰-《基于深度学习的短期电力负荷预测研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>RNN 的一个主要特点是:</em><em class='similar'>在前一时间步计算得到的隐藏状态会作为当前时间步的输入。</em><em class='similar'>在时间步,</em><em class='similar'>RNN 接收当前时间步的输入和前一时间步的隐藏状态</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>类用于处理时序相关输入序列的递归神经网络,其网络拓扑结构在时间的维度上以递归的形式展开。⁞⁞图2.4循环神经网络示意图及其时域展开形式⁞图2.4展示了经典RNN的主要结构。由图可知,<em class='similar'>RNN的一个主要特点是前一个时间步计算得到网络的隐状态会作为当前时刻网络的输入,</em>进而参与到当前输出的计算过程。<em class='similar'>在时间步,</em><em class='similar'>循环神经网络将接收当前时间步的输入和前一时间步的隐状态,</em>并产生当前时间步的输出,其计算过程如下:⁞(2.5)⁞(2.6)⁞式(2.5)-(2.6)中,——作用于输入的权值矩阵⁞——产生输出的权值矩阵⁞——作用于前一时间步隐状态的权值矩阵⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>随着其应用的范围的增大而更加深入,各种不同的模型相继被开发出来。1.1 RNN递归神经网络(Recurrent Neural Network)是前向神经网络的一个变种,使得它可对序列化的数据建模。<em class='similar'>在每一步前向时间步传播的计算中,</em><em class='similar'>RNN接收输入数据和前一步的隐藏状态,</em>计算出新的隐藏状态并输出对当前数据的预测结果。这种高维度的隐藏状态更新方式,<em class='similar'>使得每一步操作即由之前的状态和当前输入做出下一步数据的预测,</em><em class='similar'>又使得当前隐藏状态得到即时更新,</em></p>
	                    <div class="textFrom">——信息技术 王刚；刘惠义-《局部感知递归神经网络在语言模型中的应用》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>,产生当前时间步的输出,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>RNN的一个主要特点是前一个时间步计算得到网络的隐状态会作为当前时刻网络的输入,进而参与到当前输出的计算过程。在时间步,循环神经网络将接收当前时间步的输入和前一时间步的隐状态,<em class='similar'>并产生当前时间步的输出,</em><em class='similar'>其计算过程如下:</em>⁞(2.5)⁞(2.6)⁞式(2.5)-(2.6)中,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong>上式中,<em class='similar'>为作用于前一时间步隐藏状态的权重矩阵;</em><em class='similar'>为作用于输入的权重矩阵;</em><em class='similar'>为作用于输出的权重矩阵;</em><em class='similar'>和均为非线性激活函数。</em><em class='similar'> RNN 的结构决定了其在处理时序信息上具有天然的优势。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并产生当前时间步的输出,其计算过程如下:⁞(2.5)⁞(2.6)⁞式(2.5)-(2.6)<em class='similar'>中,——作用于输入的权值矩阵⁞——产生输出的权值矩阵⁞——作用于前一时间步隐状态的权值矩阵⁞——非线性激活函数⁞——非线性激活函数⁞由于RNN的结构在处理时序信息上具有天然优势,</em>其对于序列数据的建模能力较为强大。然而,RNN在反向传播的过程中产生的梯度会随着时间的推移被逐渐放大或者衰减。对于那些具有较长时间依赖性的时间序列,梯度放大或衰减程度更加趋近于指数级,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>假设在时刻 t,网络的输入为,隐藏层状态为不仅和当前时刻的输入相关,也和上一个时刻的隐藏状态相关。⁞13(2-10)(2-11)其中为&quot;状态-状态&quot;权重矩阵,<em class='similar'>W 为&quot;状态-输入&quot;权重矩阵,</em><em class='similar'>V 为&quot;状态-输出&quot;权重矩阵,</em>b 为偏置项。<em class='similar'>是非线性激活函数,</em>通常为 logistic 或 tanh 函数。上述所介绍的循环神经网络并不能很好的处理较长的序列,一个主要的原因是,RNN 在训练中存在梯度的问题(梯度爆炸或梯度消失),</p>
	                    <div class="textFrom">——网页 -《基于深度迁移学习的跨领域细粒度情感分析 - 道客巴巴》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong><em class='similar'>ht代表第t个时间步的隐藏状态,</em>是同一个时间步xt的输入函数。W是权重函数,<em class='similar'>用于修正xt。</em><em class='similar'>U是隐藏状态矩阵,</em>也被称为转移矩阵,类似于马尔可夫链。<em class='similar'>ht-1代表t的上一个时间步t-1的隐藏状态。</em><em class='similar'>权重矩阵,</em>是决定当前输入和过去隐藏状态的重要程度的过滤器。它们产生的误差会通过反向传播返回,并用于调整相应的权重,直到误差不再降低。权重输入(Wxt)和隐藏状态(Uht-1)的总和被函数φ压缩,</p>
	                    <div class="textFrom">——网页 AI先锋号-《循环神经网络（RNN）和LSTM初学者指南》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>函数,表示三个门产生的向量内部每个元素范围均⁞在0~1之间; ind⁞t Rx 表示当前时间步长为 t 的向量; indH⁞RU⁞⁞则表示由输入层到隐藏层的权重矩阵;<em class='similar'>上一隐藏状态 ht-1作为当前时间步的输入的权重矩阵表示为⁞HHRW ,</em>b 为偏置项。LSTM 中三个门的计算方式只是参数不同,这些参数在所有⁞步骤共同使用。⁞最终由&quot;候选值计算层&quot;(⁞~⁞tc )经过 tanh 函数处理后与&quot;输出门&quot;的计算结果结⁞</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 刘逸-《面向餐饮系统的用户评论文本分类算法的研究与实现》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>权值共享使得网络在挖掘数据关键信息的过程中不受位置的影响,另一方面权值共享也使得RNN⁞的连接权重矩阵,<em class='similar'>为隐藏单元到输出的权重矩阵,</em>为偏置向量,<em class='similar'>和为非线性激活函数,</em>为输入,为输出。⁞对于RNN神经网络而言,因为计算时刻的输出值需要时刻之前的全部输入都参与计算,所以循环神经网络可以充分利用序列中的所有信息,能够捕获时间相关序列中的关键信息[28]。</p>
	                    <div class="textFrom">——南昌大学硕士论文 周朝勉-《基于注意力机制与时间卷积的短期电力负荷预测研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>RNN 在反向传播过程中产生的梯度会随着时间推移逐渐放大或衰减。</em><em class='similar'>这一现象在RNN处理具有较长时间依赖性的时间序列尤为明显,</em><em class='similar'>其梯度放大或衰减的程度趋近于指数级,</em><em class='similar'>即梯度爆炸和梯度消失。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>——产生输出的权值矩阵⁞——作用于前一时间步隐状态的权值矩阵⁞——非线性激活函数⁞——非线性激活函数⁞由于RNN的结构在处理时序信息上具有天然优势,其对于序列数据的建模能力较为强大。然而,<em class='similar'>RNN在反向传播的过程中产生的梯度会随着时间的推移被逐渐放大或者衰减。</em><em class='similar'>对于那些具有较长时间依赖性的时间序列,</em><em class='similar'>梯度放大或衰减程度更加趋近于指数级,</em>这就是严重影响网络训练的梯度消失和梯度爆炸现象。<em class='similar'>为了缓解梯度消失和梯度爆炸,</em>改善RNN的学习能力,近年来许多研究人员做出了一些改进并取得了不错结果。⁞长短时记忆单元(Long-Short Term Memory, LSTM)[44]是一种改进的RNN,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(2)长短期记忆(long short term memory, LSTM)模型⁞循环神经网络(RNN)不同于传统神经网络,通过引入循环结构使得模型能够⁞具有一定程度的记忆能力,较为适合处理序列格式的文本数据。<em class='similar'>然而 RNN 随着⁞时间推移,</em><em class='similar'>在算法反向传播过程中容易产生梯度消失或梯度爆炸的问题。</em><em class='similar'>同时⁞RNN 网络记忆的信息随着序列的推移衰减,</em>后期输入对模型结果影响较多,不⁞适合表达长期依赖信息。LSTM 模型针对传统 RNN 结构引入自循环机制,</p>
	                    <div class="textFrom">——天津大学硕士论文 么素素-《基于集成学习的跨数据域文本倾向性分析研究》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong>为了缓解这一问题,<em class='similar'>改善RNN的性能,</em><em class='similar'>近年来许多研究人员对此提出了一些改进措施并取得了不错的效果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>——产生输出的权值矩阵⁞——作用于前一时间步隐状态的权值矩阵⁞——非线性激活函数⁞——非线性激活函数⁞由于RNN的结构在处理时序信息上具有天然优势,其对于序列数据的建模能力较为强大。然而,RNN在反向传播的过程中产生的梯度会随着时间的推移被逐渐放大或者衰减。对于那些具有较长时间依赖性的时间序列,梯度放大或衰减程度更加趋近于指数级,这就是严重影响网络训练的梯度消失和梯度爆炸现象。为了缓解梯度消失和梯度爆炸,<em class='similar'>改善RNN的学习能力,</em><em class='similar'>近年来许多研究人员做出了一些改进并取得了不错结果。</em>⁞长短时记忆单元(Long-Short Term Memory, LSTM)[44]是一种改进的RNN,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>墙抗震性能的措施。近几十年来,国内外对剪力墙延性的问⁞题进行了许多试验研究,开有洞口的剪力墙结构连梁与墙肢的合理设计成为剪力⁞墙结构整体延性好坏的关键所在,<em class='similar'>研究人员对此提出了许多改进措施,</em><em class='similar'>均收到了⁞一定的效果。</em>⁞1.3.1联肢剪力墙研究的发展概况⁞Coull.A.[77]根据剪力墙的受力性能将剪力墙分为单肢剪力墙,连杆连接剪力⁞</p>
	                    <div class="textFrom">——北京工业大学硕士论文 孙超-《双向单排配筋带洞口混凝土剪力墙抗震性能试验与分析》-2008 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong><em class='similar'>长短时记忆神经网络</em>[47]<em class='similar'>是一种改进的 RNN,</em>其中引入的门控机制能够有效地</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>井参数与横波之间的映射关系,但忽略了连续变量的序列特征。循环神经网络(RNN)能够在一定程度上解决序列数据的前后关联问题,但由于梯度爆炸和梯度消失问题而效果不佳㈣。<em class='similar'>长短时记忆神经网络</em><em class='similar'>(LSTM)㈨是一种改进的RNN,</em>在有效提取序列特征的同时,引入门控单元,实现长短时信息的有效记忆,能够控制长短时信息的遗忘与更新,表达不同测井参数的尺度承载能力和横波的沉积序列特征,挖掘测井参数与横波之间的深层联系。</p>
	                    <div class="textFrom">——断块油气田 周恒；武中原；张欣；张春雷；马乔雨-《基于LSTM循环神经网络的横波预测方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>14.</strong><em class='similar'>缓解 RNN 存在的梯度消失和梯度爆炸问题,</em><em class='similar'>其基本结构如图2-5所示。</em>结合LSTM 前向计算过程说明遗忘门<em class='similar'>(Forget Gate)</em><em class='similar'>、输入门</em><em class='similar'>(Input Gate)</em><em class='similar'>和输出门</em><em class='similar'>(Output Gate)</em><em class='similar'>三个门控单元的作用。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>从而保留有用的历史信息。LSTM 的基本结构是记忆单元(Memory Cell),其中每个记忆单元使用了门<em class='similar'>(Gate)</em>机制,主要包括:<em class='similar'>输入门</em><em class='similar'>(Input Gate)</em>、遗忘门<em class='similar'>(Forget Gate)</em><em class='similar'>和输出门</em><em class='similar'>(Output Gate)</em><em class='similar'>。LSTM 计算单元的基本结构如图2-5所示。</em>图2-5 LSTM 基本结构图对于 t 时刻,LSTM 计算单元的运算如下所示。记忆单元首先计算当前单元的输入信号如公式2-9所示。</p>
	                    <div class="textFrom">——网页 -《改进的文本主题表示及学习方法》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>不同时刻的状态和输出。除隐藏状态外,还增加了记忆细胞和候选记忆细胞来存储中间状态,<em class='similar'>其结构如图2-6所示。</em>LSTM通过门结构将短期记忆和长期记忆相结合,<em class='similar'>有效缓解了传统RNN⁞图2-5⁞早期RNN的基本结构⁞结构中的梯度消失和梯度爆炸问题。</em>⁞i &quot; I至连接层和激活盍教0段元素运算符篁制了一连结⁞图2-6 LSTM的基本结构⁞(3)门控循环单元(Gate Recurrent Unit, GRU)⁞LSTM单元虽然具有良好的性能,</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 刘亚欣-《基于深度学习的人体姿态估计及预测算法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>,0表示完全不通过,1表示完全通过。LSTM 用内部记忆单元即细胞的状态保存历史信息,并利用不同的&quot;门&quot;动态地让网络学习适时遗忘历史信息、依据新信息更新细胞状态,<em class='similar'>以解决RNN中梯度消失与梯度爆炸的问题。</em><em class='similar'> LSTM 神经网络记忆单元的基本结构如图2所示〔5〕。</em>图2 LSTM 单元的内部结构 LSTM 通过遗忘门控制从当前状态中移除哪些信息,输入门控制哪些信息传递到当前状态中,输出门控制当前状态中的哪些信息用作输出,</p>
	                    <div class="textFrom">——网页 -《基于CEEMDAN_LSTM的股票市场指数预测建模研究_贺毅岳》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>in modes⁞数据时会产生梯度爆炸或梯度消失[25]的问题。LSTM在RNN的基础上进行改进,增加3种门限:<em class='similar'>输入门限、</em>遗忘门限和输出门限,能够灵活改变不同时刻下的积分尺度,<em class='similar'>解决了RNN梯度爆炸或梯度消失的问题。</em><em class='similar'>LSTM的结构如图5所示。</em>⁞图5 LSTM神经网络结构⁞Fig.5 Structure of LSTM neural network⁞LSTM作为一个神经网络,主要负责计算时间序列中各个观测值之间的依赖性,</p>
	                    <div class="textFrom">——电力建设 李彬；魏吟娬；祁兵；孙毅；陈宋宋-《基于EEMD-LSTM的需求响应终端DDoS攻击检测方法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>45]是对 RNN的⁞一种改进,如下图所示:⁞⁞图3.2 LSTM 结构图⁞Fig.3.2 LSTM model structure ⁞由图可以看到,与 RNN 对比,添加了门控制电路机制。其具体 LSTM通过3个门控单元输入门<em class='similar'>(Input Gate)</em><em class='similar'>、输出门</em><em class='similar'>(Output Gate)</em>和遗忘门<em class='similar'>(Forget Gate)</em>来对的信息进行交互和控制,<em class='similar'>这样可以较好的解决梯度消失问题。</em><em class='similar'>当输入门关闭,</em>遗⁞忘门打开,输出门关闭时,LSTM 即为标准的 RNN 。<em class='similar'>⁞Input Gate:</em></p>
	                    <div class="textFrom">——广东工业大学硕士论文 罗俊宇-《基于深度学习在医疗领域的中文命名实体识别》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>简称 LSTM)是基于门控算法的循环神经⁞网络,它能够弥补上述传统 RNN 模型的缺点,因此经常用于对文本中的特征进⁞行提取。LSTM 的模型结构如图2-1[6]所示,<em class='similar'>包含了三个门控单元:</em><em class='similar'>输入门</em><em class='similar'>(input⁞gate)</em><em class='similar'>、输出门</em><em class='similar'>(output gate)</em>和遗忘门<em class='similar'>(forget gate)</em>。输入门用于控制当前时刻计⁞算新的状态会有多少被更新到当前的记忆单元中;输出门用于控制当前时刻的输⁞出会有多少程度来自当前的记忆单元中;</p>
	                    <div class="textFrom">——浙江大学硕士论文 曹金超-《一种基于深度学习的中文自然语言查询生成SQL语句技术研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>15.</strong><em class='similar'>遗忘门决定当前时间步哪些输入将被丢弃。</em>具体地,<em class='similar'>它将前一时间步的输出和当前时间步的输入拼接作为真正的输入,</em><em class='similar'>通过非线性激活函数将输出范围固定为,</em><em class='similar'>越接近1说明遗忘门越倾向于保留该输出,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>够有效缓解经典RNN的梯度消失和梯度爆炸问题。LSTM的结构如图2.5所示。⁞⁞图2.5 LSTM一个计算单元的结构⁞下面结合LSTM的前向计算过程说明遗忘门、输入门和输出门三个门控单元的作用:⁞1.<em class='similar'>遗忘门:</em><em class='similar'>用于决定当前时刻哪些输入将被丢弃。</em><em class='similar'>其将前一时间步的输出和当前时间步的实际输入拼接,</em><em class='similar'>作为输入。</em><em class='similar'>再通过非线性激活函数将输出限制在0到1之间。</em><em class='similar'>输出越接近1说明遗忘门越倾向于保留该输出,</em>反之亦然。遗忘门输出的计算过程如式(2.7)所示。⁞(2.7)⁞2.输入门:用于产生输入的映射,<em class='similar'>计算过程如式</em>(2.8)所示。⁞(2.8)⁞3.状态更新:将当前输入更新到网络的状态中。<em class='similar'>计算过程如式</em>(2.9)-(2.10)所示。⁞(2.9)⁞(2.10)</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_5" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">65.9%(628字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=融合辅助目标学习和卷积循环网络的非侵入式语音质量评价算法" target="_blank">融合辅助目标学习和卷积循环网络的非侵入式语音质量评价算法</a></span>
                      <p>唐闺臣;梁瑞宇;孔凡留;谢跃;鞠梦洁 -
                        《声学学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">5.7%(54字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=端到端语音识别中编解码器的研究与优化" target="_blank">端到端语音识别中编解码器的研究与优化</a></span>
                      <p>朱涛 -
                        《南京邮电大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.4%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://www.doc88.com/p%2D57787019125503.html" target="_blank">基于序列到序列模型的文本摘要研究综述</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(41字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=公路隧道施工期智能实时监测及预警系统" target="_blank">公路隧道施工期智能实时监测及预警系统</a></span>
                      <p>刘洁 -
                        《长安大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的心电脉搏特征识别与应用" target="_blank">基于深度学习的心电脉搏特征识别与应用</a></span>
                      <p>胡文锐 -
                        《北方民族大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4.1%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.doc88.com/p%2D7804751675498.html" target="_blank">基于PyTorch的机器翻译算法的实现</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.1%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于双向注意力机制的多模态情感分类方法" target="_blank">基于双向注意力机制的多模态情感分类方法</a></span>
                      <p>黄宏展;蒙祖强 -
                        《计算机工程与应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络机器翻译的机器译文质量估计研究" target="_blank">基于神经网络机器翻译的机器译文质量估计研究</a></span>
                      <p>孙潇 -
                        《哈尔滨工业大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识图谱的多轮对话技术及其应用研究" target="_blank">基于知识图谱的多轮对话技术及其应用研究</a></span>
                      <p>唐成达 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于机器学习的可解释性对股票指数趋势预测的研究" target="_blank">基于机器学习的可解释性对股票指数趋势预测的研究</a></span>
                      <p>张艾伦 -
                        《对外经济贸易大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于注意力机制的不规则场景文字识别方法研究" target="_blank">基于注意力机制的不规则场景文字识别方法研究</a></span>
                      <p>郭昭宏 -
                        《中国科学院大学(中国科学院重庆绿色智能技术研究院)硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=深度学习  上" target="_blank">深度学习  上</a></span>
                      <p>张宪超著 -
                        《
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">3%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多模态注意力机制的视觉问答研究" target="_blank">基于多模态注意力机制的视觉问答研究</a></span>
                      <p>张浩田 -
                        《内蒙古大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向三维模型检索的多视图特征学习方法研究" target="_blank">面向三维模型检索的多视图特征学习方法研究</a></span>
                      <p>王栋 -
                        《哈尔滨工业大学博士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识蒸馏的口语理解模型研究与实现" target="_blank">基于知识蒸馏的口语理解模型研究与实现</a></span>
                      <p>侯晓龙,周培林,邹月娴 -
                        《电子技术与软件工程
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人工智能前沿技术丛书  计算智能导论" target="_blank">人工智能前沿技术丛书  计算智能导论</a></span>
                      <p>刘玉芳，张玮责任编辑;（中国）尚荣华，焦李成，刘芳 -
                        《
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_5" class="simMore"><a href="javascript:$ShowMore(5);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>图2-5长短时记忆神经网络基本结构</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>控制门用来确定上一个隐藏层状态的信息中哪些是重要的,输入控制⁞门用来确定当前状态的哪些信息是重要的,输出控制门用来确定下一个隐藏层状态。<em class='similar'>⁞⁞图4.5长短时记忆神经网络结构图⁞长短时记忆神经网络的基本结构,</em>如图4.6所示。在 t 时刻时,长短时记忆神经网⁞络中的输入有三个:当前时刻网络的输入值、上一时刻 LSTM 的输出值、以及上⁞一时刻的单元状态;输出有两个:当前时刻的 LSTM 输出值和单元状态。</p>
	                    <div class="textFrom">——长安大学硕士论文 刘洁-《公路隧道施工期智能实时监测及预警系统》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>-8-2.2脉搏信号的理论基础.-9-⁞2.2.1脉搏信号的产生原理.-9-2.2.2脉搏信号的波形特征与物理意义.-10-2.3深度学习的理论基础.-11-⁞2.3.1卷积神经网络基本结构.-11-2.3.2<em class='similar'>双向长短时记忆神经网络基本结构.</em>-14-2.4本章小结.-16-⁞第三章心电脉搏信号的采集与预处理.-17-⁞3.1心电脉搏信号同步采集.-17-3.2改进 EEMD 算法对心电脉搏信号的去噪研究.-19-⁞3.2.</p>
	                    <div class="textFrom">——北方民族大学硕士论文 胡文锐-《基于深度学习的心电脉搏特征识别与应用》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>减少细胞状态G的累积量。这便是长短时记忆神经网络相较于传统循环神经网络更稳定的原因。下面将详细介绍长短时记忆神经网络的门控原理。⁞计算智能导论⁞2)<em class='similar'>长短时记忆神经网络的数学分析⁞基于图4-37,</em>长短时记忆神经网络的核心是设计细胞状态C,用以控制信息的变化。注意,图4-37中£时刻的输入包括当前时刻的输入不、前一时刻的细胞状态CLI以及前一时刻的隐</p>
	                    <div class="textFrom">—— 刘玉芳，张玮责任编辑；（中国）尚荣华，焦李成，刘芳-《人工智能前沿技术丛书  计算智能导论》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>输入门产生输入的映射,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>和当前时间步的实际输入拼接,作为输入。再通过非线性激活函数将输出限制在0到1之间。输出越接近1说明遗忘门越倾向于保留该输出,反之亦然。遗忘门输出的计算过程如式(2.7)所示。⁞(2.7)⁞2.<em class='similar'>输入门:</em><em class='similar'>用于产生输入的映射,</em><em class='similar'>计算过程如式</em>(2.8)所示。⁞(2.8)⁞3.状态更新:将当前输入更新到网络的状态中。<em class='similar'>计算过程如式</em>(2.9)-(2.10)所示。⁞(2.9)⁞(2.10)⁞4.输出门:通过输出门得到输出,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>输出门产生输出,<em class='similar'>并将其与前一时间步的单元状态交互得到输出,</em>其计</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>2.7)⁞2.输入门:用于产生输入的映射,计算过程如式(2.8)所示。⁞(2.8)⁞3.状态更新:将当前输入更新到网络的状态中。计算过程如式(2.9)-(2.10)所示。⁞(2.9)⁞(2.10)⁞4.输出门:通过输出门得到输出,<em class='similar'>再将其与前一时间步的单元状态交互更新单元状态并得到输出。</em>⁞(2.11)⁞(2.12)⁞式(2.7)-(2.12)中,、、、——遗忘门、输入门、候选状态、输出门⁞、——sigmoid、双曲正切激活函数⁞、——遗忘门的权值矩阵、偏置矩阵⁞、——输入门的权值矩阵、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>[14]对 BERT 输出生⁞成每个时间步上的下文感知表征 st,然后拼接意图向量 v⁞intent 输入到⁞Slot-Gate 中得到门向量 vt,通过逐元素相乘建模 BERT 输出与门向⁞量间的交互,<em class='similar'>得到各时间步最终的隐状态输出 ot,</em>公式表达如下所⁞示:⁞st=Self-Attention(ht, H),(3)⁞vt=MLP([st, v⁞intent]),(4)⁞ot=ht⨀vt,(5)⁞3.1.</p>
	                    <div class="textFrom">——电子技术与软件工程 侯晓龙,周培林,邹月娴-《基于知识蒸馏的口语理解模型研究与实现》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>上式中,、、<em class='similar'>和分别表示遗忘门、</em><em class='similar'>输入门、</em>候选状态和输出门;表示 Sigmoid 函数;<em class='similar'>和分别表示权重矩阵和偏置向量;</em><em class='similar'>表示按元素相乘。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>⁞c⁞t⁞),⁞其中,⁞i 表示帧索引,⁞a 表示 s i⁞gmo i d 函数,<em class='similar'>⁞i⁞,/和⁞〇分别表示输入门、</em><em class='similar'>遗忘门和输出门,</em>⁞c 和/z 分别表⁞示细胞状态和隐藏输出,<em class='similar'>和6为权重矩阵和偏置⁞向量,</em>⁞?<em class='similar'>表示逐元素相乘。</em>⁞但是,对长序列而言,仅使用 B iLSTM 建模可⁞能会存在首尾部隐藏输出信息损失的问题,而尾部的信息损失对 LSTM 网络而言是致命的,因为此网⁞络的最终输出通常选取为最后⁞</p>
	                    <div class="textFrom">——声学学报 唐闺臣；梁瑞宇；孔凡留；谢跃；鞠梦洁-《融合辅助目标学习和卷积循环网络的非侵入式语音质量评价算法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>𝑡)⊙ℎ(𝑡−1)+(1−𝑢(𝑡))⊙ℎ̃(𝑡)(2.18)⁞其中𝑢(𝑡)、𝑟(𝑡)分别代表更新门和重置门的输出,ℎ̃(𝑡)为候选隐含状态特征,ℎ(𝑡)是当前时刻的隐含状态,<em class='similar'>𝑊和𝑏表示权重矩阵和偏置向量,</em><em class='similar'>⊙表示对应元素相乘。</em>通过上述过程可以发现,在 GRU 中首先获取到重置门和更新门的门控信号,接着使用重置信号对上一时间步的隐含特征进行重置且将得到的结果与当前时刻输入进行拼接存入候选隐含状态中</p>
	                    <div class="textFrom">——内蒙古大学硕士论文 张浩田-《基于多模态注意力机制的视觉问答研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>Wigxt+big+Whght−1+bhg)ot=σ(Wioxt+bio+Whoht−1+bho)ct=ft◦ct−1+it◦gt⁞ht=ot◦tanh(ct)⁞(3-5)⁞其中,it、ot、ft、<em class='similar'>gt分别表示输入门、</em>输出门、遗忘门和候选门的激活向量。ct和ht分别代表记忆单元和隐状态。<em class='similar'>◦表示按位相乘,</em>σ()是按元素运算的sigmoid函数。每个LSTM单元的基本结构如图3-1:⁞ot⁞gt⁞ht⁞it⁞ft⁞ct⁞</p>
	                    <div class="textFrom">——哈尔滨工业大学博士论文 王栋-《面向三维模型检索的多视图特征学习方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>编—解码器结构最先应用于机器翻译领域</em>[48]。<em class='similar'>在该结构中,</em><em class='similar'>编码器首先将输入文本编码成向量序列,</em><em class='similar'>然后解码器根据该向量序列逐步输出文本。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>常使用CNN-RNN混合结构的神经网络对输入语音特征序列和真实标签进行建模,并通过CTC损失函数进行梯度的反向传播,进而更新网络的权值。<em class='similar'>⁞2.4基于编码器-解码器结构的语音识别方法⁞编码器-解码器结构最先应用于机器翻译。</em><em class='similar'>在该结构中,</em><em class='similar'>编码器网络首先将输入文本编码成一个向量序列,</em><em class='similar'>然后,</em><em class='similar'>解码器根据该向量序列逐步输出文本。</em>在每一个输出步骤中,解码器网络会使用注意力机制为编码器输出的向量序列分配不同的权重。下一个输出将由历史输出序列和该向量序列的加权和确定。⁞编码器-解码器结构非常适合用在语音识别任务上,这是由该结构中的注意力机机制和语音识别任务本身的特点共同决定的:⁞1.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>在每一个输出步骤中,</em><em class='similar'>解码器基于注意力机制为向量序列分配不同的权重,</em><em class='similar'>且下一个输出将由历史输出序列和该向量序列的加权和决定。</em><em class='similar'>编—解码器结构非常适合用于自动语音识别领域,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>常使用CNN-RNN混合结构的神经网络对输入语音特征序列和真实标签进行建模,并通过CTC损失函数进行梯度的反向传播,进而更新网络的权值。⁞2.4基于编码器-解码器结构的语音识别方法⁞编码器-解码器结构最先应用于机器翻译。在该结构中,编码器网络首先将输入文本编码成一个向量序列,然后,解码器根据该向量序列逐步输出文本。<em class='similar'>在每一个输出步骤中,</em><em class='similar'>解码器网络会使用注意力机制为编码器输出的向量序列分配不同的权重。</em><em class='similar'>下一个输出将由历史输出序列和该向量序列的加权和确定。</em><em class='similar'>⁞编码器-解码器结构非常适合用在语音识别任务上,</em>这是由该结构中的注意力机机制和语音识别任务本身的特点共同决定的:⁞1.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>encoder-decoder),SRN 以 GCNs 生成的特征图为输入,而后输出目标字符序列⁞(??1,)。SRN 由一个编码器和一个解码器组成。编码器是一个 CNN-LSTM⁞结构,用于生成一个特征向量序列(?1,)。<em class='similar'>基于注意力机制的解码器,</em>最早⁞由Bahdanau 等(2014)提出,通过聚焦于时步??相关的特征向量来输出。的⁞计算过程如下式:⁞=1)8)?(6??(?(2+?(7??),(3.6)⁞= arg max⁞?4)?9)?(</p>
	                    <div class="textFrom">——中国科学院大学(中国科学院重庆绿色智能技术研究院)硕士论文 郭昭宏-《基于注意力机制的不规则场景文字识别方法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>列&quot;任务,<em class='similar'>即将输入序列识别为输出序列;</em><em class='similar'>编—解码器结构使用的注意力机制可以隐式学习输入序列与输出序列之间的软对齐关系,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>.语音识别任务和机器翻译任务都是&quot;序列-序列&quot;任务,<em class='similar'>即将输入序列识别为输出序列的处理过程;</em>⁞2.<em class='similar'>编码器-解码器结构使用的注意力机制可以隐式地学习输入序列与输出序列之间的软对齐关系,</em>而不需要数据的提前对齐;⁞3.编码器产生的向量序列不再是固定长度的单个向量,因此该模型可以处理较长的语音输入序列。⁞⁞图2.7编码器-解码器模型基本结构示意图⁞由于以上原因,编码器-解码器结构受到了广泛的关注。编码器-解码器结构的示意图如图2.7所示。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong><em class='similar'>语音识别也是从输入序列识别输出序列的序列到序列过程,</em>因此,它基本上与翻译任务相同;使用注意机制的编码器-解码器方法不需要分段前的数据对齐,<em class='similar'>通过注意力机制,</em><em class='similar'>它可以隐式学习输入和输出序列之间的软对齐,</em>从而解决了语音识别的一个大问题;编码结果不再局限于单个固定长度的矢量,该模型仍然可以对长输入序列产生良好的效果,因此这种模⁞型还可以处理各种长度的语音输入。</p>
	                    <div class="textFrom">——南京邮电大学硕士论文 朱涛-《端到端语音识别中编解码器的研究与优化》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>进行聚类得到 FSA。它阐明了 RNN 如何受到门控数量的影响,并借助 FSA 透视 RNN的内部机制。⁞(3)注意力机制:注意力机制是在编码-解码器的框架下提出的,它广泛应用于自然语言处理领域。<em class='similar'>注意力机制可以很好地解释输入序列与输出序列之间的对齐关系,</em>解释说明模型学到的内容,是一种基于全局的特定模块化的可解释方法。本文将注意力机制与 CNN、LSTM 算法相结合构造基于可解释模块的可解释模型,</p>
	                    <div class="textFrom">——对外经济贸易大学硕士论文 张艾伦-《基于机器学习的可解释性对股票指数趋势预测的研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>engio 等在神经网络中通过模拟注意力机制实现英语到法语的翻译,输出序列中每输出一个元素,都通过权重参考输入序列信息,<em class='similar'>这样就可实现输入序列与输出序列之间的对齐。</em><em class='similar'>注意力机制的核心思想是:</em>将输入的源语句传入编码器后由编码器生成一个输出,此时给输出加入权重向量后作为解码器的输入。注意力机制分为随机注意(stochastic attention)机制和软注意(soft attention)机制[14]。</p>
	                    <div class="textFrom">——网页 -《基于PyTorch的机器翻译算法的实现》- （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>由于 H 包含了位置信息,CopyNet 在网络结构上更加简单,不需要开关和指针;但也正是因为 H 的特殊性,限制了 CopyNet 的通用性。3.2.2<em class='similar'>重复控制由于注意力机制忽略了输入序列和输出序列之间的对齐关系</em>[41],因此解码器可能会重复关注到输入序列的某些部分,导致输出序列也产生重复。针对这一问题,有以下几种解决方案。1)覆盖机制(coverage mechanism)覆盖机制由Tu等[41]提出,</p>
	                    <div class="textFrom">——网页 -《基于序列到序列模型的文本摘要研究综述》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>而不需要将数据提前对齐;</em><em class='similar'>编码器产生的向量序列不再是固定长度的单个向量,</em><em class='similar'>因此可以处理较长的语音输入序列。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>器翻译任务都是&quot;序列-序列&quot;任务,即将输入序列识别为输出序列的处理过程;⁞2.编码器-解码器结构使用的注意力机制可以隐式地学习输入序列与输出序列之间的软对齐关系,<em class='similar'>而不需要数据的提前对齐;</em>⁞3.<em class='similar'>编码器产生的向量序列不再是固定长度的单个向量,</em><em class='similar'>因此该模型可以处理较长的语音输入序列。</em>⁞⁞图2.7编码器-解码器模型基本结构示意图⁞由于以上原因,编码器-解码器结构受到了广泛的关注。编码器-解码器结构的示意图如图2.7所示。其中,编码器(Encoder)将输入特征序列映射为抽象的高级表征(也称为</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音识别也是从输入序列识别输出序列的序列到序列过程,因此,它基本上与翻译任务相同;使用注意机制的编码器-解码器方法不需要分段前的数据对齐,通过注意力机制,它可以隐式学习输入和输出序列之间的软对齐,从而解决了语音识别的一个大问题;<em class='similar'>编码结果不再局限于单个固定长度的矢量,</em>该模型仍然可以对长输入序列产生良好的效果,<em class='similar'>因此这种模⁞型还可以处理各种长度的语音输入。</em></p>
	                    <div class="textFrom">——南京邮电大学硕士论文 朱涛-《端到端语音识别中编解码器的研究与优化》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>器结构在自动语音识别领域受到了广泛关注,</em>其结构如图2-6所示。<em class='similar'>其中,</em><em class='similar'>编码器将输入特征序列映射为抽象的高级表征并传递给解码器,</em><em class='similar'>解码器根据接收信息预测输出序列。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>因此该模型可以处理较长的语音输入序列。⁞⁞图2.7编码器-解码器模型基本结构示意图⁞由于以上原因,<em class='similar'>编码器-解码器结构受到了广泛的关注。</em>编码器-解码器结构的示意图如图2.7所示。<em class='similar'>其中,</em>编码器(Encoder)<em class='similar'>将输入特征序列映射为抽象的高级表征</em>(也称为隐状态),并传递给解码器(Decoder)<em class='similar'>,解码器将根据接收的隐状态预测输出序列。</em>在大多数情况下,预测特定所需的信息依赖于少数输入帧。因此在解码时不需要考虑每一个输入语音帧。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>预测特定所需的信息仅依赖于少数关键输入帧,</em><em class='similar'>因此在解码时不需要考虑每一个输入帧。</em><em class='similar'>注意力机制通过为每一对输入帧和分配相应的匹配分数来完成输入序列和输出序列的对齐</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>射为抽象的高级表征(也称为隐状态),并传递给解码器(Decoder),解码器将根据接收的隐状态预测输出序列。在大多数情况下,<em class='similar'>预测特定所需的信息依赖于少数输入帧。</em><em class='similar'>因此在解码时不需要考虑每一个输入语音帧。</em><em class='similar'>注意力机制通过为每一对输入帧和分配相应的匹配得分来进行输入序列和输出序列的对齐。</em>匹配得分的高低表示特定输入帧与的相关程度,解码器通过决定对每个输入帧的关注程度进而预测输出序列。⁞加性注意力机制使用RNN解码器上一个时间步的状态和编码器网络编码得到的某一时刻的隐状态产生注意力得分:⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>,匹配分数的高低代表特定输入帧与的相关程度,</em><em class='similar'>解码器对每个输入帧的关注程度进行决定进而预测输出序列。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>因此在解码时不需要考虑每一个输入语音帧。注意力机制通过为每一对输入帧和分配相应的匹配得分来进行输入序列和输出序列的对齐。<em class='similar'>匹配得分的高低表示特定输入帧与的相关程度,</em><em class='similar'>解码器通过决定对每个输入帧的关注程度进而预测输出序列。</em>⁞加性注意力机制使用RNN解码器上一个时间步的状态和编码器网络编码得到的某一时刻的隐状态产生注意力得分:⁞(2.29)⁞式(2.29)中,、——可学习的权值向量、偏置向量⁞、——可学习的权值矩阵⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong>具体地,<em class='similar'>以加性注意力机制为例,</em><em class='similar'>首先使用解码器前一时间步的状态和</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>域,作为编码器的输入计算中间特征,如图8.3所示。⁞图8.3在目标检测应用中的RNN模型(WangetaL,2016) encoder:编码器。glimpse:瞥见。classification:<em class='similar'>分类⁞注意力机制以原图X和解码器上一个时间步的状态作为输入,</em>利用如下的高斯分布输岀中心位置:⁞SLNod)(8.12)⁞式中,为是一个应用在注意力机制中的神经网络。那么注意力选出的子区域可以表示为%,</p>
	                    <div class="textFrom">—— 张宪超著-《深度学习  上》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong>阵。<em class='similar'>然后使用 Softmax 函数进行归一化,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>模型的输出层是将输入文本编码器输出的文本向量 w 和候选文本编码器输出的候选向量 k 拼接起来,<em class='similar'>使用一个全连接层进行线性变化,</em><em class='similar'>然后通过 softmax函数将其归一化,</em><em class='similar'>计算过程如</em>公式3-16所示。其中 W 是全连接层参数,y 是输⁞出结果。⁞𝑦𝑦=𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑥𝑥(𝑊𝑊∙[𝑤𝑤;𝑘𝑘])(3-16)⁞3.3.</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐成达-《基于知识图谱的多轮对话技术及其应用研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>第 t 步的目标词概率分布的计算,输⁞入是该步的隐状态,然后模型采用的是一个单隐层的前向神经网络,隐层激活⁞函数采用的是 tanh 函数,<em class='similar'>最后输出层采用 softmax 函数进行归一化,</em><em class='similar'>计算过程⁞如式</em>(3-12)所示:⁞p(1,,1,??)=1)8)?(6??(?(2??2tanh(?(2??1+?(71))(3-12)⁞3.2.1.2 QE 模型⁞QE 模型的输入是特征向量 V,在3.</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 孙潇-《基于神经网络机器翻译的机器译文质量估计研究》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>的矩阵,然后跟文本表示 Si 在每个状态输出的级别上拼接,为文本信息扩增图像内容。借助线性变换计算每个状态LSTM输出关于图像高层语义的注意力权重,<em class='similar'>通⁞过 softmax函数进行归一化。</em><em class='similar'>计算过程如下:</em>⁞γi =⁞exp(e(Si ,Qi))⁞∑⁞i⁞exp(e(Si ,Qi))⁞(11)其中:⁞e(Si ,Qi)=Dense({Si ,dQi}+ bs2)(12)其中,Dense层激活函数为 tanh函数,bs2是偏置。{Si,</p>
	                    <div class="textFrom">——计算机工程与应用 黄宏展；蒙祖强-《基于双向注意力机制的多模态情感分类方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_6" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">35.9%(436字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络的图像描述研究" target="_blank">基于神经网络的图像描述研究</a></span>
                      <p>祝木林 -
                        《东南大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">8.5%(103字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多层级注意力网络的特定目标情感分析" target="_blank">基于多层级注意力网络的特定目标情感分析</a></span>
                      <p>刘新元 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向仪器领域的任务型对话系统研究" target="_blank">面向仪器领域的任务型对话系统研究</a></span>
                      <p>陈婷婷 -
                        《西安电子科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Transformer的对话系统研究" target="_blank">基于Transformer的对话系统研究</a></span>
                      <p>许明权 -
                        《湖南大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多注意力的融合上下文重排序算法研究" target="_blank">基于多注意力的融合上下文重排序算法研究</a></span>
                      <p>郭超峰 -
                        《华中科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.docin.com/p%2D2177208589.html" target="_blank">基于散射并矢的mimo信道模型分析 - 豆丁网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=健康观念影响下的女性保健食品包装设计研究" target="_blank">健康观念影响下的女性保健食品包装设计研究</a></span>
                      <p>张婷 -
                        《江南大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于改进一维卷积神经网络的电力系统暂态稳定评估" target="_blank">基于改进一维卷积神经网络的电力系统暂态稳定评估</a></span>
                      <p>赵恺,石立宝 -
                        《电网技术
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.doc88.com/p%2D07539798780145.html" target="_blank">基于区域嵌入法的反Stefan问题高效计算</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(22字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_6" class="simMore"><a href="javascript:$ShowMore(6);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>最后解码器根据</em>、<em class='similar'>前一时间步输出向量和状态向量得到当前时间步的状态向量和输出向量,</em>经过 Softmax 函数之后得到预测的输出序列。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>2.29)中,、——可学习的权值向量、偏置向量⁞、——可学习的权值矩阵⁞——双曲正切激活函数⁞再使用softmax函数进行归一化:⁞(2.30)⁞对加权求和得到加性注意力输出向量:⁞(2.31)⁞RNN<em class='similar'>解码器网络根据</em>、<em class='similar'>上一个解码时间步的输出向量以及状态向量产生当前时间步的状态向量以及输出向量:</em>⁞(2.32)⁞(2.33)⁞除了加性注意力机制外,目前使用较为广泛的注意力机制有缩放点积注意力机制(Scale Dot Product Attention, SDPA)[45]、多头注意力机制(</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>)⁞t t t⁞x⁞⁞a W W a (1)⁞ ya⁞ˆ SoftMax()⁞t t⁞y W a (2)式中: t nRx 、<em class='similar'> t mRa 和ˆ t kRy 分别为第 t个时间步的输入向量、</em><em class='similar'>系统状态向量和输出向量;</em>⁞ax⁞m nRW 、 aam mRW 和 ya⁞k mRW 为转移矩阵;⁞tanh()为双曲正切函数;SoftMax()为指数归一化函数。Bengio等人对式(1)(2)进行链式求导,</p>
	                    <div class="textFrom">——电网技术 赵恺,石立宝-《基于改进一维卷积神经网络的电力系统暂态稳定评估》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>模型参数在梯度反向更新时出现的严重的梯度消⁞失或梯度爆炸问题,LSTM 网络中一个基本单元的结构如图2.5所示。⁞⁞图2.5 LSTM 网络单元结构图⁞图2.5中,<em class='similar'>𝑥𝑡、𝑐𝑡、ℎ𝑡分别是当前时间步的输入向量、</em><em class='similar'>状态向量以及输出向量,</em>⁞𝑓𝑡、𝑖𝑡、𝑜𝑡对应的分别是 LSTM 单元结构中的遗忘门、输入门和输出门,𝑐𝑡⁞,为当前输⁞入状态。公式2.6-2.8描述了遗忘门、输入门和输出门的计算过程。</p>
	                    <div class="textFrom">——华中科技大学硕士论文 郭超峰-《基于多注意力的融合上下文重排序算法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>除了上述加性注意力机制外,</em><em class='similar'>目前使用较为广泛的注意力机制还有缩放点积注意力</em><em class='similar'>(Scaled Dot-Product Attention,</em><em class='similar'>SDPA)</em>机制[49]、<em class='similar'>多头注意力</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'>MHA)</em>机制[17]和局部注意力<em class='similar'>(Local Attention,</em><em class='similar'>LA)</em>机制[50]。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对加权求和得到加性注意力输出向量:⁞(2.31)⁞RNN解码器网络根据、上一个解码时间步的输出向量以及状态向量产生当前时间步的状态向量以及输出向量:⁞(2.32)⁞(2.33)<em class='similar'>⁞除了加性注意力机制外,</em><em class='similar'>目前使用较为广泛的注意力机制有缩放点积注意力机制</em><em class='similar'>(Scale Dot Product Attention,</em><em class='similar'> SDPA)[45]</em><em class='similar'>、多头注意力机制</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'> MHA)</em>以及局部注意力机制<em class='similar'>(Local Attention,</em><em class='similar'> LA)[46]</em>。在编码器-解码器结构中通常使用不同的注意力机制以从不同的角度获取各种层次的信息。目前,出现了各种基于不同注意力机制的编解码网络,如LAS模型、Transformer模型等。其中,Transformer模型以其极高的识别准确度和简便的建模流程而受到广泛关注。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>LC)模型,解码器中图像特征输入方式采用上文介绍的第三种输入方式。我们从不包含注意力模块的 LC 模型开始,先分别将<em class='similar'>缩放点积注意力</em><em class='similar'>(Scaled Dot-Product Attention,</em><em class='similar'>SDPA),</em><em class='similar'>多头注意力</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'>MHA),</em>自适应注意力(Adaptive Attention, AA)三种注意力机制引入到模型中,比较这三种注意力机制对模型性能的影响。然后,我们在模型中加入图像空间特征的二维位置编码(2D Positional </p>
	                    <div class="textFrom">——东南大学硕士论文 祝木林-《基于神经网络的图像描述研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>通常,<em class='similar'>为了从不同角度获取各种层次的信息,</em><em class='similar'>编—解码器结构中会使用不同的注意力机制,</em><em class='similar'>所以目前出现了各种类型的编—解码器网络,</em><em class='similar'>如LAS模型</em>[51]、<em class='similar'>Transformer模</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对加权求和得到加性注意力输出向量:⁞(2.31)⁞RNN解码器网络根据、上一个解码时间步的输出向量以及状态向量产生当前时间步的状态向量以及输出向量:⁞(2.32)⁞(2.33)⁞除了加性注意力机制外,目前使用较为广泛的注意力机制有缩放点积注意力机制(Scale Dot Product Attention, SDPA)[45]、多头注意力机制(Multi-Head Attention, MHA)以及局部注意力机制(Local Attention, LA)[46]<em class='similar'>。在编码器-解码器结构中通常使用不同的注意力机制以从不同的角度获取各种层次的信息。</em><em class='similar'>目前,</em><em class='similar'>出现了各种基于不同注意力机制的编解码网络,</em><em class='similar'>如LAS模型、</em><em class='similar'>Transformer模型等。</em>其中,Transformer模型以其极高的识别准确度和简便的建模流程而受到广泛关注。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>效地实现语句编码的功能,在情感分析任务,其性能较RNN 类网络配合注意力机制有一定的提升[5纥⁞49⁞矩阵相乘⁞Softmax⁞缩放⁞矩阵相乘⁞多头注意力机制编码器⁞多头注意力机制(Multi-Head Attention, MHA)是自注意力机制的一种拓展,其具有多个注意力感知头(Head),每个感知头使用缩放点积注意力进行编码,且每个感知头可以并行计算,不同的感知头从不同语义空间进行学习,<em class='similar'>获得不同空间的注意力聚焦编码结果</em>[5纥多头</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 刘新元-《基于多层级注意力网络的特定目标情感分析》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>注[52]<em class='similar'>。论文第三章将详细探讨 Transformer 模型,</em><em class='similar'>并在此基础上进行改进。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>出现了各种基于不同注意力机制的编解码网络,如LAS模型、Transformer模型等。其中,Transformer模型以其极高的识别准确度和简便的建模流程而受到广泛关注。<em class='similar'>本文第三章和第四章将详细探讨Transformer模型,</em><em class='similar'>并在此基础上进行改进。</em>⁞2.5本章小结⁞本章主要分为两部分。第一部分主要介绍了语音识别的基本理论和处理流程。第二部分主要介绍了深度学习方法在端到端语音识别中的主要应用,这部分首先介绍端</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>在自然语言理解领域,</em><em class='similar'>考虑到意图检测和槽位填充两个子任务之间的密切相关性,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>如双向长短期记⁞西安电子科技大学硕士学位论文⁞忆网络与条件随机场相结合,不仅能够利用过去和未来的信息,还可进行句子级别的标注。⁞3)<em class='similar'>联合训练⁞在自然语言理解任务中,</em><em class='similar'>领域识别、</em><em class='similar'>意图识别和槽位填充之间存在一定的相关性,</em>因此将这三个任务进行联合训练是研究的一个重要方向。2016年,微软Hakkani-Tür[22]⁞等人提出了采用 RNN 和 LSTM 结构的联合模型完成联合任务,取得了比单个模型更⁞</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 陈婷婷-《面向仪器领域的任务型对话系统研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>主要包含三部分。</em><em class='similar'>第一部分主要介绍了对话系统的基本组成结构,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>即第一步上下文向量 ctxc聚集了来自第一步解码序列 ŷ的全局信息。⁞2.8小结⁞本章节介绍本文所涉及的相关基础理论与技术,<em class='similar'>主要包括三大部分。</em><em class='similar'>第一部分介绍了任务型对话系统的四个组成模块,</em>包括NLU、 DST、DPL 和 NLG;第二部分介绍了聊天型对话系统的几种生成方法,包括规则、检索和生成;第三部分介绍Seq2seq文本生成模型,</p>
	                    <div class="textFrom">——湖南大学硕士论文 许明权-《基于Transformer的对话系统研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>这一章节为后续第三章、</em><em class='similar'>第四章的内容做下铺垫。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对女性保健食品包装设计的定义,包装⁞设计可识别性、阅读性、展示性和象征性四个角度分析,具体从设计理念、材料结构、⁞功能和视觉的角度进行阐述,<em class='similar'>为第三章和第四章的内容做理论铺垫,</em>为后续章节中对女⁞性群体和市场上女性保健食品包装设计的分析提供理论依据。⁞图2-2 Dr. Harvey 多种膳食补充剂第三章女性保健食品包装设计现状分析⁞19⁞</p>
	                    <div class="textFrom">——江南大学硕士论文 张婷-《健康观念影响下的女性保健食品包装设计研究》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>本文的主要内容共分为五章。结构如下:第一章简要介绍了MIMO系统的发展历史和研究现状以及MIMO信道模型的基本概念。第二章介绍了MIMO无线信道特性、信道建模主要方法和典型的信道模型,<em class='similar'>为后续章节的展开做好铺垫。</em>第三章和第四章是本文的重点,也是本文的主要贡献。第三章首先介绍了散射并矢公式的由来,并在此基础上对已有的MIMO物理信道模型做了扩展,其次根据扩展后的信道模型,对微小区环境下的链路相关系数进行了仿真计算。</p>
	                    <div class="textFrom">——网页 -《基于散射并矢的mimo信道模型分析 - 豆丁网》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>以及正则化参数选取的合理性.本文其余章节安排如下:在第二章中我们重点介绍我们在后文论证过程中需要运用的定义和定理,同时介绍了几类实用的共轭梯度算法,<em class='similar'>为后续章节的展开做铺垫.</em>在第三章和第四章中,我们给出了高效实现文献[18]中的区域嵌入法求解对一维反Stefan问题和二维反Stefan问题的具体步骤,通过一系列数值实验说明了数值方法的有效性.</p>
	                    <div class="textFrom">——网页 -《基于区域嵌入法的反Stefan问题高效计算》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第3章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_7" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">64.9%(796字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.doc88.com/p%2D43747321413501.html" target="_blank">人工智能之机器学习研究报告</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.4%(54字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的中文人物关系抽取研究与应用" target="_blank">基于深度学习的中文人物关系抽取研究与应用</a></span>
                      <p>雷西唯 -
                        《青海师范大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(52字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://mp.weixin.qq.com/s?src=11&timestamp=1621337837&ver=3076&signature=qFisLbBfGO8lYRI3Y7XEB-2EyE2ldpzGGi1p*HFJS48AU*MgVn4xlExYiXOXbiIl9WUIiOvAK*s3aCPW5HYylDK-XZj22kcNVgn2-1lx5pPhGYQFx1rzogTPEZt*Jxc9&new=1" target="_blank">Transformer 的一些说明</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(52字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=一种基于迁移学习的视觉多任务模型探析" target="_blank">一种基于迁移学习的视觉多任务模型探析</a></span>
                      <p>刘夏鸣 -
                        《科学技术创新
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习和社区论坛问答的专家推荐系统的设计与实现" target="_blank">基于深度学习和社区论坛问答的专家推荐系统的设计与实现</a></span>
                      <p>郭令奇 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的文本摘要相关技术研究与应用" target="_blank">基于深度学习的文本摘要相关技术研究与应用</a></span>
                      <p>秦展展 -
                        《电子科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110546978.html" target="_blank">基于Transformer模型的对话生成方法及系统与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于ALBERT-UniLM模型的文本自动摘要技术研究" target="_blank">基于ALBERT-UniLM模型的文本自动摘要技术研究</a></span>
                      <p>孙宝山;谭浩 -
                        《计算机工程与应用
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(44字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=深浅层特征结合注意力增强的点云配准研究与应用" target="_blank">深浅层特征结合注意力增强的点云配准研究与应用</a></span>
                      <p>兰志翔 -
                        《西北大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=不平衡样本的多标签毒性文本分类 ——基于改进损失函数的神经网络模型" target="_blank">不平衡样本的多标签毒性文本分类 ——基于改进损失函数的神经网络模型</a></span>
                      <p>贾鑫桐 -
                        《上海财经大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=改进CNN算法研究及其在夜晚背景下杂草与甜菜识别中的应用" target="_blank">改进CNN算法研究及其在夜晚背景下杂草与甜菜识别中的应用</a></span>
                      <p>何小飞 -
                        《江苏大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://www.elecfans.com/d/883694.html" target="_blank">注意力机制的诞生、方法及几种常见模型-电子发烧友网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于人工智能的竹类主要害虫识别系统开发与应用" target="_blank">基于人工智能的竹类主要害虫识别系统开发与应用</a></span>
                      <p>李非非;杨帆;余飞;季猛;舒智慧;徐杰 -
                        《世界竹藤通讯
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于GoogLeNet Inception-V3模型的电力设备图像识别" target="_blank">基于GoogLeNet Inception-V3模型的电力设备图像识别</a></span>
                      <p>徐凯;梁志坚;张镱议;刘兴华;郑含博 -
                        《《高压电器》
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=超宽带雷达人体目标行为智能识别方法研究" target="_blank">超宽带雷达人体目标行为智能识别方法研究</a></span>
                      <p>陈朋云 -
                        《电子科技大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_7" class="simMore"><a href="javascript:$ShowMore(7);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>Transformer 模型是近年较为流行的一种深度编—解码器模型,</em><em class='similar'>因其对语音输入—输出序列有强大的建模能力和优秀的识别能力,</em><em class='similar'>在自动语音识别任务中显现了良好的性能,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>中常用的各种深度神经网络,然后介绍了基于CTC的语音识别方法,最后介绍了目前较为流行的编解码结构下的语音识别,为本文第三章和第四章的内容做铺垫。<em class='similar'>⁞⁞第3章基于自适应掩膜局部注意力编码器的语音识别⁞3.1引言⁞Transformer模型作为近年来较为流行的一种深度编解码模型,</em><em class='similar'>以其对语音输入-输出序列强大的建模能力和优秀的识别能力,</em>正受到广泛的关注。Transformer模型中仅存在全连接网络,而没有使用与循环神经网络类似的结构,这使得其在训练时能够充分利用多GPU的并行计</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>组线性变换解码器的轻量级语音识别⁞4.1引言⁞Transformer模型自被提出以来,<em class='similar'>其在端到端语音识别任务中展现了强大的能力。</em>随着对Transformer模型研究的深入,逐渐衍生出了各种各样的变种模型。但是,Transformer模型的表现往往与编码器块和解码器块的深度呈正相关。此外,模型维度越大,模型的表达能力越强,识别的准确率和泛化能力越高,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>受到了广泛的关注。<em class='similar'>随着研究的深入,</em><em class='similar'>逐渐衍生出了各式各样的变种模型。</em>然而,<em class='similar'>Transformer 模型的性能往往与编码器块和解码器块的深度呈正相关。</em><em class='similar'>此外,</em><em class='similar'>模型维度越大,</em>模型的性能、<em class='similar'>识别准确率和泛化能力也越高,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>的轻量级语音识别⁞4.1引言⁞Transformer模型自被提出以来,其在端到端语音识别任务中展现了强大的能力。<em class='similar'>随着对Transformer模型研究的深入,</em><em class='similar'>逐渐衍生出了各种各样的变种模型。</em>但是,<em class='similar'>Transformer模型的表现往往与编码器块和解码器块的深度呈正相关。</em><em class='similar'>此外,</em><em class='similar'>模型维度越大,</em>模型的表达能力越强,<em class='similar'>识别的准确率和泛化能力越高,</em>但是会增加模型中各权值矩阵的维度,进而导致模型参数量和计算量的剧烈升高。比如,G. Synnaeve等人提出的改进Transformer模型[56]</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>和计算复杂度的剧烈增长。例如,<em class='similar'>Pham 等人构建了一个包含48个编码器块和48个解码器块的Transformer 模型,</em><em class='similar'>其参数量达到了252M</em><em class='similar'>[54];</em><em class='similar'>Synnaeve 等人搭建了一个包含24个编码器块的 Transformer 模型,</em><em class='similar'>在模型维度为1024的情况下,</em><em class='similar'>其参数量达到了</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>模型维度越大,模型的表达能力越强,识别的准确率和泛化能力越高,但是会增加模型中各权值矩阵的维度,进而导致模型参数量和计算量的剧烈升高。比如,G. Synnaeve等人提出的改进Transformer模型[56]使用了24个编码器网络块,<em class='similar'>在模型维度为1024的情况下,</em>得到的模型参数量为270M;N. Q.<em class='similar'> Pham等人构建了一个含有48个编码器网络块和48个解码器网络块的Transformer模型</em>[57],<em class='similar'>其参数量达到了252M。</em>为了实现Transformer模型的轻量化,近年来研究人员做出了各种尝试。文献<em class='similar'>[54]</em>提出了一种简化的自注意力机制,其使用FSMN块作为映射层完成状态序列的转换,相较于普通的自注意力机制,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>270M[55]</em><em class='similar'>。为了降低基于 Transformer 模型的参数量,</em><em class='similar'>研究人员做出了各种尝试。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>在模型维度为1024的情况下,<em class='similar'>得到的模型参数量为270M;</em>N. Q. Pham等人构建了一个含有48个编码器网络块和48个解码器网络块的Transformer模型[57],其参数量达到了252M。为了实现Transformer模型的轻量化,<em class='similar'>近年来研究人员做出了各种尝试。</em>文献[54]提出了一种简化的自注意力机制,其使用FSMN块作为映射层完成状态序列的转换,相较于普通的自注意力机制,<em class='similar'>模型参数量下降了20%;</em>文献[58]</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>侧重于以识别准确率的小幅度降低为代价,</em><em class='similar'>实现模型</em>参数量和计算复杂度的降低,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>实现基于轻量化网络空时域融合的单视角人体行为识别任务。⁞在实验过程中,为了尽可能减少模型参数,本章选用 MobileNet V3网络中的MobileNet V3-Small 模型,<em class='similar'>以降低少量识别准确率为代价,</em><em class='similar'>实现模型</em>的轻量化设计。⁞综上所述,本节提出了一种基于通道注意力机制的 MobileNet 轻量化网络空时融合单视角人体行为识别方法,首先利用 FPN 网络分别对预处理后的单视角人体行为距离像和时频图分别进行多尺度特征提取,</p>
	                    <div class="textFrom">——电子科技大学博士论文 陈朋云-《超宽带雷达人体目标行为智能识别方法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>从而在增加模型宽度和深度的同时能减少参数量和计算量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>在每模型深度为48层,在每个卷积层后加入Relu激活函数来增加模型的非线性。模型中Inception模块的主要思想是用密集成分来近似最优的局部稀疏结构[29],相比于图像识别领域的其他模型,<em class='similar'>增加了模型的深度和宽度,</em><em class='similar'>在减少参数和计算量的同时减轻过拟合,</em>其结构见图2,带有罗马数字的方块为Inception模块,内部结构见括号内。图2 GoogLeNet Inception-V3模型结构Fig.</p>
	                    <div class="textFrom">——《高压电器》 徐凯；梁志坚；张镱议；刘兴华；郑含博-《基于GoogLeNet Inception-V3模型的电力设备图像识别》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>且在每个卷积层后加入 ReLU 激活函数来增加模型的非线性,如图7所示。 Inception V3神经网络相比于图像识别领域的其他神经网络模型,<em class='similar'>增加了模型的深度和宽度,</em><em class='similar'>在显著减少参数和计算量的同时也减轻了⁞过拟合</em>[15]。⁞图7 Inception V3卷积拆分结构图⁞Fig.7 The split structure of Inception V3 convolutions⁞2.</p>
	                    <div class="textFrom">——世界竹藤通讯 李非非；杨帆；余飞；季猛；舒智慧；徐杰-《基于人工智能的竹类主要害虫识别系统开发与应用》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>直到 GoogleNet 诞生之前,主流的效果突破做法是让网络变得更深、更宽。但纯粹增大网络会导致模型在更新参数时发生梯度弥散,并增大了计算量。为此,<em class='similar'>需要在增加网络深度和宽度的同时减少模型的参数。</em>通过实验发现参数大部分都集中在全连接层中,在对其进行稀疏连接后参数量仍未减少,究其原因是计算机仅仅只优化了密集矩阵计算,并未开发出针对稀疏矩阵的优化方式。因此需要一种方法,</p>
	                    <div class="textFrom">——江苏大学硕士论文 何小飞-《改进CNN算法研究及其在夜晚背景下杂草与甜菜识别中的应用》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>Transformer 模型如图3-1所示,</em><em class='similar'>可以看出是一个典型的编—解码器结构。</em><em class='similar'>左侧为编码器,</em><em class='similar'>由若干个块</em><em class='similar'>(Block)</em>堆叠而成,<em class='similar'>每个块中包含两个子层,</em><em class='similar'>分别为多头注意力层和前馈网络层</em><em class='similar'>(Feedforward Network Layer,</em>FNL);<em class='similar'>右侧为解码器,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>数据集上实验表明&quot;局部—全局&quot;级联结构的融合注意力机制识别效果最好。⁞3.2自注意力机制与Transformer模型⁞Transformer模型的网络结构图如图3.1所示。⁞⁞图3.1 Transformer模型网络结构图⁞由图3.1可知,<em class='similar'>其是一个典型的编码器-解码器结构,</em>且内部不存在循环神经网络或卷积神经网络。图3.1左边是一个块<em class='similar'>(block)</em><em class='similar'>,通常编码器由若干个块堆叠而成。</em><em class='similar'>每个块中存在有两个子层,</em><em class='similar'>分别是多头注意力层和前馈网络层</em>(Position-wise Feed-forward Network, PFN)。解码器网络的结构和编码器类似,也由数个块堆叠而成。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>中较难解决的长期依赖问题。Transformer 的网络架构如图2.4所示,图片来自Vaswani A 等(2017),<em class='similar'>Transformer 是一个 encoder-decoder 的结构,</em><em class='similar'>由若干个编码器和解码器堆叠形成。</em><em class='similar'>图2.4的左侧部分为编码器,</em>由 Multi-Head Attention 和一个全连接层组成,用于将输入语料转化成特征向量。<em class='similar'>右侧部分为解码器,</em>其输入为编码器的输出以及已经预测的结果,由 Masked </p>
	                    <div class="textFrom">——上海财经大学硕士论文 贾鑫桐-《不平衡样本的多标签毒性文本分类 ——基于改进损失函数的神经网络模型》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>tion 机制将任意位置的两个单词的距离转换成1,有效的解决了 NLP 中棘手的长期依赖问题。Transformer 的网络架构如下图所示,<em class='similar'>Transformer 是一个 encoder-decoder 的结构,</em><em class='similar'>由若干个编码器和解码器堆叠形成。</em><em class='similar'>下图的左侧部分为编码器,</em>由 Multi-Head Attention 和一个全连接组成,用于将输入语料转化成特征向量。<em class='similar'>右侧部分是解码器,</em>其输入为编码器的输出以及已经预测的结果,</p>
	                    <div class="textFrom">——网页 -《人工智能之机器学习研究报告》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>Transformer 模型在文献[53]中被提出,摈弃了循环和卷积结构,是一个完全基于注意力机制的模型,由简单的编码器和解码器构成。<em class='similar'>Transformer 模型结构如图5-1所示。</em><em class='similar'>从图中可以看出,</em><em class='similar'>Transformer模型由编码器</em>(左边部分)和解码器(右边部分)组成。编码器部分由 self-attention和前馈神经网络组成,解码器部分由 Attention层、self-attention和前馈神经网络组成。</p>
	                    <div class="textFrom">——青海师范大学硕士论文 雷西唯-《基于深度学习的中文人物关系抽取研究与应用》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>处理和计算机视觉任务中取得了远超传统卷积神经网络(CNN)或长短时期记忆网络(LSTM)的表现。Transformer网络有两种类型,分别是编码器和解码器。一个Transformer编码器模块由若干个编码器和解码器堆叠形成。<em class='similar'>如下图的左侧部分为编码器,</em>由多头注意(Multi-Head Attention)和一个全连接组成,用于将输入语料转化成特征向量。<em class='similar'>右侧部分是解码器,</em>其输入为编码器的输出以及已经预测的结果,</p>
	                    <div class="textFrom">——科学技术创新 刘夏鸣-《一种基于迁移学习的视觉多任务模型探析》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>9])这两种常用方式来获得更好的训练效果,如下图中Add&amp;Norm模块所示。<em class='similar'>解码器</em>(Deocder):解码器同样由六个相同的解码层模块叠加而成,除了与编码器中相同的两个子网络层<em class='similar'>(multi-headattention多头注意力层和FeedForward全连接前馈层)</em>,解码器增加了第三个子网络层,该层也是multi-headattention层,该层提取了编码器隐藏层的信息。同样的,残差连接(residualconnection[8])和层参数正则化(layernormalization[9])</p>
	                    <div class="textFrom">——网页 -《Transformer 的一些说明》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>解码器块将多头注意力层替换为掩膜</em>(Masked)<em class='similar'>多头注意力层,</em><em class='similar'>并在之后级联了一个多头注意力层用于获取预测字符与语音特征间的相关性。</em><em class='similar'>每个子层之间都使用残差连接进行耦合,</em><em class='similar'>并在之后使用层归一化</em><em class='similar'>(Layer Normalization)</em><em class='similar'>对输出进行调整。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>tion-wise Feed-forward Network, PFN)。解码器网络的结构和编码器类似,也由数个块堆叠而成。相较于编码器块,<em class='similar'>解码器块将多头注意力替换为了掩膜多头注意力,</em><em class='similar'>并在掩膜多头注意力之后级联了一个多头注意力用于捕获预测字符与语音特征间的关联。</em><em class='similar'>每个子层之间都使用残差连接进行耦合,</em><em class='similar'>并在残差连接之后使用层归一化</em><em class='similar'>(Layer Normalization,</em> LN)<em class='similar'>对输出进行调整。</em>⁞3.2.1自注意力机制⁞Transformer中的编码器网络和解码器网络中频繁使用自注意力机制以从不同表示子空间获取大量的丰富信息。自注意力机制使用点积运算来计算序列中任意位置元素间的关联性。⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>sformer 模型分为编码器和解码器两部分,编码器由两个子层组成,分别是多头注意力层和前馈神经网络。解码器的结构与编码器相似,<em class='similar'>通过增添一个多头注意力层将编码器与解码器相连接。</em><em class='similar'>每个子层之后采用残差连接和层归一化</em><em class='similar'>(Layer Normalization)</em>操作,解决模型随网络层数加深而导致的梯度不稳定问题,并加快收敛速度,改进的 Transformer 模型如图26所示。⁞图26改进的 </p>
	                    <div class="textFrom">——西北大学硕士论文 兰志翔-《深浅层特征结合注意力增强的点云配准研究与应用》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>ormer的解码器结构解码器能够对已编码的表示进行检索。6个相同的层堆叠在一起每个解码层含有两个子层结构,一个是多头注意力机制,另一个是全连接前馈神经网络单元与编码器结构类似,<em class='similar'>每个解码器子层之间都采用残差连接方式,</em><em class='similar'>并且使用层归一化</em><em class='similar'>(layer normalization)</em>。第一个多头注意子层被修改,以防止当前位置参与到后面的子序列的位置中,因为我们不想在预测当前的位置时有目标序列的未来信息对其进行干扰。</p>
	                    <div class="textFrom">——网页 -《注意力机制的诞生、方法及几种常见模型-电子发烧友网》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>第二章相关技术和算法研究⁞经过 softmax 计算模型这一时刻输出词的概率分布。编码器由同构的层堆叠而成,每一层有两个子层,第一个子层是多头自注意力机制层第二个子层是全连接层,<em class='similar'>每个子层都使用残差连接</em>(residual connection)[53]和层归一化(layer normalizatoin)⁞[54]。解码器部分也是由同构的层堆叠而成,与编码器不同的是,<em class='similar'>解码器多了一个多头注意力机制子层,</em>用于对编码器的输出进行信息交互,其他子层与编码器相同,</p>
	                    <div class="textFrom">——电子科技大学硕士论文 秦展展-《基于深度学习的文本摘要相关技术研究与应用》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>在较新的文献中,</em><em class='similar'>常用线性层指代全连接层</em>[59]。<em class='similar'>因此,</em><em class='similar'>后续对这两种说法不加区分。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>以及其和普通全连接网络的对比。然后,构建基于分层分组线性变换的扩张缩放单元用于增强模型的表达能力,同时给出了其数学定义和拓扑描述。值得注意的是,<em class='similar'>在较新的文献中,</em><em class='similar'>常常用线性变换来指代全连接层。</em><em class='similar'>因此,</em><em class='similar'>本文对两种说法不加以区分。</em>⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。与普通全连接层使用的线性变换不同,分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>Transformer 模型中的编码器和解码器通过频繁地使用自注意力机制,</em><em class='similar'>从不同表示子空间中获取丰富的信息。</em><em class='similar'>自注意力机制使用点积运算来获取序列中任意位置元素间的相关性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>每个子层之间都使用残差连接进行耦合,并在残差连接之后使用层归一化(Layer Normalization, LN)对输出进行调整。⁞3.2.1<em class='similar'>自注意力机制⁞Transformer中的编码器网络和解码器网络中频繁使用自注意力机制以从不同表示子空间获取大量的丰富信息。</em><em class='similar'>自注意力机制使用点积运算来计算序列中任意位置元素间的关联性。</em>⁞考虑将一个长度为、向量维度(也称为模型维度)为的序列作为自注意力在一个表示子空间的输入。在表示子空间中,自注意力首先使用由三个不同的权值矩阵形成的全连接层将映射到向</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>q)为注意力打分函数,W, v, U 均为神经网络参数,在训练过程中发生变化,。为输入向量的维度。⁞多头自注意力机制是注意力机制在自然语言处理领域的一项重要应用,是被团队首次提出的,<em class='similar'>在Transformer模型中的编码器和解码器中均使用了多头自注意力机制。</em>假设输入为向量序列乙将其和三个不同的权重矩阵唯,Wq,伙做矩阵乘从而得到三个不同的向量,分别是:Query向量(Q),</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 郭令奇-《基于深度学习和社区论坛问答的专家推荐系统的设计与实现》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过多层双向Transformer编码器的训练后,得到文本序列的特征向量表示T1,T2,,TN。⁞图1 ALBERT模型结构⁞Fig.<em class='similar'>1 ALBERT model structure⁞基于自注意力机制Seq2Seq框架的Transformer模型,</em><em class='similar'>其结构为编码器-解码器,</em>模型结构如图2所示。ALBERT采用其编码器部分,编码器由N个相同的网络层堆叠而成,每个网络层有两个子网络层:第一层为多头自注意力层;第二层为前馈网络层,</p>
	                    <div class="textFrom">——计算机工程与应用 孙宝山；谭浩-《基于ALBERT-UniLM模型的文本自动摘要技术研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>步骤4:利用全连接层和softmax层对步骤3的输出进行处理,最终通过softmax函数得到单词的概率,最后通过贪心搜索的方式选择概率最大的词作为最后的输出,组成回应文本。45.进一步的,<em class='similar'>所述transformer模型包括编码器和解码器,</em><em class='similar'>其中,</em>所述编码器采用多头自注意力机制;所述解码器包括角色注意力模块、对话历史注意力模块以及注意力路由模块;以下对所述编码器和解码器进行详细说明:46.(一)编码器47.将角色信息和用户对话历史信息的文本转化为句子向量</p>
	                    <div class="textFrom">——网页 -《基于Transformer模型的对话生成方法及系统与流程》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_8" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">69.9%(1,029字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于障碍物图像感知的油气管道机器人路径规划策略研究" target="_blank">基于障碍物图像感知的油气管道机器人路径规划策略研究</a></span>
                      <p>戴耀南 -
                        《武汉工程大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.4%(65字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向不同语义粒度约束的文本生成方法研究" target="_blank">面向不同语义粒度约束的文本生成方法研究</a></span>
                      <p>潘囿丞 -
                        《哈尔滨工业大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(62字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=一种优化硬件延时的Transformer架构搜索算法" target="_blank">一种优化硬件延时的Transformer架构搜索算法</a></span>
                      <p>焦润 -
                        《南京大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向多类型消息的网络谣言传播机制研究" target="_blank">面向多类型消息的网络谣言传播机制研究</a></span>
                      <p>戴天骥 -
                        《重庆邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=一种基于GA的模糊神经网络控制器设计及应用" target="_blank">一种基于GA的模糊神经网络控制器设计及应用</a></span>
                      <p>戚志东;朱伟兴;毛务本;陆文昌 -
                        《江苏大学学报(自然科学版)
                        》- 2002 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于CUDA加速的目标检测算法研究" target="_blank">基于CUDA加速的目标检测算法研究</a></span>
                      <p>王润强 -
                        《电子科技大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的中文文本情绪分类方法研究" target="_blank">基于深度学习的中文文本情绪分类方法研究</a></span>
                      <p>高凯龙 -
                        《北京建筑大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向科技文献的学术知识图谱构建研究与应用" target="_blank">面向科技文献的学术知识图谱构建研究与应用</a></span>
                      <p>陈曦 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110471865.html" target="_blank">一种基于时频跨域特征选择的语音分离方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的方面级情感分析研究" target="_blank">基于深度学习的方面级情感分析研究</a></span>
                      <p>吴文乐 -
                        《郑州大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://www.doc88.com/p%2D24661725012047.html" target="_blank">多层感知器神经网络反向传播算法的实现与研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=改进YOLOv5s的遥感图像目标检测" target="_blank">改进YOLOv5s的遥感图像目标检测</a></span>
                      <p>赵文清;康怿瑾;赵振兵;翟永杰 -
                        《智能系统学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(22字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_8" class="simMore"><a href="javascript:$ShowMore(8);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>假设<em class='similar'>一个长度为</em>、<em class='similar'>向量维度</em><em class='similar'>(模型维度)</em><em class='similar'>为的序列为自注意力在表示子空间上的输入。</em><em class='similar'>在中,</em><em class='similar'>自注意力首先使用由三个不同的权重矩阵</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Transformer中的编码器网络和解码器网络中频繁使用自注意力机制以从不同表示子空间获取大量的丰富信息。自注意力机制使用点积运算来计算序列中任意位置元素间的关联性。⁞考虑将<em class='similar'>一个长度为</em>、<em class='similar'>向量维度</em><em class='similar'>(也称为模型维度)</em><em class='similar'>为的序列作为自注意力在一个表示子空间的输入。</em>在表示子空间中,<em class='similar'>自注意力首先使用由三个不同的权值矩阵形成的全连接层将映射到向量维度为的三个状态序列:</em>⁞(3.1)⁞(3.2)⁞(3.3)⁞式(3.1)-(3.3)<em class='similar'>中,</em></p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>形成的全连接层将映射到向量维度为的三个序列,</em>计算过程如下:</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>算来计算序列中任意位置元素间的关联性。⁞考虑将一个长度为、向量维度(也称为模型维度)为的序列作为自注意力在一个表示子空间的输入。在表示子空间中,<em class='similar'>自注意力首先使用由三个不同的权值矩阵形成的全连接层将映射到向量维度为的三个状态序列:</em>⁞(3.1)⁞(3.2)⁞(3.3)⁞式(3.1)-(3.3)中,、、——键(Key)向量、问询(Query)向量、值(Value)向量序列,、、⁞、、——、、各自对应的全连接网络权值矩阵,、、⁞然后,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>式中,</em><em class='similar'>,分别表示查询</em><em class='similar'>(Query)</em><em class='similar'>向量序列、</em><em class='similar'>键(</em><em class='similar'>Key)</em><em class='similar'>向量序列和值</em><em class='similar'>( Value )</em><em class='similar'>向量序列;</em><em class='similar'>,分别为对应的全连接网络权重矩阵。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>假设输入部分表示为𝑋=[𝑥1,𝑥2,.𝑥𝑛],输出部分表示为𝑌=[𝑦1,𝑦2,.𝑦𝑛],那么可以通过输入向量 X 乘以不同的系数 W,得到的Q、K、<em class='similar'>V 分别表示查询向量序列 query、</em><em class='similar'>键向量序列 key、</em><em class='similar'>和值向量序列 value,</em>公式表⁞示如下:⁞𝑄=𝑊𝑞𝑋(3-1)𝐾=𝑊𝐾𝑋(3-2)𝑉=𝑊𝑉𝑋(3-3)𝑊𝑞、𝑊𝑘、𝑊𝑣分别是参数矩阵。⁞由此可以得出输出矩阵 Y,</p>
	                    <div class="textFrom">——北京建筑大学硕士论文 高凯龙-《基于深度学习的中文文本情绪分类方法研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>在表示子空间中,自注意力首先使用由三个不同的权值矩阵形成的全连接层将映射到向量维度为的三个状态序列:⁞(3.1)⁞(3.2)⁞(3.3)⁞式(3.1)-(3.3)<em class='similar'>中,、、——键</em><em class='similar'>(Key)</em><em class='similar'>向量、</em>问询<em class='similar'>(Query)</em><em class='similar'>向量、</em>值(<em class='similar'>Value)</em><em class='similar'>向量序列,</em>、、⁞、、——、、<em class='similar'>各自对应的全连接网络权值矩阵,</em>、、⁞然后,使用Softmax函数将键向量序列和问询向量序列之间的点积运算结果进行概率化表示,进而得到和之间的注意力权重矩阵,最后将该注意力权重矩阵作用到值向量序列上就可以得到该表示子空间中的输出,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>⁞(,,) max()⁞T⁞k⁞K QAttention Q K V soft V⁞d⁞(4-1)⁞(,,)(1,,) oMultiHead Q K V Concat head headh W(4-2)<em class='similar'>⁞式中Q,</em>K,V分别是查询向量序列,<em class='similar'>键向量序列和值向量序列</em><em class='similar'>(Query,</em><em class='similar'>Key,⁞Value)</em>。(,,)Q K V⁞i i i ihead Attention QW KW VW。 kd 对内积进行缩放,避免softmax的结果非0即1。⁞为了扩大全局注意力的影响,</p>
	                    <div class="textFrom">——武汉工程大学博士论文 戴耀南-《基于障碍物图像感知的油气管道机器人路径规划策略研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>在此<em class='similar'>基础上</em>,<em class='similar'>将至中各个输出序列按维度拼接,</em><em class='similar'>通过一个全连接层即可</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>该表示子空间中的输出,计算过程见式(3.4)。⁞(3.4)⁞在式(3.4)中,使用了对点积计算结果进行了缩放,以便产生的梯度能够顺利地进行反向传播。⁞在单一表示子空间的注意力<em class='similar'>基础上</em>,<em class='similar'>将至各个表示子空间中计算得到的对应注意力输出序列按维度拼接,</em><em class='similar'>并通过一个全连接层即得到多头注意力输出:</em>⁞(3.5)⁞式(3.5)中,——按向量元素维度进行拼接⁞——输出权值矩阵,⁞在如图3.1所示的Transformer模型中,多头自注意力机制的使用方式有三种:⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>得到多头注意力的输出,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>)⁞T⁞i i i i i⁞k⁞Q KZ Attention Q K V V⁞d⁞=(3.5)⁞将 h 个 ihead 输出的 iZ 进行拼接,同时利用 OW 对拼接后的矩阵进行线性变⁞换,<em class='similar'>得到多头注意力机制的输出 Z,</em><em class='similar'> Z的计算过程如式</em>(3.6)所示。⁞12() O⁞hZ Concat Z Z Z W=,,,(3.6)⁞其中, OW 表示权重矩阵。多头注意力机制以2n dE ×∈作为输入,经过逐步⁞计算得到特征 Z,以 Z作为输出。⁞3.2.</p>
	                    <div class="textFrom">——郑州大学硕士论文 吴文乐-《基于深度学习的方面级情感分析研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>MLP)构成,并且每个模块内部采用残差连接。其⁞通道加权 C×H×W⁞中局部窗口大小为7,多层感知机隐藏层的嵌入维⁞度为4。<em class='similar'>多头自注意力机制的计算过程如下。</em>输出特征图⁞图5坐标注意力机制⁞Attention Q, K ,V  SoftMax QKT / d  BV (4)⁞Fig.</p>
	                    <div class="textFrom">——智能系统学报 赵文清；康怿瑾；赵振兵；翟永杰-《改进YOLOv5s的遥感图像目标检测》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>在 Transformer 模型中,</em><em class='similar'>模型维度通常指各模块输出向量的维度,</em><em class='similar'>取值常为256、</em><em class='similar'>512或1024</em><em class='similar'>(2的整数幂)</em><em class='similar'>。前馈网络层本质上是两层全连接网络,</em><em class='similar'>第一层全连接网络将扩张到更大的维度,</em><em class='similar'>第二个全连接网络再将维度还原。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>3.2.2 Transformer其余网络组件⁞在Transformer模型中,除了自注意力机制外,还有其它组件,它们对网络的性能表现也具有重要的作用。下面对这些组件进行简要介绍。⁞1.前馈网络层⁞在Transformer中,<em class='similar'>模型的维度通常指的是模型中各模块输出向量的维度,</em><em class='similar'>常取256、</em><em class='similar'>512、1024等2的整数次幂。</em><em class='similar'>前馈网络层实际上是两层全连接网络,</em><em class='similar'>它首先将扩张到更大的维度,</em><em class='similar'>再通过第二个全连接层进行维度还原。</em>前馈网络主要用于增强模型的拟合能力。式(3.6)描述了前馈网络的前向传播过程。⁞(3.6)⁞式(3.6)中,——线性整流激活函数⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>式中,<em class='similar'>表示激活函数;</em><em class='similar'>,分别表示两个全连接网络的权重矩阵;</em><em class='similar'>,分别表示两个全连接网络的偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>一个全连接网络2压缩全局特征描述子得到压缩特征描述子m为压缩后的特征维度,该压缩特征描述子是用来引导特征选择的,其计算过程如下,<em class='similar'>n代表全连接网络2的操作,</em><em class='similar'>δ代表sigmoid激活函数,</em><em class='similar'>w表示该全连接网络2的权重矩阵,</em>g表示全局特征描述子:z=δ(n(wg))再使用两个全连接层(全连接网络3和全连接网络4)将压缩特征描述子进行特征维度还原,分别得到时域特征描述子与时频域特征描述子aj表</p>
	                    <div class="textFrom">——网页 -《一种基于时频跨域特征选择的语音分离方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>[,,,,])fc t t t t t fcV W v f cc c ot b(4.6)⁞ˆ()u fc fcV W V b(4.7)⁞其中,V 表示第一层全连接输出的中间向量,<em class='similar'>表示 sigmoid 激活函数,</em>和⁞2fcW 表⁞示全连接网络的权重矩阵,<em class='similar'>⁞1fcb 和⁞2fcb 表示全连接网络的偏置矩阵,</em> ûV 表示第二层全连接输出的用户融合特征向量。⁞重庆邮电大学硕士学位论文第4章基于用户认知与多类型消息的转发态势预测模型⁞</p>
	                    <div class="textFrom">——重庆邮电大学硕士论文 戴天骥-《面向多类型消息的网络谣言传播机制研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>𝛼𝑒⁞𝑖𝑇⁞∙𝛼𝑜⁞𝑗⁞)⊘(∥𝛼𝑒⁞𝑖∥∥𝛼𝑜⁞𝑗⁞∥).(3.7)⁞其中,𝐴𝑡𝑡𝑛𝑖,𝑗表示第 j 个本体标签对第 i 个单词的注意力,⊘表示按元素相⁞除,<em class='similar'>∥∥表示向量的 L2范数。</em><em class='similar'>将权重矩阵经过一层全连接网络和激活函数,</em>得到每个单词关于本体标签的权重向量𝛽,如公式3.7-公式3.8所示。⁞𝜇𝑖=𝑚𝑎𝑥(𝑅𝑒𝐿𝑈(𝑊𝑎∙𝐴𝑡𝑡𝑛[𝑖−𝑠:𝑖+𝑠]+𝑏𝑎)).(3.8)</p>
	                    <div class="textFrom">——吉林大学硕士论文 陈曦-《面向科技文献的学术知识图谱构建研究与应用》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>且富含上下文语义信息,</em><em class='similar'>因此引入位置信息有助于增强表示序列内部关系的能力。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>⁞(3.6)⁞式(3.6)中,——线性整流激活函数⁞、——两个全连接层的权值矩阵,,⁞、——两个全连接层的偏置向量,,⁞2.位置编码⁞语音输入序列以及字符序列都是时间关联的序列,具有特定的排列顺序。<em class='similar'>排列顺序富含了上下文语义信息,</em><em class='similar'>因此在模型中引入位置信息有助于强化对序列内部关系进行表征的能力。</em>Transformer内部不存在RNN中的循环结构,无法利用天然包含在循环结构中的时序位置信息。如果不加以处理,注意力机制在不同上下文环境中会输出相同状</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong>的时序位置信息,<em class='similar'>注意力机制就会在不同上下文环境中输出相同的状态序列,</em><em class='similar'>进而导致位置信息完全丢失。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>息,因此在模型中引入位置信息有助于强化对序列内部关系进行表征的能力。Transformer内部不存在RNN中的循环结构,无法利用天然包含在循环结构中的时序位置信息。如果不加以处理,<em class='similar'>注意力机制在不同上下文环境中会输出相同状态序列,</em><em class='similar'>进而导致位置信息的完全丢失。</em>由此可见,在序列中附上各个向量的位置信息帮助模型进行学习是非常有必要的。Transformer模型引入了位置编码(Positional Encoding, PE)来表征序列内部向量间的位置信息。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong>因此,<em class='similar'>Transformer 模型中引入了位置编码</em><em class='similar'>(Positional Encoding,</em><em class='similar'>PE)</em><em class='similar'>来表示序列内部向量间的位置信息。</em><em class='similar'>将 PE 与输入序列进行加性组合,</em><em class='similar'>使得输入序列附带关于序列内部的位置信息,</em><em class='similar'>使得模型自身具备学习位置信息的能力。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>结构中的时序位置信息。如果不加以处理,注意力机制在不同上下文环境中会输出相同状态序列,进而导致位置信息的完全丢失。由此可见,在序列中附上各个向量的位置信息帮助模型进行学习是非常有必要的。<em class='similar'>Transformer模型引入了位置编码</em><em class='similar'>(Positional Encoding,</em><em class='similar'> PE)</em><em class='similar'>来表征序列内部向量间的位置信息。</em><em class='similar'>Transformer通过将PE与输入序列进行加性组合,</em><em class='similar'>使得输入序列被动地附有序列内部的位置信息,</em><em class='similar'>进而使模型自身具备学习位置信息的能力。</em>下面介绍PE的生成过程。⁞给定序列长度,表示PE编码过程生成的第个位置(时间步)、维度为(能被2整除)的位置编码向量。向量中每个元素由式(3.7)和式(3.8)得到。⁞(3.7)⁞(3.8)⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>⁞FFN(𝑥)= max(0,𝑥𝑊1+𝑏1)𝑊2+𝑏2(2-4)式中𝑊1,𝑊2,𝑏1,𝑏2———可学习的训练参数。⁞(3)位置编码⁞为了使模型在计算时能够体现出位置的先后顺序,<em class='similar'>Transformer引入了位置编码</em><em class='similar'>(Positional Encoding,</em><em class='similar'>PE)</em><em class='similar'>来表示序列中词语之间的相对或绝对位置关系,</em>从而解决了不使用循环神经网络或卷积神经网络所造成的无序问题。该位置编码表示采用与词嵌入相同的维度,以便与词嵌入表示相加一同作为编码器的输入。Transformer采用正弦和余弦函数交替生成每个</p>
	                    <div class="textFrom">——哈尔滨工业大学博士论文 潘囿丞-《面向不同语义粒度约束的文本生成方法研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>,解码器的输入是之前已翻译出的所有单词,即推理的过程仍然是自回归的,逐词地进行翻译。此外,由于抛弃了自回归的计算方式,词语之间的相对位置信息也被抹去,<em class='similar'>所以Transformer中也引入了位置编码</em><em class='similar'>(Positional Encoding)</em>来补充位置信息。模型的输入均通过Embedding层转换为定长的实值向量。下面介绍Transformer中⁞最重要的Attention机制。⁞2.1.1注意力机制⁞一段语句的词语之间的依赖关系可以通过一组权</p>
	                    <div class="textFrom">——南京大学硕士论文 焦润-《一种优化硬件延时的Transformer架构搜索算法》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>同时给出其数学定义和拓扑描述。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>实现了解码器的轻量化。⁞4.2基于分层分组线性变换的扩张缩放单元⁞本节首先给出分层分组线性变换的基本思想,以及其和普通全连接网络的对比。然后,构建基于分层分组线性变换的扩张缩放单元用于增强模型的表达能力,<em class='similar'>同时给出了其数学定义和拓扑描述。</em>值得注意的是,在较新的文献中,常常用线性变换来指代全连接层。因此,本文对两种说法不加以区分。⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>与普通全连接层使用的线性变换不同,</em><em class='similar'>分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接,</em><em class='similar'>如图3-2所示。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>在较新的文献中,常常用线性变换来指代全连接层。因此,本文对两种说法不加以区分。⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。<em class='similar'>与普通全连接层使用的线性变换不同,</em><em class='similar'>分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接。</em>在不同的网络层,通过设定神经元被划分的组数,可以控制整个网络的参数量。对于一个层全连接网络,与分别为第层的输入和输出,为层神经元所分的组数。对于普通全连接网络,其参数量为,若采用分层分组线性变换,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>⁞图4-1机器学习和深度学习⁞4.1卷积神经网络的理论与搭建⁞4.1.1卷积神经网络的基本结构⁞卷积神经网络由全连接神经网络发展而来,全连接神经网络的结构简单,<em class='similar'>每一⁞层的神经元与上一层的所有神经元相互连接就构成了网络,</em><em class='similar'>如图4-2所示。</em>使用全⁞连接神经网络的最大问题在于参数过多,处理一个仅仅几百像素的图片,都会产生⁞数十万个参数,产生计算速度缓慢,过拟合等问题,</p>
	                    <div class="textFrom">——电子科技大学硕士论文 王润强-《基于CUDA加速的目标检测算法研究》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong><em class='similar'>在不同的网络层,</em><em class='similar'>通过设定神经元被划分的组数,</em><em class='similar'>可以控制整个网络的参数量。</em>具体地,<em class='similar'>对于一个层全连接网络,</em><em class='similar'>与分别表示第层的输入和输出,</em><em class='similar'>表示第层的神经元的划分组数,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>在较新的文献中,常常用线性变换来指代全连接层。因此,本文对两种说法不加以区分。⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。与普通全连接层使用的线性变换不同,分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接。<em class='similar'>在不同的网络层,</em><em class='similar'>通过设定神经元被划分的组数,</em><em class='similar'>可以控制整个网络的参数量。</em><em class='similar'>对于一个层全连接网络,</em><em class='similar'>与分别为第层的输入和输出,</em><em class='similar'>为层神经元所分的组数。</em>对于普通全连接网络,其参数量为,若采用分层分组线性变换,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>)运算,把有相同规则后件的输入进行综合:4=43(6)4=(1,4)(7)第五层:去模糊化层,表示模糊控制的输出下列函数用模仿重心法进行解模糊:5=54=()4(8)=5=54(9)其中,<em class='similar'>和分别表示第层的第个神经元的输入和输出;</em>为第-1层的第个节点的连接权;,为隶属函数的中心和宽度;网络各层的连接权为1可见,该神经网络的每一层对应于模糊逻辑控制器的每一步计算,与常规神经网络不同之处是参数不再是体现于连接权而反映在连接点中[3]2算法的实</p>
	                    <div class="textFrom">——江苏大学学报(自然科学版) 戚志东；朱伟兴；毛务本；陆文昌-《一种基于GA的模糊神经网络控制器设计及应用》-2002 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过激活函数对神经网络输入。神经元的信号传递特性由如下的线性代数式定义[1]:(1.1)(1.2)1.2神经网络神经网络以分层结构为基本特征,根据功能的不同可分为三类[1]:输入层、隐藏层和输出层,如图2所示。<em class='similar'>神经元按所在网络层的不同,</em>分别称为源节点、隐藏节点和输出节点。根据网络中信息流动的不同,神经网络构造结构可分为[1]:前馈网络和递归网络。前馈网络结构中,</p>
	                    <div class="textFrom">——网页 -《多层感知器神经网络反向传播算法的实现与研究》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>14.</strong><em class='similar'>。可见,</em><em class='similar'>在网络层数和每层神经元个数相同的情况下,</em><em class='similar'>引入分组线性变换后,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>可以控制整个网络的参数量。对于一个层全连接网络,与分别为第层的输入和输出,为层神经元所分的组数。对于普通全连接网络,其参数量为,<em class='similar'>若采用分层分组线性变换,</em>其参数量为。<em class='similar'>可见,</em><em class='similar'>在网络层数和每层神经元个数相同的情况下,</em>分层分组线性变换的参数量是对应全连接网络的。⁞⁞图4.1分层分组线性变换示意图⁞采用稀疏化连接的分层分组线性变换能够以相对较少的参数量进行有效学习。第层中的各个神经元,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>15.</strong><em class='similar'>假设输入向量和输出向量分别为和,</em><em class='similar'>分组线性变换首先根据维度和构建个维度逐渐增加的中间层。</em><em class='similar'>因此,</em><em class='similar'>第层的输出向量比第层拥有更大的维度。</em><em class='similar'>若需要进行变换的向量维度能够被设置的最大组数整除,</em><em class='similar'>某一层的输出向量的</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>采用稀疏化连接的分层分组线性变换能够以相对较少的参数量进行有效学习。第层中的各个神经元,都能够通过多种路径到达输入向量的某个输入神经元,以降低信息在流动过程中的损失。<em class='similar'>令与分别代表输入向量和输入向量。</em><em class='similar'>分层分组线性变换首先根据维度和构建个维度逐渐增加的中间层。</em><em class='similar'>因此,</em><em class='similar'>层的输出向量比层的输出向量拥有更大的维度。</em><em class='similar'>若进行变换的向量维度能够被规定的最大组数整除,</em><em class='similar'>某一层的输出向量可以通过式</em>(4.1)得到。⁞(4.1)⁞式(4.1)中,——层所分组数,取值为⁞——层所使用的线性变换⁞——层所学习的权重⁞4.2.2扩张缩放单元⁞在分层分组线性变换的基础上,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_9" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">49.7%(446字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110367779.html" target="_blank">基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">12.6%(113字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110367779_2.html" target="_blank">基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程_2</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">8.8%(79字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=加强特征的时空图卷积轨道交通线网客流预测" target="_blank">加强特征的时空图卷积轨道交通线网客流预测</a></span>
                      <p>许晗 -
                        《北京建筑大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于概念交互图的长文本匹配研究" target="_blank">基于概念交互图的长文本匹配研究</a></span>
                      <p>郭苏州 -
                        《中原工学院硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于依存图卷积和文本片段搜索的方面情感三元组抽取模型" target="_blank">基于依存图卷积和文本片段搜索的方面情感三元组抽取模型</a></span>
                      <p>徐康;李霏;姬东鸿 -
                        《计算机工程
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的认知无线电网络功率控制方法研究" target="_blank">基于深度学习的认知无线电网络功率控制方法研究</a></span>
                      <p>梁风 -
                        《曲阜师范大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_9" class="simMore"><a href="javascript:$ShowMore(9);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>式中,表示分组线性变换操作;<em class='similar'>表示第层的可训练的权重矩阵;</em>表示第层的划分组数,值为。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>炸或者梯度消失问题的出现,为了避免此问题,对算子进行进一步优化,令,,进而将优化后算子扩展至拥有 Q 个通⁞道的图信号输入中,得到神经网络第层输出为⁞(3-13)<em class='similar'>其中是在特定层中的可训练权重矩阵,</em><em class='similar'>表示激活函数,</em><em class='similar'>表示第层的特征矩阵。</em>至此,可以得到 GCN 图卷积神经网络的信息传播过程。⁞3.2 BiLSTM 神经网络结构⁞3.2.1 LSTM 神经网络⁞长短时记忆网络 LSTM 是一种可以处理时间序列数据的神经网络模型,</p>
	                    <div class="textFrom">——北京建筑大学硕士论文 许晗-《加强特征的时空图卷积轨道交通线网客流预测》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现子域空间的交互,使用大池化方法得到终线性表示。图神⁞经网络的公式如下:⁞()=()()(3-5)⁞其中=+,图的邻接矩阵;是单位矩阵,表示的度矩阵,即:=∑;⁞是激活函数;()<em class='similar'>表示第层的可训练的权重矩阵;</em>()=,为输入的图顶点特征。⁞为充分利用文本信息,本文将利用传统的文本相似度计算方法,抽取出全局特征信息,将其与以上方法获得两个全局特征向量,拼接为一个向量表征,然后将该向量传入到分类器中,</p>
	                    <div class="textFrom">——中原工学院硕士论文 郭苏州-《基于概念交互图的长文本匹配研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>在分组线性变换的基础上,</em>加入残差连接,<em class='similar'>可以构建包含维度扩张和维度收缩两个阶段的&quot;钻石&quot;型缩放单元,</em>如图3-3所示。<em class='similar'>缩放单元由5个配置参数决定:</em><em class='similar'>深度</em><em class='similar'>(层数)</em><em class='similar'>、宽度因子、</em><em class='similar'>输入维度、</em><em class='similar'>输出维度和分组线性变换的最大组数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>取值为⁞——层所使用的线性变换⁞——层所学习的权重⁞4.2.2<em class='similar'>扩张缩放单元⁞在分层分组线性变换的基础上,</em><em class='similar'>可以构建含有维度扩张和维度收缩两个主要阶段的扩张缩放单元。</em>该单元首先将输入向量变换到更高维度,使网络具有比较强大的学习能力,再将维度进行收缩以匹配模型维度,进而减少整个模型的参数量。<em class='similar'>扩张缩放单元由5个参数进行描述:</em>(1)<em class='similar'>深度</em><em class='similar'>(层数)</em>;(2)<em class='similar'>宽度因子;</em>(3)<em class='similar'>输入维度;</em>(4)输出维度;(5)<em class='similar'>分层分组线性变换的最大组数。</em>⁞⁞(a)扩张缩放单元基本计算步骤(b)扩张缩放单元示意图(c)逐块缩放策略⁞图4.2扩张缩放单元和逐块缩放策略示意图⁞扩张缩放单元的示意图见图4.2(b)。在扩张阶段,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong><em class='similar'>基于分组线性变换,</em>可以形成网络更深、<em class='similar'>包含扩张和收缩两个阶段的&quot;缩放单元&quot;。</em>在扩张阶段,分组组数随着网络深度的加深而变多,神经元数量也会变多,反之亦然。<em class='similar'>在&quot;缩放单元&quot;中配置5个配置参数:</em><em class='similar'>深度n、</em><em class='similar'>宽度因子mw、</em><em class='similar'>输入维度dm、</em><em class='similar'>输出维度do、</em><em class='similar'>最大组数gmax。</em>在扩张阶段,该单元将维度为dm的输入序列映射到更高维度(限制最高维度dmax=mwdm),同时各层层数将会线性地增加到层。</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>然后使用混合器将分组的输入和输出混合,<em class='similar'>形成扩张和收缩两个阶段的&quot;缩放单元&quot;;</em>在扩张阶段,分组组数随着网络深度的加深而变多,神经元数量也会变多,反之亦然;在收缩阶段,<em class='similar'>&quot;缩放单元&quot;中配置5个配置参数:</em><em class='similar'>深度n、</em><em class='similar'>宽度因子mw、</em><em class='similar'>输入维度dm、</em><em class='similar'>输出维度do、</em><em class='similar'>最大组数gmax;</em>在扩张阶段,该单元将维度为dm的输入序列映射到更高维度,限制最高维度dmax=mwdm,</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程_2》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>层被逐层映射到最高维度为的向量;</em><em class='similar'>在收缩阶段,</em><em class='similar'>最高维度向量在剩下的层变换为输出维度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>b)扩张缩放单元示意图(c)逐块缩放策略⁞图4.2扩张缩放单元和逐块缩放策略示意图⁞扩张缩放单元的示意图见图4.2(b)。在扩张阶段,<em class='similar'>维度为的输入向量将在前层中被逐层映射到维度为的最高维度向量。</em><em class='similar'>在收缩阶段,</em><em class='similar'>使用剩余的层将最高维度变换到输出维度。</em>分层分组线性变换的输入为原始输入序列或中间层的输出结果,其中,为切分混合函数,图4.2(a)简要描述了扩张缩放单元的一个基本计算步骤。由图4.2(b)可知,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>分组线性变换的输入为原始输入序列或中间层输出结果,</em><em class='similar'>表示切分混合函数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>图见图4.2(b)。在扩张阶段,维度为的输入向量将在前层中被逐层映射到维度为的最高维度向量。在收缩阶段,使用剩余的层将最高维度变换到输出维度。<em class='similar'>分层分组线性变换的输入为原始输入序列或中间层的输出结果,</em>其中,<em class='similar'>为切分混合函数,</em>图4.2(a)简要描述了扩张缩放单元的一个基本计算步骤。由图4.2(b)可知,该计算步骤两个主要的操作,分别为函数的分组切分、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>同时各层层数将会线性地增加到层。在收缩阶段,将维度为dmax的向量线性地降低到do维度,收缩阶段将使用剩余的层:其中,yl为一个&quot;缩放单元&quot;中某一层l的输出,<em class='similar'>π为分组线性变换,</em><em class='similar'>π的输入为输入特征序列x或者中间层输出结果γ</em>(x,yl-1),函数γ首先将对yl-1进行切分,然后使用混合器将切分结果与输入特征序列x的切分结果进行合并,该过程为一个分组线性变换。</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>以第2层为例,</em><em class='similar'>首先将上一层的输出和原始输入根据该层组数按照相同规律进行切分,</em>得到、、和4个中间向量,前两者来自于,后两者来自于;<em class='similar'>然后按特定顺序合并和、</em>和,<em class='similar'>得到的两个向量即为的输</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>单元的一个基本计算步骤。由图4.2(b)可知,该计算步骤两个主要的操作,分别为函数的分组切分、混合器混合以及的分层分组线性变换。<em class='similar'>以第二层为例,</em>首先将上一层(Layer-1)<em class='similar'>的输出和原始输入根据该层组数,</em><em class='similar'>分别按照相同的切分规律进行切分得到4个中间向量,</em>其中前两个向量、拆分自,后两个向量、拆分自。<em class='similar'>然后按照顺序将、</em><em class='similar'>进行合并,</em>、进行合并,<em class='similar'>得到的两个向量即为的输出结果。</em>最后将的输出结果送入进行处理便得到最终输出。式(4.2)-(4.3)描述了第层输出的计算过程。⁞(4.2)⁞(4.3)⁞式(4.2)-(4.3)中,——分层分组线性变换,输入为序列或中间层输出结果⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>上式中,<em class='similar'>和分别表示第层的权重矩阵和偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>个隐藏层和一个具有节点的输出层组成。为了便于表示,层的索引为从0到。⁞设表示第层的节点数。隐藏层中的第层的输出向量表示为公式(3.7),⁞(3.7)⁞其中,<em class='similar'>和分别表示第层的输出向量、</em><em class='similar'>权重矩阵和偏置向量。</em>注意,第层的输入是第()层的输出,即。表示线性整流函数。⁞图3.1深度神经网络的结构⁞第3章基于深度学习的和速率求解方法⁞输出层生成优化后的功率分配。</p>
	                    <div class="textFrom">——曲阜师范大学硕士论文 梁风-《基于深度学习的认知无线电网络功率控制方法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>通过增加图卷积的层数可以帮助模型解决方面词和观点词距离较远的问题。依存图卷积层中第层节点的更新方式如式⁞(2)所示。⁞(2)⁞其中,代表句子中的第个单词在第层图卷积网络中的表达,<em class='similar'>和分别代表第层图卷积网络的⁞权重矩阵和偏置向量。</em>代表邻接强度分布,计算方式如式(3)所示。⁞(3)⁞2.3文本片段搜索层⁞经过依存图卷积层学习完句子中单词之间的依存句法关联之后,本文通过枚举所有可能的文本片段来生成候选方面词和观点词集合。</p>
	                    <div class="textFrom">——计算机工程 徐康；李霏；姬东鸿-《基于依存图卷积和文本片段搜索的方面情感三元组抽取模型》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>对于某些层数较深的网络,</em><em class='similar'>可以在其组件中嵌入含有逐块缩放策略的&quot;钻石&quot;型缩放单元,</em>如图3-3<em class='similar'>(c)</em>所示。<em class='similar'>每一个六边形表示一个缩放单元,</em><em class='similar'>对于处于位置</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>式(4.2)-(4.3)描述了第层输出的计算过程。⁞(4.2)⁞(4.3)⁞式(4.2)-(4.3)中,——分层分组线性变换,输入为序列或中间层输出结果⁞、<em class='similar'>——当前层的权值矩阵和偏置向量⁞对于某些复杂且较深的网络,</em><em class='similar'>可以在网络各子组件中嵌入逐块缩放的扩张缩放单元,</em>以适应计算过程中向量维度和深度的变化。图4.2<em class='similar'>(c)</em>为逐块缩放策略的示意图。图4.2<em class='similar'>(c)</em>中,<em class='similar'>每一个六边形为一个扩张缩放单元,</em><em class='similar'>对于一个位置</em>为的扩张缩放单元,其配置参数中的深度(层数)和宽度因子由式(4.4)-(4.5)得到。⁞(4.4)⁞(4.5)⁞式(4.4)-(4.5)中,——总的扩张缩放单元个数⁞——允许的最小深度,为超参数⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>上式中,和均<em class='similar'>为超参数</em>,<em class='similar'>分别表示最小深度和最大深度;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>还考虑构筑块之间的堆叠所造成的影响;在各个构筑块间引入不同的深度和宽度因子约束:其中,nb和为第b块&quot;缩放单元&quot;的深度和宽度因子,b表示总块数,nmin与nmax<em class='similar'>为超参数</em>,<em class='similar'>为设定的最小深度和最大深度;</em>每个块中,在&quot;缩放单元&quot;之后级联自注意力机制、互注意力机制和前馈网络,形成解码网络。本发明的有益效果在于:从模型算法角度出发,为解决语音识别在边缘计算设备上的轻量化部署难题提供一种新的方法,通过基于自适</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_10" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">72.3%(954字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=YOLO算法在目标检测中的研究进展" target="_blank">YOLO算法在目标检测中的研究进展</a></span>
                      <p>耿创;宋品德;曹立佳 -
                        《兵器装备工程学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=结合可见光纹理迁移的红外图像质量增强算法研究" target="_blank">结合可见光纹理迁移的红外图像质量增强算法研究</a></span>
                      <p>吴宇彬 -
                        《广东工业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=不平衡样本的图像分类算法研究" target="_blank">不平衡样本的图像分类算法研究</a></span>
                      <p>李林 -
                        《西安电子科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向中文APP用户评论数据的软件需求挖掘方法" target="_blank">面向中文APP用户评论数据的软件需求挖掘方法</a></span>
                      <p>王莹;郑丽伟;张禹尧;张晓妘 -
                        《计算机科学
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的语音带宽扩展技术" target="_blank">基于深度学习的语音带宽扩展技术</a></span>
                      <p>闫宇霆 -
                        《大连理工大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_10" class="simMore"><a href="javascript:$ShowMore(10);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>轻量级前馈网络层的结构如图3-4右侧所示,</em><em class='similar'>类似于普通前馈网络层,</em><em class='similar'>也由两层全连接网络组成。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>力的权值矩阵不必减小输入序列的维度,只需将计算得到的序列通过输出线性层映射到模型的维度。在此之后使用的编码器-解码器自注意力也是如此。最后使用轻量级前馈网络层代替普通前馈网络层进一步减少参数量。⁞4.3.2<em class='similar'>轻量级前馈网络层⁞类似于普通的前馈网络层,</em><em class='similar'>轻量级前馈网络层也由两层全连接网络组成。</em>其结构示意图见图4.4(b)。由于已经在解码器块中引入了扩张缩放单元用于构建较宽、较深的网络,因此不必在前馈网络层中对输入序列的维度进行扩张。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>rmer 模块输入首先进行位置编码操作,并通入多头注意力机制模块;然后与多头注意力机制模块的输入进行残差连接,并进行层归一化;<em class='similar'>接着通入由全连接网络组成的前馈网络层;</em>最后,将前馈层的输入输出相加,并进行层归一化,得到 Transformer模块的输出。⁞为了让梯度更好地反向传播至网络的浅层,将上采样模块与下采样模块时间维度尺⁞图4.3基于 </p>
	                    <div class="textFrom">——大连理工大学硕士论文 闫宇霆-《基于深度学习的语音带宽扩展技术》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>20)其中,Q,K,V 为输入,这里在计算时统一替换为 X 即可;h 为⁞Head 的数量,WQ⁞i ,WKi ,WV⁞i ,WO 为可学习的参数,d k 表示K 的编码维度。相比多头注意力层,前馈神经网络层相对较为简单,<em class='similar'>仅由两层全连接神经网络组成,</em>主要提供非线性变换,这⁞里的公式不再进行展开。⁞除了两个主要子层外,Transformer 对子层与子层之间的连接方式同样进行了设置,</p>
	                    <div class="textFrom">——计算机科学 王莹；郑丽伟；张禹尧；张晓妘-《面向中文APP用户评论数据的软件需求挖掘方法》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>假设<em class='similar'>收缩因子为</em>,<em class='similar'>轻量级前馈网络层的全连接层1将维度为</em><em class='similar'>(和模型维度一致)</em>的序列转变成维度为的序列,<em class='similar'>全连接层2再将序列维度还原至。</em><em class='similar'>假定普通前馈网络层需要先将序列维度扩张倍,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其结构示意图见图4.4(b)。由于已经在解码器块中引入了扩张缩放单元用于构建较宽、较深的网络,因此不必在前馈网络层中对输入序列的维度进行扩张。给定一<em class='similar'>个收缩因子</em>(),<em class='similar'>轻量级前馈网络层中的第一个全连接层将输入为模型维度的序列变换为维度为的序列,</em><em class='similar'>第二层全连接层将维度还原到模型维度。</em><em class='similar'>若普通前馈网络将序列维度扩张倍的,</em>那么在其他条件相同的情况下,轻量级前馈网络层的参数量将是前者的。⁞⁞(a)普通前馈网络层(b)轻量级前馈网络层⁞图4.4两种前馈网络层示意图⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>轻量级前馈网络层的参数量是普通前馈网络层的。</em>另外,<em class='similar'>轻量级前馈网络层的激活函数为最近提出的 MISH 激活函数</em>[60]。<em class='similar'>相比于 ReLU 激活函数,</em><em class='similar'>MISH 求得的梯度更加平滑,</em><em class='similar'>更有利于模型的训练。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>轻量级前馈网络层中的第一个全连接层将输入为模型维度的序列变换为维度为的序列,第二层全连接层将维度还原到模型维度。若普通前馈网络将序列维度扩张倍的,那么在其他条件相同的情况下,<em class='similar'>轻量级前馈网络层的参数量将是前者的。</em>⁞⁞(a)普通前馈网络层(b)轻量级前馈网络层⁞图4.4两种前馈网络层示意图⁞在激活函数方面,<em class='similar'>轻量级前馈网络层选择了最近提出的MISH激活函数</em>[61]。<em class='similar'>MISH激活函数求得的梯度相较于ReLU更加平滑,</em><em class='similar'>更有利于模型进行学习。</em>其表达式见式(4.6)。⁞(4.6)⁞4.3.3改进Transformer模型的结构⁞在第三章改进Transformer模型的基础上,采用本章所介绍的内容对解码器网络进行优化,进而得到如图4.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>模块的高效性与灵活性,因此 MTPT采用了由两层卷积操作构建的残差模块,首先将特征 F (内容特征或纹理特征)经卷积核尺寸为3的卷积操作,并使用激活函数Mish[53]进行非线性激活,<em class='similar'>相对于传统激活函数</em><em class='similar'>(例如 ReLU)</em><em class='similar'>,Mish 函数的梯度更加平滑,</em>能有效增强网络结构的性能。最后再经过一个卷积核尺寸同为3的卷积操作,⁞并与输入特征 F 逐像素累加得到提取特征,整体计算过程表示为⁞</p>
	                    <div class="textFrom">——广东工业大学硕士论文 吴宇彬-《结合可见光纹理迁移的红外图像质量增强算法研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>3基于缩放扩张单元的改进Transformer模型⁞本节介绍扩张缩放单元在Transformer解码器网络中的应用。本文在各个解码器网络块中采用上节所述的缩放扩张单元对基础网络进行了扩充,<em class='similar'>并对普通前馈网络层进行改进,</em><em class='similar'>得到轻量级的前馈网络层。</em>⁞4.3.1轻量级解码器块⁞通常来讲,增加Transformer模型表达能力主要有一下几种思路:(1)宽度缩放:增加模型中向量的维度以及各个映射的维度;(2)深度缩放:增加模型的深度;</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>模型每个卷积层中的通道域注意力输入,通过 H 和 W 维度上的非对称池化以及组合特征之后的1×1卷积增加注意力信息的细节;(2)<em class='similar'>利用 mish 激活函数来代替 relu 激活函数以获得更平滑的梯度;</em>(3)改进 CBAM 模型空间域上的注意力输入和融合方式,其一方面引入最大池化层和卷积层增加空间域上的软注意力输入,另一方面将自注意力模型与软注意力模型相结合使卷积神经网络可以有重点的关注图</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 李林-《不平衡样本的图像分类算法研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>借鉴了 Chien-Yao Wang 等[44]提出的CSPNet,CSPNet 主要解决了模型卷积过程中出现的重复问题,减少了模型的参数和计算量。激活函数也由 ReLU 替换为 Mish,<em class='similar'>Mish 相比 ReLU 具有更加平滑的梯度,</em>可以更好地保持模型准确度。⁞特征提取则采用了 SPP 和 PANet 两大改进,分别利用四个不同尺度的最大池化层对特征进行处理,最大化增大感受野面积,</p>
	                    <div class="textFrom">——兵器装备工程学报 耿创；宋品德；曹立佳-《YOLO算法在目标检测中的研究进展》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>(1)</em><em class='similar'>宽度缩放:</em><em class='similar'>增加模型中向量维度和各个映射维度;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>用上节所述的缩放扩张单元对基础网络进行了扩充,并对普通前馈网络层进行改进,得到轻量级的前馈网络层。⁞4.3.1轻量级解码器块⁞通常来讲,增加Transformer模型表达能力主要有一下几种思路:<em class='similar'>(1)</em><em class='similar'>宽度缩放:</em><em class='similar'>增加模型中向量的维度以及各个映射的维度;</em>(2)深度缩放:增加模型的深度;(3)结合宽度缩放和深度缩放。然而,上述策略在某些较小数据集上的作用比较有限。比如,对于THCHS30数据集,将Transformer模型的模型维度从512增加到1024时,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>(2)</em><em class='similar'>深度缩放:</em><em class='similar'>增加模型深度</em>(层数);</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>得到轻量级的前馈网络层。⁞4.3.1轻量级解码器块⁞通常来讲,增加Transformer模型表达能力主要有一下几种思路:(1)宽度缩放:增加模型中向量的维度以及各个映射的维度;<em class='similar'>(2)</em><em class='similar'>深度缩放:</em><em class='similar'>增加模型的深度;</em>(3)结合宽度缩放和深度缩放。然而,上述策略在某些较小数据集上的作用比较有限。比如,对于THCHS30数据集,将Transformer模型的模型维度从512增加到1024时,模型的参数量增加了4倍,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>体量较小的数据集上的表现差强人意。例如,针对THCHS-30数据集[62],<em class='similar'>将 Transformer 模型的模型维度从512增加至1024时,</em>其</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>宽度缩放:增加模型中向量的维度以及各个映射的维度;(2)深度缩放:增加模型的深度;(3)结合宽度缩放和深度缩放。然而,上述策略在某些较小数据集上的作用比较有限。比如,对于THCHS30数据集,<em class='similar'>将Transformer模型的模型维度从512增加到1024时,</em>模型的参数量增加了4倍,而CER变化不大。而在模型的各个块中均匀地增加模型的维度和深度,会导致模型参数量骤然上升。⁞⁞图4.3轻量级解码器块结构图⁞为了减少模型的总体参数量,将扩张缩放单元所采用的逐块缩放策略引入到模型中,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>在不同的解码器块中嵌入深度、</em><em class='similar'>宽度不均匀的缩放单元,</em><em class='similar'>并将普通的前馈网络层替换为改进的轻量级前馈网络层,</em><em class='similar'>形成轻量级解码器块,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong><em class='similar'>在不同的解码器块采用深度、</em><em class='similar'>宽度不均匀的扩张缩放单元,</em>可以在模型宽度和深度增加的同时进一步减少参数量。按照上述策略,在普通Transformer的解码器块中嵌入对应的扩张缩放单元,<em class='similar'>并将普通的前馈网络层替换为改进的轻量级前馈网络层</em>(Lightweight Position-wise Feedforward Network, LPFN),<em class='similar'>便形成了如图4.3所示的轻量级解码器块。</em>在每一个块中,首先通过一个扩张缩放单元完成输入序列的深度缩放和宽度缩放,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>本文在各个解码器网络块中采用上节所述的缩放扩张单元对基础网络进行了扩充,<em class='similar'>并对普通前馈网络层进行改进,</em><em class='similar'>得到轻量级的前馈网络层。</em>⁞4.3.1<em class='similar'>轻量级解码器块⁞通常来讲,</em>增加Transformer模型表达能力主要有一下几种思路:(1)宽度缩放:增加模型中向量的维度以及各个映射的维度;(2)深度缩放:增加模型的深度;(3)结合宽度缩放和深度缩放。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>力的权值矩阵不必减小输入序列的维度,只需将计算得到的序列通过输出线性层映射到模型的维度。在此之后使用的编码器-解码器自注意力也是如此。最后使用轻量级前馈网络层代替普通前馈网络层进一步减少参数量。⁞4.3.2<em class='similar'>轻量级前馈网络层⁞类似于普通的前馈网络层,</em>轻量级前馈网络层也由两层全连接网络组成。其结构示意图见图4.4(b)。<em class='similar'>由于已经在解码器块中引入了扩张缩放单元用于构建较宽、</em>较深的网络,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>在每一个块中,</em><em class='similar'>首先通过一个缩放单元完成输入序列的深度缩放和宽度缩放,</em><em class='similar'>配置参数中的深度和宽度因子将逐块增加,</em><em class='similar'>越靠近输出端,</em><em class='similar'>缩放单元的结构会变得越深、</em><em class='similar'>越宽;</em><em class='similar'>解码器中的自注意力机制和普通自注意力机制有所不同,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并将普通的前馈网络层替换为改进的轻量级前馈网络层(Lightweight Position-wise Feedforward Network, LPFN),便形成了如图4.3所示的轻量级解码器块。<em class='similar'>在每一个块中,</em><em class='similar'>首先通过一个扩张缩放单元完成输入序列的深度缩放和宽度缩放,</em><em class='similar'>扩张缩放单元配置参数中的深度和宽度因子将逐块增加。</em><em class='similar'>越靠近输出端,</em><em class='similar'>扩张缩放单元内部结构将变得更宽、</em><em class='similar'>更深。</em>其次,<em class='similar'>解码器端自注意力机制和普通自注意力机制有所不同,</em>普通自注意力机制使用的三个权值矩阵通常用于将输入序列维度减小以减小计算量。而在轻量级解码器块中,由于扩张缩放单元的输出向量维度较低,因此前面的解码器掩膜自注意力的权值矩阵不</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>普通自注意力机制使用的三个权重矩阵通常将输入序列维度减小,</em><em class='similar'>而在轻量级解码器块中,</em><em class='similar'>由于缩放单元的输出向量维度较低,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并将普通的前馈网络层替换为改进的轻量级前馈网络层(Lightweight Position-wise Feedforward Network, LPFN),便形成了如图4.3所示的轻量级解码器块。在每一个块中,首先通过一个扩张缩放单元完成输入序列的深度缩放和宽度缩放,扩张缩放单元配置参数中的深度和宽度因子将逐块增加。越靠近输出端,扩张缩放单元内部结构将变得更宽、更深。其次,解码器端自注意力机制和普通自注意力机制有所不同,<em class='similar'>普通自注意力机制使用的三个权值矩阵通常用于将输入序列维度减小以减小计算量。</em><em class='similar'>而在轻量级解码器块中,</em><em class='similar'>由于扩张缩放单元的输出向量维度较低,</em>因此前面的解码器掩膜自注意力的权值矩阵不</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>必再次减小输入序列的维度,</em><em class='similar'>只需将计算得到的序列通过线性层映射至模型维度;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>权值矩阵通常用于将输入序列维度减小以减小计算量。而在轻量级解码器块中,由于扩张缩放单元的输出向量维度较低,<em class='similar'>因此前面的解码器掩膜自注意力的权值矩阵不必减小输入序列的维度,</em><em class='similar'>只需将计算得到的序列通过输出线性层映射到模型的维度。</em>在此之后使用的编码器-解码器自注意力也是如此。最后使用轻量级前馈网络层代替普通前馈网络层进一步减少参数量。⁞4.3.2轻量级前馈网络层⁞类似于普通的前馈网络层,轻量级前馈网络层也由两层全连接网络组成。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>之后的编—解码器自注意力也是如此;</em><em class='similar'>最后使用轻量级前馈网络层代替普通前馈网络层进一步降低参数量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>,由于扩张缩放单元的输出向量维度较低,因此前面的解码器掩膜自注意力的权值矩阵不必减小输入序列的维度,只需将计算得到的序列通过输出线性层映射到模型的维度。<em class='similar'>在此之后使用的编码器-解码器自注意力也是如此。</em><em class='similar'>最后使用轻量级前馈网络层代替普通前馈网络层进一步减少参数量。</em>⁞4.3.2轻量级前馈网络层⁞类似于普通的前馈网络层,轻量级前馈网络层也由两层全连接网络组成。其结构示意图见图4.4(b)。由于已经在解码器块中引入了扩张缩放单元用于构建较宽、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong>在原始 Transformer 模型的基础上,<em class='similar'>采用上述内容对解码器进行优化,</em><em class='similar'>得到如图3-6所示的改进 Transformer 模型。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>61]。MISH激活函数求得的梯度相较于ReLU更加平滑,更有利于模型进行学习。其表达式见式(4.6)。⁞(4.6)⁞4.3.3改进Transformer模型的结构⁞在第三章改进Transformer模型的基础上,<em class='similar'>采用本章所介绍的内容对解码器网络进行优化,</em><em class='similar'>进而得到如图4.5所示的改进的轻量化Transformer模型。</em>其中,编码器采用&quot;ALDSA-自注意力&quot;级联形式的融合注意力机制以完成语音特征的高效提取。解码器网络由基于分</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong><em class='similar'>解码器由若干个轻量级解码器块堆叠而成,</em><em class='similar'>用于实现整个模型的轻量化。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>进而得到如图4.5所示的改进的轻量化Transformer模型。其中,编码器采用&quot;ALDSA-自注意力&quot;级联形式的融合注意力机制以完成语音特征的高效提取。<em class='similar'>解码器网络由基于分组线性变换的解码器块堆叠而成,</em><em class='similar'>用于实现整个模型的轻量化。</em>⁞⁞图4.5改进的轻量化Transformer编解码器模型⁞4.4实验配置⁞为了验证改进的模型在中英文不同语种下的识别效果和轻量化效果,本章实验同样选择了中文AISHELL-1普通话数据集以</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_11" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">28.7%(378字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://blog.csdn.net/qq_34218078/article/details/127197163" target="_blank">语音和噪声相关数据集(持续更新)_凌逆战的博客-CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">9%(118字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向声纹识别的神经网络损失函数研究" target="_blank">面向声纹识别的神经网络损失函数研究</a></span>
                      <p>王岩 -
                        《北京林业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">5.7%(75字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图像监测的微量移液技术的研究" target="_blank">基于图像监测的微量移液技术的研究</a></span>
                      <p>尚志武,周士琦 -
                        《工程设计学报
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4.6%(60字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于生成对抗网络的人脸矫正研究与实现" target="_blank">基于生成对抗网络的人脸矫正研究与实现</a></span>
                      <p>闵文超 -
                        《电子科技大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">4.5%(59字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=AISHELL-" target="_blank">AISHELL-</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(56字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习和面积占有率的群养猪饮水行为识别" target="_blank">基于深度学习和面积占有率的群养猪饮水行为识别</a></span>
                      <p>张凯中 -
                        《江苏大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="https://www.doc88.com/p%2D66216953226653.html" target="_blank">基于深度学习SuperGlue算法的单目视觉里程计_刘帅</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="https://blog.csdn.net/colleges/article/details/122144163" target="_blank">3-Python数据划分代码-小记_骑着蜗牛环游深度学习世界的博客-CSDN博客_划分数据集python代码</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_11" class="simMore"><a href="javascript:$ShowMore(11);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>实验环境包含硬件和软件两部分。<em class='similar'>在硬件方面,</em><em class='similar'>主要使用一台高性能服务器完成所有模型的训练,</em><em class='similar'>其主要配置为:</em><em class='similar'>处理器</em><em class='similar'>(Central Processing Unit,</em><em class='similar'>CPU)/2×Intel</em><em class='similar'>(R)</em><em class='similar'> Xeon(</em><em class='similar'>R)</em><em class='similar'> CPU E5-2680 v4@2.40GHz;</em><em class='similar'>内存</em>(Memory)</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>该词汇表共含有503个建模单位。⁞3.5实验配置⁞本节首先给出实验的软硬件环境,然后从网络模型的超参数配置、模型评价指标等方面描述模型的详细训练信息。⁞3.5.1实验环境⁞在硬件方面,<em class='similar'>本文使用了一台高性能服务器来完成所有模型的训练。</em><em class='similar'>其主要配置为:</em><em class='similar'>处理器CPU/2×Intel</em><em class='similar'>(R)</em><em class='similar'> Xeon(</em><em class='similar'>R)</em><em class='similar'> CPU E5-2680 v4@2.40GHz;</em>内存Memory/8×ECC Registered DDR4@32GB;显卡GPU/4×NVIDIA Tesla P100@16GB。<em class='similar'>⁞在软件方面,</em>本文所有实验都在Ubuntu 18.04操作系统,Python3.7编程语言以及深度学习框架Pytorch 1.3的环境下进行。实验详细软硬件配置见表3.4。⁞表3.4实验软硬件配置⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>为所有图像检测68个人脸关键点,并保存到包含对应图像文件名的.68pt 文件中。⁞4.5.2实验环境⁞本文所使用的服务器详细配置如下:⁞操作系统:Ubuntu 16.04⁞CPU:Intel<em class='similar'>(R)</em><em class='similar'> Xeon(</em><em class='similar'>R)</em><em class='similar'> CPU E5-2680 v4@2.40GHz,</em><em class='similar'>56核⁞内存:</em>125GB⁞GPU:8张 Ge Force GTX 1080Ti 显卡⁞显存:8*11GB=88GB 电子科技大学硕士学位论文⁞38⁞第三方库:tensorflow 1.0,Cuda 8.0,cudnn 5.1⁞4.5.</p>
	                    <div class="textFrom">——电子科技大学硕士论文 闵文超-《基于生成对抗网络的人脸矫正研究与实现》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>素。利用labelme软件对移液区域进行标记制作成标签集,将样本集和标签集的80%组合成训练集,20%组合成⁞测试集。⁞2)模型训练。⁞实验中采用型号为 Intel<em class='similar'>(R)</em><em class='similar'>Xeon(</em><em class='similar'>R)</em>Gold 6136的 CPU<em class='similar'>(central processing unit,</em><em class='similar'>中央处理器)</em>,其内⁞存为12 GB。采用CPU模式,分别对剪枝前后U-Net模型进行训练。模型训练参数的配置如表1。其中:&quot;resolution&quot;表示图像训练样本的分辨率;&quot;imgs_set&quot;⁞表示训练样本总数;</p>
	                    <div class="textFrom">——工程设计学报 尚志武,周士琦-《基于图像监测的微量移液技术的研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>/8×ECC Registered DDR4@32GB;</em><em class='similar'>显卡</em><em class='similar'>(GPU)/4×NVIDIA Tesla P100@16GB;</em><em class='similar'>在软件方面,</em><em class='similar'>所有模型的训练都在 Ubuntu 18.04系统下完成,</em><em class='similar'>编程语言为 Python </em>3.6.9,<em class='similar'>深度学习框架为 PyTorch 1.</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其主要配置为:处理器CPU/2×Intel(R) Xeon(R) CPU E5-2680 v4@2.40GHz;<em class='similar'>内存Memory/8×ECC Registered DDR4@32GB;</em><em class='similar'>显卡GPU/4×NVIDIA Tesla P100@16GB。</em><em class='similar'>⁞在软件方面,</em><em class='similar'>本文所有实验都在Ubuntu 18.04操作系统,</em>Python3.7编程语言以及深度学习框架Pytorch 1.3的环境下进行。实验详细软硬件配置见表3.4。⁞表3.4实验软硬件配置⁞类型型号规格⁞处理器CPU Intel(R) Xeon(R) CPU E5-2680 v4@2.40GHz 2⁞显卡GPU NVIDIA Tesla P10016GB×4⁞内存 ECC Registered DDR4@32GB 32GB×4⁞硬盘西部数据SSD阵列21TB⁞麦克风 Actins ATS3605D 1⁞操作系统 Ubuntu 18.04-⁞编程语言 Python3.7-⁞深度学习框架 Pytorch 1.3-⁞3.5.2模型训练配置⁞1.超参数配置⁞在所有实验中,模型的维度和注意力的头数(表示子空间个数)分别为和。ALDSA的超参数设置为、。对于所有的残差连接,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>为保证实验结果的有效性,本文实验均利用同一设备在相同的环境下完成.实验环境为: CPU 型号为 i7G9700k ,<em class='similar'>显卡为 GeForceRTX2080,</em>显存为32GB ,<em class='similar'>系统为 Ubuntu16.04pytorch 深度学习框架,</em><em class='similar'>编程语言为 Python .</em>3.1数据集本文使用 KITTI 室外场景的 VO 数据集作为验证算法的实验数据集,数据集包含了相同场景下视点、光照等发生变化的图像,以验证 SGGVO 在视点、光照发生变化的图像上的性能表现.</p>
	                    <div class="textFrom">——网页 -《基于深度学习SuperGlue算法的单目视觉里程计_刘帅》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>CPU 为 Inter Core i5-7500,主频为3.40 GHz,64GB内存,1TB 硬盘,显卡为 NVIDA GeForce GTX1080,系统为 Ubuntu 16.04,<em class='similar'>编程语言为Python,</em><em class='similar'>使用 TensorFlow 深度学习框架,</em>使用 visual studio 2017软件编写程序。⁞2.2实验样本库的建立⁞群养猪分割实验的训练数据从前3天获取的视频段中采集2000张,测试数据从后2天的视频段中采集400张,</p>
	                    <div class="textFrom">——江苏大学硕士论文 张凯中-《基于深度学习和面积占有率的群养猪饮水行为识别》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>来自于400个来自中国不同口音区域的发言人,</em><em class='similar'>以44.1KHz</em><em class='similar'>(高保真麦克风)</em><em class='similar'>和16kHz</em><em class='similar'>(Android 或 iOS 系统手机)</em>的采</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong><em class='similar'>Android系统手机</em><em class='similar'>（16kHz，</em>16-bit&amp;#xff09 xff1b;<em class='similar'>iOS系统手机</em><em class='similar'>（16kHz，</em>16-bit）。高保真麦克风录制的音频降采样为16kHz。<em class='similar'>400名来自中国不同口音区域的发言人参与录制。</em>⁞AISHELL-2中文语音数据库⁞时长为1000小时，其中718小时来自AISHELL-ASR0009，282小时来自AISHELL-ASR0010。录音文本涉及唤醒词、</p>
	                    <div class="textFrom">——网页 -《语音和噪声相关数据集(持续更新)_凌逆战的博客-CSDN博客》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>本研究使用的数据集是:AISHELL-2,希尔贝壳公司开源的中文普通话语音数据⁞集。录制环境为安静室内环境,3种来自不同信道的音频,同时使用3种不同设备:<em class='similar'>⁞高保真麦克风</em><em class='similar'>(44.1kHz,</em>16-bit)<em class='similar'>; Android系统手机</em><em class='similar'>(16kHz,</em>16-bit); iOS系统的手机⁞<em class='similar'>(16kHz,</em>16-bit)。⁞AISHELL-2数据集全称希尔贝壳中文普通话开源语音数据库,<em class='similar'>1991名录音者来⁞自于中国有着不同口音的不同区域。</em></p>
	                    <div class="textFrom">——北京林业大学硕士论文 王岩-《面向声纹识别的神经网络损失函数研究》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>不同口音区域的发言人参与录制。⁞AISHELL-3高保真中文语音数据库⁞时长为85小时88035句，可做为多说话人合成系统。录制过程在安静室内环境中，<em class='similar'>使用高保真麦克风</em><em class='similar'>（44.1kHz，</em>16bit）<em class='similar'>。218名来自中国不同口音区域的发言人参与录制。</em>⁞AISHELL-WakeUp-1中英文唤醒词语音数据库⁞AISHELL-DMASH 中文普通话麦克风阵列家居场景语音数据库⁞AISHELL-4多通道中文会议语音数据库⁞</p>
	                    <div class="textFrom">——网页 -《语音和噪声相关数据集(持续更新)_凌逆战的博客-CSDN博客》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>样率进行录制,<em class='similar'>录制过程在安静室内环境中进行,</em><em class='similar'>内容涉及智能家居、</em><em class='similar'>无人驾驶、</em><em class='similar'>工业生产等11个领域;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>音信号和文本标签预处理流程。⁞3.4.1实验数据集介绍⁞AISHELL-1数据集含有约170小时的语音数据,来自于400个拥有不同性别、口音和年龄的说话人。<em class='similar'>内容覆盖智能家居、</em><em class='similar'>无人驾驶、</em><em class='similar'>工业生产等11个领域。</em><em class='similar'>录制过程在安静室内环境中进行。</em>AISHELL-1被划分为训练集、验证集和测试集三个子集。其中训练集由120098段语音组成,时长约150小时;验证集由14326段语音组成,时长约10小时;测试集由7176段语音组成,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>4.1录制环境4.2录制设备4.3录制方法6.1目录结构6.2命名规则6.2.1目录命名规则6.2.2文件命名规则产品概述此中文普通话语音数据库共500小时。<em class='similar'>录音文本涉及智能家居、</em><em class='similar'>无人驾驶、</em><em class='similar'>工业生产等11个领域。</em>邀请800名来自中国不同口音区域发音人参与录制。<em class='similar'>录制过程在安静室内环境中,</em>同时使用3种不同设备:高保真麦克风(44.1kHz,16bit,500H);Android 系统手机(16kHz,16bit,</p>
	                    <div class="textFrom">——网页 -《AISHELL-》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>验证集</em>(Val)<em class='similar'>和测试集</em>(Test)三个子集,<em class='similar'>前者的划分比例参照文献</em>[63],</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>是相对路径。output_dir：训练集、<em class='similar'>测试集、</em>验证集文件所在的目录，是相对路径。split_prop：划分比例的列表。<em class='similar'>这里参照了文献的划分比例，</em>即[训练集:<em class='similar'>验证集:</em><em class='similar'>测试集]</em>=[3:1:2]。该列表共三个元素，例如[3,1,2]，表示[训练集:<em class='similar'>验证集:</em><em class='similar'>测试集]</em>=[3:1:2]。⁞3划分过程⁞3.1读取待划分数据⁞这里使用了numpy.</p>
	                    <div class="textFrom">——网页 -《3-Python数据划分代码-小记_骑着蜗牛环游深度学习世界的博客-CSDN博客_划分数据集python代码》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_12" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">53.6%(952字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多任务学习的坐姿检测系统研究与实现" target="_blank">基于多任务学习的坐姿检测系统研究与实现</a></span>
                      <p>胡昊杰 -
                        《华南理工大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(62字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=非线性幂变换Gammachirp滤波器的鲁棒语音特征提取*" target="_blank">非线性幂变换Gammachirp滤波器的鲁棒语音特征提取*</a></span>
                      <p> -
                        《计算机科学与探索
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(60字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于特征压缩激活网络的肺部CT图像分割算法研究" target="_blank">基于特征压缩激活网络的肺部CT图像分割算法研究</a></span>
                      <p>贺梦婷 -
                        《吉林大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(57字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络的语音分离及其DSP实现" target="_blank">基于神经网络的语音分离及其DSP实现</a></span>
                      <p>李光鹏 -
                        《内蒙古大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于低资源语音识别系统的硬件实现" target="_blank">基于低资源语音识别系统的硬件实现</a></span>
                      <p>雷杰 -
                        《辽宁大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络" target="_blank">GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络</a></span>
                      <p>倪伟健;秦会斌 -
                        《电子技术应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于残差网络和门控卷积网络的语音识别研究" target="_blank">基于残差网络和门控卷积网络的语音识别研究</a></span>
                      <p>朱学超;张飞;高鹭;任晓颖;郝斌 -
                        《计算机工程与应用
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=一种基于前馈序列记忆神经网络的改进方法" target="_blank">一种基于前馈序列记忆神经网络的改进方法</a></span>
                      <p>梁翀;刘迪;浦正国;张彬彬 -
                        《山东农业大学学报(自然科学版)
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110488262.html" target="_blank">一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=小词汇量语音识别在煤炭装船系统中的应用研究" target="_blank">小词汇量语音识别在煤炭装船系统中的应用研究</a></span>
                      <p>常璟杰 -
                        《北京交通大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于轻量级网络的信号识别研究" target="_blank">基于轻量级网络的信号识别研究</a></span>
                      <p>纪衡 -
                        《电子科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_12" class="simMore"><a href="javascript:$ShowMore(12);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>字单字符作为基本建模单位,</em><em class='similar'>故对应的评价指标为字错误率</em><em class='similar'>(Character Error Rate,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>错误率(Label Error Rate, LER)作为评价语音识别系统准确率的性能评价指标。对于采用不同建模单位的语音识别系统,其计算方式大同小异。对于AISHELL-1数据集,<em class='similar'>其以汉字单字符为建模单位,</em>本文使用字错误率<em class='similar'>(Character Error Rate,</em> CER)来描述其准确度;对于TED-LUM2,其以一元模型为基本建模单位,<em class='similar'>对应指标为单词错误率</em>(Word Error Rate, WER)。CER和WER计算方式见式(3.17)</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>并通过训练集数据训练一个字符级3-元语言模型,通过浅融合集成到束搜索中,其中设置语言模型权重为0.2。⁞(3)实验评价指标:为了测试识别结果的准确性,<em class='similar'>本实验使用的评价指标为字错误率</em><em class='similar'>(character error rate,</em>⁞CER),其公式如下:⁞CER= R+ I+D⁞N (11)⁞其中,R 为替换错误字数,I 为插入错误字数,D 为删除错误字数,N 是正确标签序列的总字数。⁞3.3模型的性能比较⁞</p>
	                    <div class="textFrom">——计算机工程与应用 朱学超；张飞；高鹭；任晓颖；郝斌-《基于残差网络和门控卷积网络的语音识别研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>对应的评价指标为词错误率</em><em class='similar'>(Word Error Rate,</em><em class='similar'>WER)。</em>二者定义如下:</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其中 egs 为 Kaldi 提供的一些例程的脚本,tools 为 Kaldi 训练过程中采用的工具(例如 openFst),而 src⁞是 kaldi 执行的源代码。⁞在语音识别领域中,<em class='similar'>最为常用的评价指标是词错误率</em><em class='similar'>(Word Error Rate,</em><em class='similar'>WER),</em>WER 的统计方式是对于一句输入的语段,在已知标注词序列和语音识⁞第4章语音识别系统的搭建与硬件实现⁞45⁞别结果的条件下,将识别结果中的插入词错误,</p>
	                    <div class="textFrom">——辽宁大学硕士论文 雷杰-《基于低资源语音识别系统的硬件实现》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>PTB和Wiki9任务等常见任务,给出常见算法与本文改进算法在词错误率<em class='similar'>(Word Error Rate,</em><em class='similar'>WER)</em><em class='similar'>评价指标上的对比。</em>⁞在相同的 SWB 数据库上,对比不同声学模型的迭代训练时间。以交叉熵(CE)准则为判断依据,在相同的硬件配置条件下训练,本文选择单 Nvidia Tesla K20 GPU。实验结果见表1,</p>
	                    <div class="textFrom">——山东农业大学学报(自然科学版) 梁翀；刘迪；浦正国；张彬彬-《一种基于前馈序列记忆神经网络的改进方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>式中,</em><em class='similar'>分别表示相较于参考文本替换/增加/删除的字符</em><em class='similar'>(单词)</em><em class='similar'>数;</em><em class='similar'>表示参考文本的字符</em><em class='similar'>(单词)</em>数目。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对于TED-LUM2,其以一元模型为基本建模单位,对应指标为单词错误率(Word Error Rate, WER)。CER和WER计算方式见式(3.17)。⁞(3.17)⁞式(3.17)<em class='similar'>中,——相较于参考文本替换的字符</em><em class='similar'>(单词)</em><em class='similar'>数⁞——相较于参考文本增加的字符</em><em class='similar'>(单词)</em><em class='similar'>数⁞——相较于参考文本删除的字符</em><em class='similar'>(单词)</em><em class='similar'>数⁞——参考文本的字符</em><em class='similar'>(单词)</em>数⁞3.6实验结果及分析⁞本小结首先探索自注意力机制和ALDSA在拓扑结构上的结合方式,通过消融实验得到最优的融合注意力机制。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>下,<em class='similar'>其 MACs 值约是另一个常见的反映网络复杂度的指标——浮点运算数</em><em class='similar'>(Floating Point Operations,</em><em class='similar'>FLOPs)</em><em class='similar'>的。</em><em class='similar'>对于一层将输入维度映射为输</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Parameters)和模型计算量也是衡量网络复杂度的重要指标。本文使用乘加累积操作数(Multiplication and Accumulations, MACs)[62]来反映网络实际的计算量。在相同的条件下,对于同一个网络,<em class='similar'>MACs约是另一个反映网络复杂度的指标——浮点运算数</em><em class='similar'>(Floating Point Operations,</em><em class='similar'> FLOPs)</em>的0.5倍。<em class='similar'>⁞对于一层将输入维度映射为输出维度的全连接网络,</em>MACs的计算方式见式(4.7)。⁞(4.7)⁞对于较为复杂的卷积操作,MACs的计算方式如下:⁞(4.8)⁞式4.8中,、——卷积核的高度、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>设模型M的运行时间为 s,模型M′的运行时间为 s′,则模型的加速比δ(M,M∗)为⁞δ(M,M∗)= s⁞s∗(2­33)⁞(2)模型运算数⁞一般情况下,模型所需要的运行时间取决于模型的复杂度,<em class='similar'>评价模型复杂度的常用指标为浮点运算数</em><em class='similar'>(FLoating point OPerations,</em><em class='similar'>FLOPs)</em>与乘积累加运算数(Multiply-accumulate Operations,Macs)。</p>
	                    <div class="textFrom">——电子科技大学硕士论文 纪衡-《基于轻量级网络的信号识别研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>对于较为复杂的卷积操作,</em><em class='similar'>MACs 值的计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Cs约是另一个反映网络复杂度的指标——浮点运算数(Floating Point Operations, FLOPs)的0.5倍。⁞对于一层将输入维度映射为输出维度的全连接网络,MACs的计算方式见式(4.7)。⁞(4.7)<em class='similar'>⁞对于较为复杂的卷积操作,</em><em class='similar'>MACs的计算方式如下:</em>⁞(4.8)⁞式4.8中,、——卷积核的高度、宽度⁞、——输入通道数、输出通道数⁞、——输出图像的高度和宽度⁞4.5实验结果及分析⁞本节首先通过对比实验验证改进模型的相关性能,特别是参数量、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>式中,</em><em class='similar'>分别表示卷积核的高度和宽度;</em><em class='similar'>分别表示输入和输出的通道数;</em><em class='similar'>分别表示输出图像的高度和宽度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>所以标准的卷积层的卷积核的大小为Dw DH m,一共有n个,其中.Dw和DH(一般相等)是卷积核的宽度和高度。因此,标准卷积层⁞的参数量数量为:⁞Dw‘DH m‘凡(1)⁞其中,<em class='similar'>%和Dn分别是卷积核的宽度和高度,</em><em class='similar'>m和n分⁞别是输入和输出特征图的通道数。</em>⁞从上述分析中,标准卷积层参数的大小取决于输入特征通道数m和输出特征通道数厅的乘积m 凡的大小。为了能够减少卷积层的参数,</p>
	                    <div class="textFrom">——电子技术应用 倪伟健；秦会斌-《GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>)的0.5倍。⁞对于一层将输入维度映射为输出维度的全连接网络,MACs的计算方式见式(4.7)。⁞(4.7)⁞对于较为复杂的卷积操作,MACs的计算方式如下:⁞(4.8)<em class='similar'>⁞式4.8中,</em><em class='similar'>、——卷积核的高度、</em><em class='similar'>宽度⁞、</em><em class='similar'>——输入通道数、</em><em class='similar'>输出通道数⁞、</em>——输出图像的高度和宽度⁞4.5实验结果及分析⁞本节首先通过对比实验验证改进模型的相关性能,特别是参数量、计算量等轻量化指标。其次,通过消融实验验证提出的局部注意力和轻量化方法的有效性。⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>然后通过1×1的逐点卷积对得到的特征图进行维度扩张。从表3-1可以看到,使用深度可分离卷积后,卷积操作的参数量和计算量均下降至⁞原来的⁞𝐷KW×𝐷KH左右。其中𝐷KW、<em class='similar'>𝐷KH分别为卷积核的宽高,</em>𝐶in、𝐶out分别表示输入和输出特征图的通道数,<em class='similar'>𝐷W、𝐷H分别表示输出特征图的宽、</em>高。⁞图3-4标准卷积操作⁞图3-5深度可分离卷积操作⁞表3-1使用深度可分离卷积前后卷积操作参数量和计算量比较⁞参数量计算量⁞</p>
	                    <div class="textFrom">——华南理工大学硕士论文 胡昊杰-《基于多任务学习的坐姿检测系统研究与实现》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>首先对分帧、<em class='similar'>加窗后的语音帧做快速傅里叶变换</em><em class='similar'>(Fast Fourier Transform,</em><em class='similar'>FFT)</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对被抑制部分的语音特征加窗,本实验中帧移⁞为80。⁞图3.3语音分帧加窗⁞Figure3.3 framing and windowing for voice signal⁞<em class='similar'>(3)</em><em class='similar'>快速傅里叶变换;</em><em class='similar'>得到加窗的语音帧之后,</em><em class='similar'>对其进行快速傅里叶变换</em><em class='similar'>(Fast Fourier⁞Transform,</em><em class='similar'> FFT)</em>将语音信号从时域变换到频域上。一帧数据经傅里叶变换之后得到160个复⁞数,由傅氏变换的性质可知所得复数是共轭对称的,所以我们取前81个作为有效数据,</p>
	                    <div class="textFrom">——内蒙古大学硕士论文 李光鹏-《基于神经网络的语音分离及其DSP实现》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>可将信号分为短时的语音帧来方便进行后续操作,并且为了减少语音帧的边缘效应使之平滑过渡,需对分帧后的语音帧进行加窗处理。本文选用的窗口为汉明窗,得到加窗后的语音信号 S(n)。⁞(4)短时傅里叶变换。<em class='similar'>对加窗后的时域语音帧片段进行快速傅里叶变换</em><em class='similar'>(fast Fourier transform,</em><em class='similar'>FFT),</em>将其由时域变换到频域,得到每一帧语音信号的快速傅里叶变换后的幅度谱 Y(t, i)。⁞Y(t, i)= fft(S(n), iFFT), iFFT =512(9)⁞(5)</p>
	                    <div class="textFrom">——计算机科学与探索 -《非线性幂变换Gammachirp滤波器的鲁棒语音特征提取*》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>将实际频率转化为梅尔(Mel)<em class='similar'>频域,</em><em class='similar'>以便模拟人耳对声音的感知;</em><em class='similar'>最后使用三角滤波器组进行滤波,</em><em class='similar'>再取对数即可得到 FBank 特征。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>计算过程进行介绍。⁞首先,对分帧、加窗后的语音帧做快速傅里叶变换得到频谱,对频谱取模得到振幅:⁞(2.2)⁞式(2.2)中,——输入的时域语音信号⁞——每个语音帧中的采样点数⁞然后,<em class='similar'>将实际频率转化为Mel频域以便模拟人耳对声音的感知。</em>式(2.3)描述了这一过程。⁞(2.3)<em class='similar'>⁞最后,</em><em class='similar'>使用三角滤波器组进行滤波、</em><em class='similar'>取对数即可得到FBANK特征。</em>FBANK特征具有二维结构,在神经网络方法中通常使用卷积神经网络(Convolutional Neural Network, CNN)[40]来进一步提取其深层次信息。⁞在FBANK的基础上,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>因此在低频区域存在更多的滤波器,分布比较密集;对高频声音不敏感,在高频区域滤波器的数目就变得比较少,分布越来越稀疏。<em class='similar'>通常采用三角滤波器组模拟人耳对声音感知的滤波特性,</em>如图3-4a)图所示,是 Mel 滤波器组滤波特性图,横轴为频率,单位 Hz,纵轴是归一化后的滤波器组幅频特性。</p>
	                    <div class="textFrom">——北京交通大学硕士论文 常璟杰-《小词汇量语音识别在煤炭装船系统中的应用研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong>对于 AISHELL-1,<em class='similar'>论文使用窗口长度为25ms、</em><em class='similar'>帧移为10ms 的80维 FBank特征作为模型输入;</em><em class='similar'>对于 TED-LIUM2,</em><em class='similar'>在80维 FBank 特征的基础上额外增加了</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>区域人数比例(%)⁞北方33383⁞南方3810⁞粤贵闽184⁞其它113⁞合计400100⁞3.4.2语音信号数据处理⁞对于AISHELL-1数据集,<em class='similar'>本文使用窗口25ms、</em><em class='similar'>帧移为10ms的40维FBANK特征作为模型的输入。</em><em class='similar'>对于TED-LIUM2,</em><em class='similar'>在80维FBANK特征的基础上还额外增加了3维的pitch,</em>总共83维FBANK特征。本文还使用了近期提出的SpecAugment[52]语音增强方法对训练集进行增强。在上述原始特征的基础上,本文使用一个含有两层卷积层的卷积模块对原始特征进行进</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>其中,</em><em class='similar'>卷积核为3×3、</em><em class='similar'>步长为2、</em><em class='similar'>输出通道数为256、</em><em class='similar'>激活函数为 ReLU。</em>在卷积模块的作用下,<em class='similar'>原始特征的时间步长度被压缩至。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>gment[52]语音增强方法对训练集进行增强。在上述原始特征的基础上,本文使用一个含有两层卷积层的卷积模块对原始特征进行进一步处理。<em class='similar'>其中,</em>两层卷积层的超参数为:<em class='similar'>卷积核、</em><em class='similar'>步长2、</em><em class='similar'>输出通道256以及ReLU激活函数。</em>通过上述卷积模块,<em class='similar'>原始特征时间步将被压缩为原来的长度。</em>⁞在标签处理方面,对于AISHELL-1数据集,本文共使用不同的4336个字符来构成词汇表(字典)。词汇表中4333个字符统计自于AISHELL-1标注文本。除此之外,还增加了&quot;&lt;EOS/BOS&gt;&quot;、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>r模型;步骤3:使用最终的基于高斯残差自注意力的resgsa-transformer模型对输入语音进行识别,得到输出文本。优选地,所述n=12,m=6。优选地,所述2-d卷积层的卷积核大小为3*3,<em class='similar'>步长为2,</em><em class='similar'>通道数为256,</em><em class='similar'>激活函数为relu。</em>优选地,所述高斯残差自注意力模块和位置前馈模块的输出维度均为256,模块中每个层均使用残差连接以及层归一化,每个注意力层的注意力头个数均为4。本发明的有益效果如下:1.</p>
	                    <div class="textFrom">——网页 -《一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>模型架构如图3.5所示。⁞模型示意图中上半部分为编码收缩路径,首先是两个卷积层对输入图像进行特征的初步提取,<em class='similar'>卷积核的尺寸为3×3,</em><em class='similar'>步长为1,</em><em class='similar'>激活函数采用 ReLU,</em>输出特征图的通道数为64。scSE 模块添加在两次卷积操作后,池化操作前,由并行的通道和空间 SE 模块相加组成,通道 SE 模块先对输入特征图进行空间全局平均池化,得到尺寸为1×1的特征图,再使用两个构成瓶颈的全连接层,</p>
	                    <div class="textFrom">——吉林大学硕士论文 贺梦婷-《基于特征压缩激活网络的肺部CT图像分割算法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>对于 AISHELL-1,</em><em class='similar'>论文使用不同的4336个字符来构成词汇表</em><em class='similar'>(字典)</em><em class='similar'>。其中4333个字符来自于本身的标注文本,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>的卷积模块对原始特征进行进一步处理。其中,两层卷积层的超参数为:卷积核、步长2、输出通道256以及ReLU激活函数。通过上述卷积模块,原始特征时间步将被压缩为原来的长度。⁞在标签处理方面,<em class='similar'>对于AISHELL-1数据集,</em><em class='similar'>本文共使用不同的4336个字符来构成词汇表</em><em class='similar'>(字典)</em><em class='similar'>。词汇表中4333个字符统计自于AISHELL-1标注文本。</em>除此之外,还增加了&quot;&lt;EOS/BOS&gt;&quot;、&quot;&lt;PAD&gt;&quot;以及&quot;&lt;UNK&gt;&quot;这3个额外的特殊字符用于辅助模型进行训练。其中 </p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>模型训练的特殊字符,</em>分别为<EOS/BOS>、<PAD>和<UNK>。<em class='similar'>&lt;EOS/BOS&gt;可指示模型开始或停止输出字符序列;</em><em class='similar'>&lt;PAD&gt;可在训练阶段将一个批处理</em>(Batch)<em class='similar'>大小的数据中不同长度的语音特征序列或字符序列填充到相同的长度;</em><em class='similar'>&lt;UNK&gt;可在输出时代替某些在词汇表中未出现的字符,</em><em class='similar'>避免模型训练时出</em>错;</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>计自于AISHELL-1标注文本。除此之外,还增加了&quot;&lt;EOS/BOS&gt;&quot;、<em class='similar'>&quot;&lt;PAD&gt;&quot;以及&quot;&lt;UNK&gt;&quot;这3个额外的特殊字符用于辅助模型进行训练。</em><em class='similar'>其中 EOS/BOS&gt;&quot;字符用于指示模型开始或停止输出字符序列 PAD&gt;&quot;字符用于在训练阶段将一个批处理数据中不同长度的语音特征序列或字符序列填充到相同的长度 UNK&gt;&quot;字符用于代替那些在词汇表中没有出现的输出字符,</em><em class='similar'>以避免训练出现意</em>料之外的错误。而对于TED-LUM2数据集,本文使用SentencePiece工具生成建模单位为一元模型(Unigram)的词汇表。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_13" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">10.6%(199字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的方面级情感分类研究" target="_blank">基于深度学习的方面级情感分类研究</a></span>
                      <p>王媛媛 -
                        《重庆大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3%(56字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110488262.html" target="_blank">一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=主题可控的多文档摘要生成方法研究" target="_blank">主题可控的多文档摘要生成方法研究</a></span>
                      <p>何思博 -
                        《华中科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=非独立同分布词语相关度计算方法研究" target="_blank">非独立同分布词语相关度计算方法研究</a></span>
                      <p>张玉腾 -
                        《齐鲁工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_13" class="simMore"><a href="javascript:$ShowMore(13);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>改进的 Transformer 模型由12个编码器块和6个解码器块堆叠而成,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>3.5.2模型训练配置⁞1.超参数配置⁞在所有实验中,模型的维度和注意力的头数(表示子空间个数)分别为和。ALDSA的超参数设置为、。对于所有的残差连接,Dropout的概率设置为0.1。<em class='similar'>整个声学模型由12个编码器块和6个解码器块堆叠而成。</em>在模型训练方面,使用参数的Adam优化器(Adam Optimizer, AO)进行模型参数的更新。具体地,对于AISHELL-1,学习率(Learning Rate, LR)为1.0,梯度裁剪(</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>4.11)⁞(,21) cos(/100002)modeli d⁞pos iPE pos(4.12)② Transformer 编码层:Transformer 编码层是在 ELMo 模型的基础上改进的。<em class='similar'>由6个编码器和6个解码器堆叠而成的 Transformer 代替了 ELMo 中的 LSTM。</em>其⁞输入⁞重庆大学硕士学位论文4基于 BERT 词嵌入的 SCBMA-BERT ⁞结构如图4.7所示。</p>
	                    <div class="textFrom">——重庆大学硕士论文 王媛媛-《基于深度学习的方面级情感分类研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>未知符号&quot;&lt;unk 句子起始与结尾符号&quot;&lt;eos 填充符号&quot;&lt;pad&gt;&quot;和空格符号&quot;&lt;space&gt;&quot;)组成的词汇集。2、网络结构:如图1所示,本发明提出的resgsa-transformer是一种改进的speech-transformer,它由卷积前端、<em class='similar'>12个编码器子块、</em><em class='similar'>6个解码器子块和一个嵌入层的堆叠组成。</em>卷积前端采用两个2-d卷积层,卷积核大小为3*3,步长为2,通道数为256,激活函数为relu;编码器子块包含一个resgsa层和一个位置前馈模块;</p>
	                    <div class="textFrom">——网页 -《一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>论文使用Kullback-Leibler散度作为模型训练的损失函数,</em>标签平滑度(Label</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>𝛽1值为0.9,𝛽2值为⁞华中科技大学硕士学位论文⁞0.998,学习率的权重衰减因子为0.01,学习率的变化方式为线性增长和下降,其中线性增长的步数占训练总步数的10%。<em class='similar'>⁞模型训练时使用的损失函数为 Kullback-Leibler 散度</em>(KL divergence),衡量了模型分布𝑄近似真实分布𝑃时的信息损失,KL 散度越大,模型分布的表达越差,计算公式如(4.1)所示。⁞𝐷𝐾𝐿(𝑃||𝑄)=∑𝑃(𝑥) log (𝑃(</p>
	                    <div class="textFrom">——华中科技大学硕士论文 何思博-《主题可控的多文档摘要生成方法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>论文使用了近期提出的 SpecAugment</em>[76]<em class='similar'>对训练集数据进行必要的增强。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>本文使用窗口25ms、帧移为10ms的40维FBANK特征作为模型的输入。对于TED-LIUM2,在80维FBANK特征的基础上还额外增加了3维的pitch,总共83维FBANK特征。<em class='similar'>本文还使用了近期提出的SpecAugment</em>[52]<em class='similar'>语音增强方法对训练集进行增强。</em>在上述原始特征的基础上,本文使用一个含有两层卷积层的卷积模块对原始特征进行进一步处理。其中,两层卷积层的超参数为:卷积核、步长2、输出通道256以及ReLU激活函数。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>LM)。<em class='similar'>在推理阶段,</em><em class='similar'>将原始模型和语言模型的预测结果以浅融合</em>[77]<em class='similar'>的方式综合,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>05.0⁞表示子空间个数44⁞FFN维度10241024⁞⁞2535⁞⁞22⁞遵从大多数语音识别系统的配置,本文除了声学模型外,还构建了与之配套的外部语言模型。<em class='similar'>在推理解码阶段,</em><em class='similar'>将声学模型的预测结果和语言模型的预测结果以浅融合</em>(Shallow Fusion, SF)<em class='similar'>的方式进行综合,</em>能进一步提升识别准确率。对于AISHELL-1数据集,本文利用标注文本训练了一个2层LSTM网络,其模型维度为1024。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>"↓"表示该项指标越低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>即低层次的显式共现⁞耦合,低层次的显式超链接耦合和高层次的隐式概念耦合。由于 CCE 具有全面捕⁞捉概念耦合的强大功能,因此在所有对比方法中获得了最佳结果。⁞(1)<em class='similar'>加粗表示最优结果,</em><em class='similar'>下划线表示次优结果,</em>*表示 CCE 比次优结果提升的百分比。齐鲁工业大学硕士学位论文⁞21⁞表3.2所有数据集上的平均斯皮尔曼秩相关性系数。。⁞Families  Methods </p>
	                    <div class="textFrom">——齐鲁工业大学硕士论文 张玉腾-《非独立同分布词语相关度计算方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_14" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(61字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>在本章提出的改进模型的基础上,</em><em class='similar'>将轻量级解码器替换为普通解码器、</em><em class='similar'>将轻量级解码器的注意力表示子空间个数从</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong><em class='similar'>、轻量级解码器以及注意力表示子空间个数这三个方面来进行。</em><em class='similar'>本文在本章所提出的改进Transformer模型的基础上,</em><em class='similar'>分别将ALDSA编码器替换为普通Transformer编码器、</em>轻量级解码器网络替换为普通Transformer解码器网络以及将解码器的注意力表示子空间个数从4降低为1,观察这些改动得到的变种模型在AISHELL-1和TED-LIUM2数据集上的相关指标,并将相关结果记录到了表4.4。表4.4中,BASE表示本章提出的改进模型,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_15" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(72字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=叶尖定时测量误差的高精度实验分析与修正" target="_blank">叶尖定时测量误差的高精度实验分析与修正</a></span>
                      <p>蒙一鸣;肖志成;欧阳华 -
                        《航空动力学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>其他三项分别作为横轴绘制散点图,</em><em class='similar'>如图3-9所示。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>t 时刻增量式编码器的输出线⁞数, sumn 为编码器旋转一圈的总输出线数。式(20)⁞所定义的轴位置误差本质上即为 t 时刻转速波动引起的误差。接下来分析轴位置误差与测量总误差之间的关系,<em class='similar'>以两者分别为横轴和纵轴绘制散点图,</em><em class='similar'>如图9所示。</em>对比数据点与 sp totale e的虚线参考线,可看出两者明显呈正比关系。其具体相关系数值见表2,不同传感器的相关系数值均处于0.98与0.995之间,可以确定该实验中转速波动是 </p>
	                    <div class="textFrom">——航空动力学报 蒙一鸣；肖志成；欧阳华-《叶尖定时测量误差的高精度实验分析与修正》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>进一步论证了所提方法的有效性。</em><em class='similar'>此外,</em><em class='similar'>轻量级解码器中注意力表示子空间的个数在很大程度上会影响到模型的识别准确率,</em><em class='similar'>采用单一表示子空间时模型的识别性能较差。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>器能大幅降低模型的参数量和计算量,但是会一定程度降低识别的准确率。综合两种特点的BASE模型在识别准确率、参数量以及计算量上都达到了一个较好的折中。<em class='similar'>此外,</em>从消融实验可知,<em class='similar'>注意力机制中表示子空间的个数很大程度上影响到模型的识别准确率,</em><em class='similar'>采用单一的表示子空间表现较差。</em><em class='similar'>⁞为了更加直观地说明提出方法的有效性,</em>本文根据各变种模型在两个数据集上的CER/WER以及参数量绘制了图4.9。从图4.9可知,BASE模型趋近于靠近图像的右下角,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第4章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_16" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用泛函分析" target="_blank">应用泛函分析</a></span>
                      <p>腾岩梅，贾超华，冯伟杰等编著 -
                        《北京：北京航空航天大学出版社,2012.09
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=量子隐形传态线路的设计与分析" target="_blank">量子隐形传态线路的设计与分析</a></span>
                      <p>张国帅 -
                        《贵州大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=泛函分析与最优化理论" target="_blank">泛函分析与最优化理论</a></span>
                      <p>王日爽编著 -
                        《北京：北京航空航天大学出版社
                        》- 2003 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>述为:假设表示 Hilbert 空间、<em class='similar'>表示的一个子空间,</em><em class='similar'>对于一个给定向量,</em><em class='similar'>需要找到一个离最近的向量,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>首先有SUS」,,应用命题4,即有S」」,US\其次,仍⁞由命题3,又有&quot;U (1最后,结合起来,即有⁞SL±±=Slo投影定理⁞我们现在要讨论的最优化问题是,在内积空间或Hilbert空间中,<em class='similar'>给定一个向量x与一个子空间要求找出一个向量⁞它是M中距离x最近的向量。</em>这也就是说,要找出一个向量使得min || x — m ||=|| x —m0||。当然,当xGM时,答案是明显的,只需取%=x。然而,在一般情形下,要解决这个问题,</p>
	                    <div class="textFrom">——北京：北京航空航天大学出版社 王日爽编著-《泛函分析与最优化理论》-2003 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>9z=zi o⁞2.射影定理的应用⁞(1)最佳逼近问题⁞利用射影定理,可以解决在随机过程理论、逼近论、最优化理论以及其他学科中经常要碰到的最佳逼近问题。⁞设X是Hilbert空间,<em class='similar'>给定一个向量①C X和一个子空间M,</em>经常需要讨论是否唯一存在 yCM,使得||z—y∣∣=d(z,M)= inf ||n—z∣∣。这就是Hilbert空间中的最佳逼近问题。⁞z∈M⁞由射影定理及其证明过程可以看出,</p>
	                    <div class="textFrom">——北京：北京航空航天大学出版社,2012.09 腾岩梅，贾超华，冯伟杰等编著-《应用泛函分析》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>{,.,})m mspan ??(28)span ??。将1,.,m??生成一个H 的子空间⁞W ,其维数为 m ,通过对1,.,m??正交化和范化后可以得到W 的一组规范⁞正交基。设 H 为一个 Hilbert 空间,<em class='similar'>X 为 H 的一个子空间,</em><em class='similar'>一个向量?</em>与 X 正⁞交(记为??X )是指:?与X 中任意向量正交。由与 X 正交的所有向量张⁞成的子空间称为 X 的正交补空间。记为 X ?。X 与 X ?公共元只有零向量0。H⁞可以分解为直和: </p>
	                    <div class="textFrom">——贵州大学硕士论文 张国帅-《量子隐形传态线路的设计与分析》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_17" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图神经网络的半监督文本分类算法研究" target="_blank">基于图神经网络的半监督文本分类算法研究</a></span>
                      <p>王钢坤 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">10.8%(97字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=时变转速下基于改进图注意力网络的轴承半监督故障诊断" target="_blank">时变转速下基于改进图注意力网络的轴承半监督故障诊断</a></span>
                      <p>邵海东;颜深;肖一鸣;刘翊 -
                        《电子与信息学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">8.6%(77字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/05/202110219069.html" target="_blank">一种基于语义图网络的医疗预测方法及系统与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.3%(56字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="https://wenku.baidu.com/view/761d09c69cc3d5bbfd0a79563c1ec5da50e2d648" target="_blank">GAT模型的实际应用案例分析</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.1%(55字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能电网中虚假数据注入攻击的检测与防御研究" target="_blank">智能电网中虚假数据注入攻击的检测与防御研究</a></span>
                      <p>王媛媛 -
                        《华北电力大学(北京)博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">5.6%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图卷积与神经协同过滤的融合信息推荐模型" target="_blank">基于图卷积与神经协同过滤的融合信息推荐模型</a></span>
                      <p>江原 -
                        《吉林大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">5.6%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://m.toutiao.com/i6888696049314038276/" target="_blank">Day221:GCN,GNN,GAT</a></span>
                      <p>做个自律的禾苗 -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.5%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="https://blog.csdn.net/jing_jing95/article/details/88836707" target="_blank">神经网络</a></span>
                      <p>csdn -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.4%(48字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=依存约束的图网络实体关系联合抽取" target="_blank">依存约束的图网络实体关系联合抽取</a></span>
                      <p>任鹏程;于强;侯召祥 -
                        《计算机系统应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">5.2%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多注意力机制的用户在线评论情感分析研究" target="_blank">基于多注意力机制的用户在线评论情感分析研究</a></span>
                      <p>周婷 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="https://www.doc88.com/p-58339018467068.html" target="_blank">基于图卷积和语义关系的人</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识图谱和图注意力的众包任务推荐算法" target="_blank">基于知识图谱和图注意力的众包任务推荐算法</a></span>
                      <p>沈旭;王淑营;田媛梦;郑庆 -
                        《计算机应用研究
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络的机器阅读理解综述" target="_blank">基于神经网络的机器阅读理解综述</a></span>
                      <p>顾迎捷;桂小林;李德福;沈毅;廖东 -
                        《软件学报
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=视频群体行为分析与识别关键技术研究" target="_blank">视频群体行为分析与识别关键技术研究</a></span>
                      <p>徐得中 -
                        《北京工业大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=多模态数据的图表示学习" target="_blank">多模态数据的图表示学习</a></span>
                      <p>杨旭 -
                        《西安电子科技大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_17" class="simMore"><a href="javascript:$ShowMore(17);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'>GAT)[80]</em><em class='similar'>是一种图神经网络的变体,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>既实现了连接关系的利用,又通过嵌入的思想实现了实体和关系的低维空间向量表示。现有基于传播的方法主要通过将图神经网络融入知识图谱中,挖掘节点间的高阶连通关系。<em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'> GAT)</em><em class='similar'>是图神经网络的一种,</em>在 KGAT 中主要用于学习邻居权重并在传播时控制信息聚合的多少。KGAT 可选的聚合器有 GCN、GraphSage 和 Bi-Interaction,其中 Bi-Interaction 性能最好,</p>
	                    <div class="textFrom">——计算机应用研究 沈旭；王淑营；田媛梦；郑庆-《基于知识图谱和图注意力的众包任务推荐算法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>但是通过模型进行联合抽取依旧面临挑战.⁞语句的依存分析是 NLP中处理文本的关键技术之一,其目标是确定句子的句法结构和各单词间的依存关系.图神经网络是图结构数据建模的有效模型,<em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em> GAT)[1]<em class='similar'>是一种空域图神经网络,</em>适用于动态图的处理,有利于将顶点特征之间的关联性更好得融合进模型.⁞为优化传统 Pipline方式并实现高效的实体关系联合抽取模型,本文综合依存分析和图注意力网络特性</p>
	                    <div class="textFrom">——计算机系统应用 任鹏程；于强；侯召祥-《依存约束的图网络实体关系联合抽取》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>大训练数据需求由于小归纳偏差;四、难以解释自我注意机制学习和输入的贡献令牌对预测。因此,已经有许多研究者提出了基于 Transformer 的改进方法[68][69]。⁞2.3.3<em class='similar'>图注意力网络⁞图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'>GAT)</em><em class='similar'>是对图神经网络</em>(Graph Neural ⁞Network)的一种改进,由 Velickovic 等人于2017年提出。该模型将注意力机制引入图神经网络中,与同样以 GNN 为基础的图卷积神经网络(</p>
	                    <div class="textFrom">——常州大学硕士论文 周婷-《基于多注意力机制的用户在线评论情感分析研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>与传统的图卷积神经网络</em><em class='similar'>(Graph Convolutional Network,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>第2章相关知识背景⁞5⁞第2章相关知识背景⁞本章的结构组织顺序为先介绍本文中所研究的推荐系统问题,接着给出关于本⁞文用到的模型与相关算法知识背景的描述:<em class='similar'>图卷积神经网络 Graph  Convolutional⁞Network</em>(GCN)与神经协同过滤 Neural Collaborative Filtering(NCF)。这两种讨论⁞到的推荐方法各有其优越性及不足,本文结合两者的优点以改进提出的推荐模型的⁞效率与灵活性。</p>
	                    <div class="textFrom">——吉林大学硕士论文 江原-《基于图卷积与神经协同过滤的融合信息推荐模型》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>网络无法表示顶点和边这种关系型数据,便出现了图神经网络解决这种图数据的表示问题,这属于DNN往图方向的应用扩展。(GAT, GCN都属于GNN的一种,只是 integrate节点附近的message的方式不同)GCNGCN <em class='similar'>(Graph Convolutional Network)</em><em class='similar'>:图卷积神经网络,</em>GNN是频域GNN的代表模型。GNN在训练过程中,有将attention引入图结构的,有将门控机制引入图结构的,还有将卷积引入图结构的,引入卷积的GNN就是GCN,</p>
	                    <div class="textFrom">——网页 做个自律的禾苗-《Day221:GCN,GNN,GAT》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>作为输入,</em><em class='similar'>其中,</em>表示<em class='similar'>节点个数</em>,<em class='similar'>表示每个节点的特征个数;</em><em class='similar'>输出一组新的节点特征,</em>其中<em class='similar'>(可能具有不同的基数)</em>。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>能对新的节点实现实时学习与分类。⁞模型的输入层是一组节点特征表示,h =危工2,,E 6 rf,其中n是节点数,<em class='similar'>F是每个节点的特征数。</em><em class='similar'>该层生成一组新的节点特征,</em><em class='similar'>这些节点特征可能具有不同的基数尸,</em>九,={丸&amp;,,牖}(言6产,<em class='similar'>)作为其输出。</em>为了获得足够的表达能力将输入特征转换为更高层次的特征,至少需要一个可学习的线性变换。为此,作为初始步骤,</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 王钢坤-《基于图神经网络的半监督文本分类算法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(3-47)⁞Hkejfi exp(LeakyReLU(ar[Whi\\Whk])&#39;)⁞其中%是节点j到节点i的注意系数,队代表图中节点i的邻域。该层的节⁞点特征的输入集是其中N<em class='similar'>是节点数</em>,<em class='similar'>F是每个节点的特⁞征数,</em><em class='similar'>该层产生一组新的节点特征</em><em class='similar'>(可能具有不同的基数F’)</em>,/i&#39;=⁞K,hr2eir&#39;作为其输出。we 是应用于每个节点的共享线性变换⁞的权重矩阵(the weight matrix)。aeK2F&#39;是单层前馈神经网络的权重向量。</p>
	                    <div class="textFrom">——华北电力大学(北京)博士论文 王媛媛-《智能电网中虚假数据注入攻击的检测与防御研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过叠加该层构造任意图注意网络。层通过计算节点对(i,j)注意机制中的系数:aij是节点j对i的注意系数,Ni表示图中节点i的邻域,该层的节点特征的输入集为,hi∈,N是节点数量,<em class='similar'>F是每个节点的特征数,</em><em class='similar'>该层生成一组新的节点特性</em><em class='similar'>(可能具有不同的基数F&#39;)</em>,,<em class='similar'>作为输出。</em>是应用于每个节点的共享线性变换的权矩阵,是单层前馈神经网络的权向量。它由一个SoftMax函数进行归一化,并应用了非线性LeakyReLU(负输入斜率=0:2)。</p>
	                    <div class="textFrom">——网页 csdn-《神经网络》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>为了将输入特征转化为更高层次的特征,</em><em class='similar'>首先将由权重矩阵参数化的共享线性变换应用于每个节点;</em><em class='similar'>然后在节点上使用自注意力机制计算系数</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>帧的数量为 n)。产生新的一组节点特征输出&#39;h ,&#39;&#39;&#39;&#39;⁞12{,}nh h h h=。<em class='similar'>为了获得足够的表达能力将输入特征转换为高级特征,</em>需要一种可学习的线性转换。<em class='similar'>首先将由权重矩阵 W 参数化的共享线性变换应用于每个节点,</em><em class='similar'>然后,</em><em class='similar'>在节⁞点上执行一种共享的注意力机制 a ,</em><em class='similar'>计算注意力系数 ije ⁞</em>(,)ij⁞i je a Wh Wh=(5-14)⁞之后,我们通过掩模(masked)注意力将结构信息注入模型。</p>
	                    <div class="textFrom">——北京工业大学博士论文 徐得中-《视频群体行为分析与识别关键技术研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>障诊断。⁞H ′⁞W ∈⁞Rd′×d⁞F⃗⁞以下描述节点级图注意力层的具体构造,输入为一组节点特征H,图注意力层能输出一组新的节点特征。为了获得足够的表达能力,<em class='similar'>需要进行线性变换将输入特征转化为更高层次的特征。</em><em class='similar'>为⁞此,</em>作为初始步骤,<em class='similar'>对每个节点应用权值矩阵参数化的共享线性变换,</em><em class='similar'>然后在节点上执行⁞一种共享的注意机制计算注意力系数。</em></p>
	                    <div class="textFrom">——电子与信息学报 邵海东；颜深；肖一鸣；刘翊-《时变转速下基于改进图注意力网络的轴承半监督故障诊断》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>n|},通过图注意力层将产生一个新的节点表示集合作为输出h={h′1,h′2 h′|n|},f′表示输出特征的维度。<em class='similar'>为了将输入转化为更高层次的输出特征,</em><em class='similar'>图注意力层将在每一个节点采用权重矩阵参数化共享的线性转换,</em><em class='similar'>并采用共享的注意力机制计算注意力系数,</em>如公式(7)所示:[0065][0066]其中,表示句子中由实体对vi和vj构成的图φ在领域本体中有关系r,er表示r的关系向量,</p>
	                    <div class="textFrom">——网页 -《一种基于语义图网络的医疗预测方法及系统与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>认为输入的多域样本之间的关系矩阵中可能存在错误,从而导致结果偏离最优解。因此图注意力网络采用了注意力机制,该机制优化了多个域样本的相似关系。图注意力网络由两个图注意力层构成。第一步,<em class='similar'>利用权重矩阵Θ参数化的共享线性变换来变换每个节点。</em><em class='similar'>然后,</em><em class='similar'>我们在节点上执行自我注意力权重计算,</em><em class='similar'>并采用共享注意力机制 a来计算注意力系数。</em>⁞eij = a(Θhi,Θhj),(6­8)⁞其中 eii =1表示自相关权重,主要用于自我注意力机制的训练。</p>
	                    <div class="textFrom">——西安电子科技大学博士论文 杨旭-《多模态数据的图表示学习》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>一个图神经层的结构如图所示我们至少要有一个可学习的线性变换来实现拥有充足的表达能力来将输入特征转换为我们需要的更高层的特征。因此,<em class='similar'>我们首先对每个节点应用由权重矩阵WRF&#39;F参数化的共享线性变换。</em><em class='similar'>然后</em>,图注意层首先根据输入的节点特征向量集,进行self-attention处理:eijaWhi,WhjF&#39;F&#39;F&#39;F其中,a是一个RRR的映射,WR是一个权值矩阵(被所有hi所共享)。</p>
	                    <div class="textFrom">——网页 -《GAT模型的实际应用案例分析》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>接着使用 Softmax 函数对进行归一化处理得到,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>{fsem))(4-5)其中勾e?n表示语义分支预测的动作得分,/sem表示初始语义特征向量。模型将视觉分支、空间分支和语义分支分别预测的动作得分进行融合,得到该人-物对总体的动作得分,<em class='similar'>最后使用Softmax函数对结果进行归一化处理。</em><em class='similar'>其计算过程如式</em>(4-6)所示Sa=Sv;?S:?Ss;m(4-6其中Sa表示人-物对总体的动作得分。完成人-物对的人体动作预测之后,模型对人-物对的交互得分进行预测,该得分是综合视觉、空间语义三个方面的特征得到的,</p>
	                    <div class="textFrom">——网页 -《基于图卷积和语义关系的人》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(,)(,)(,)tanh()Tdot j ij iTjibilinear j ij iTCQMLP j i jif C Q C QSfC Q C WQf C Q VW C W Q (19)(2)<em class='similar'>使用Softmax函数对权重进行归一化处理,</em><em class='similar'>得到?</em>j1,,?ji,,?jn:1exp()softmax()exp()jijijinjiiSSS (20)(3)将归一化后的权重和相应的问题Q中的单词Qi进行加权求和,得到序列C?</p>
	                    <div class="textFrom">——软件学报 顾迎捷；桂小林；李德福；沈毅；廖东-《基于神经网络的机器阅读理解综述》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_18" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向对话文本的关系抽取研究" target="_blank">面向对话文本的关系抽取研究</a></span>
                      <p>周孟佳 -
                        《武汉大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>式中,<em class='similar'>和分别表示槽位节点和意图节点的集合;</em><em class='similar'>表示可训练的权重矩阵。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>푒퐿푈￿￿￿⁞1⁞|푁￿⁞￿|푊￿⁞(￿)ℎ￿⁞(￿)+⁞￿∈￿￿⁞￿￿∈￿⁞푊￿⁞(￿)ℎ￿⁞(￿)￿(5.3)⁞其中,푅表示异构图中边的关系集合,即5.2.2小节提到的八种边的类型。<em class='similar'>푁￿⁞￿表示⁞与节点 hv 相邻的节点集合,</em><em class='similar'>푊￿⁞(￿)⁞表示可训练的权重矩阵,</em>l 为关系图卷积网络的层数,⁞其取值见5.3小节实验设置。푅푒퐿푈表示激活函数。⁞5.3实验设置⁞本章模型采用的数据集、预处理方式及评价指标同3.4小节,</p>
	                    <div class="textFrom">——武汉大学硕士论文 周孟佳-《面向对话文本的关系抽取研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_19" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=旋转机械早期故障诊断关键技术研究" target="_blank">旋转机械早期故障诊断关键技术研究</a></span>
                      <p>杨静 -
                        《西安理工大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202011413754.html" target="_blank">信息服务提供方法、装置、电子设备和存储介质与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于扩张卷积的注意力机制视频描述模型" target="_blank">基于扩张卷积的注意力机制视频描述模型</a></span>
                      <p>王金金;曾上游;李文惠;张介滨 -
                        《电子测量技术
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>式中,</em><em class='similar'>表示 Sigmoid 函数;</em><em class='similar'>和表示可训练的权重矩阵和偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>[0057]其中it,ft,ot,ct分别代表t时刻输入门,遗忘门,输出门和细胞状态的输出,xt表示t时刻输入模型的向量,ht表示t时刻区块中隐藏层中的向量,<em class='similar'>σ表示sigmoid激活函数,</em><em class='similar'>w和b分别表示不同门内待训练的权重矩阵和偏置向量。</em>三个具有筛选功能的门结构,其主要功能如下:1)输入门:用当前的信息以及上一个隐藏层传过来的信息作为输入,用来决定流向当前区块的信息,</p>
	                    <div class="textFrom">——网页 -《信息服务提供方法、装置、电子设备和存储介质与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>Wxgxt+Wagat-1+bg)(6)⁞ct =ft☉ct-1+it☉gt (7)⁞at =ot☉Ø(ct)(8)⁞其中,it、ft、ot 分别表示输入门、遗忘门和输出门,⁞Wxj、<em class='similar'>bj 均是可训练的权重矩阵和偏置向量,</em><em class='similar'>σ表示sigmoid函数,</em>Ø表示tanh函数,☉是哈达玛积运算,即向量的点乘。⁞2.5 AMSGrad优化器⁞ Adam⁞是在深度学习中用来替代随机梯度下降的优化⁞算法,结合了⁞AdaGrad⁞和⁞RMSProp⁞</p>
	                    <div class="textFrom">——电子测量技术 王金金；曾上游；李文惠；张介滨-《基于扩张卷积的注意力机制视频描述模型》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>其中1⁞i⁞x 表示第 i 个样本,n样本尺寸,是样本容⁞量。定义编码映射函数为 ef ,则隐层特征 id 可由下式(4.3)计算出:⁞i e i e i ef Sd x W x b (4.3)<em class='similar'>⁞其中S 代表 sigmoid 函数,</em><em class='similar'> eW 和 eb 分别表示编码层的权重矩阵和偏置向量。</em>⁞⁞⁞⁞⁞⁞⁞⁞⁞解码⁞⁞编码⁞ix⁞⁞⁞2⁞ix⁞⁞𝑥2⁞3⁞ix ⁞⁞⁞⁞11⁞ix ⁞⁞输入 ix ⁞特征 id 重构ˆ⁞ix ˆ⁞ix⁞⁞⁞2ˆ⁞ix⁞⁞⁞3ˆ⁞ix ⁞⁞1ˆ⁞ix ⁞⁞⁞M⁞id⁞⁞⁞2⁞id⁞⁞⁞1⁞id ⁞⁞⁞1⁞⁞⁞西安理工大学博士学位论文⁞</p>
	                    <div class="textFrom">——西安理工大学博士论文 杨静-《旋转机械早期故障诊断关键技术研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_20" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图像处理的桥梁裂缝识别与测量方法研究" target="_blank">基于图像处理的桥梁裂缝识别与测量方法研究</a></span>
                      <p>马嘉斌 -
                        《北京交通大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">7.9%(124字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=融合多模态特征的乳腺癌分类系统的分析与设计" target="_blank">融合多模态特征的乳腺癌分类系统的分析与设计</a></span>
                      <p>郭星晨 -
                        《阜阳师范大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">7.7%(121字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于通用目标检测器的大坝裂缝检测方法" target="_blank">基于通用目标检测器的大坝裂缝检测方法</a></span>
                      <p>赵凡;李琳芸;魏仁杰;张志伟 -
                        《数据采集与处理
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">6.2%(97字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向文本的方面级情感分类研究及系统实现" target="_blank">面向文本的方面级情感分类研究及系统实现</a></span>
                      <p>李佳洲 -
                        《电子科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.9%(77字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=改进YOLOX-S的偏光片表面缺陷检测算法" target="_blank">改进YOLOX-S的偏光片表面缺陷检测算法</a></span>
                      <p>陈乐;周永霞;祖佳贞 -
                        《计算机工程与应用
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.7%(74字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>式中,</em><em class='similar'>TP(</em><em class='similar'>True Positive)</em><em class='similar'>表示预测正样本正确的个数;</em><em class='similar'>TN(</em><em class='similar'>True Negative)</em><em class='similar'>表示预测负样本正确的个数;</em><em class='similar'>FP(</em><em class='similar'>False Positive)</em><em class='similar'>表示预测正样本错误的个数;</em><em class='similar'>FN(</em><em class='similar'>False Negative)</em><em class='similar'>表示预测负样本错误的个数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>以便后续对不同模型进行性能的比较和评价。多种评价指标都基于混淆矩阵给出,其中混淆矩阵是常用的精度评价标准依据,表2.3给出了混淆矩阵的具体内容。⁞第2章相关技术与理论基础⁞阴性 FN TN⁞在分类任务中,<em class='similar'>TP(</em><em class='similar'>True Positive)</em><em class='similar'>表示正例样本中所预测正确的个数,</em><em class='similar'>TN(</em><em class='similar'>True Negative)</em><em class='similar'>表示负例样本中预测正确的个数,</em><em class='similar'>FN(</em><em class='similar'>False Negative)</em><em class='similar'>表示正例样本中所预测错误的个数,</em><em class='similar'>FP(</em>Fake Positive)<em class='similar'>表示负例样本中预测错误的结果个数。</em></p>
	                    <div class="textFrom">——阜阳师范大学硕士论文 郭星晨-《融合多模态特征的乳腺癌分类系统的分析与设计》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong><em class='similar'>True Positive)</em><em class='similar'>表示预测正确的正样本;</em><em class='similar'>TN(</em><em class='similar'>True Negative)</em><em class='similar'>表示预测正确的负样本;</em><em class='similar'>FP(</em><em class='similar'>False Positive)</em><em class='similar'>表示预测错误的正样本;</em><em class='similar'>FN(</em><em class='similar'>False Negative)</em><em class='similar'>表示预测错误的负样本。</em>AP(i)表示第 i类缺陷平均精度。⁞除检测性能外,本文还关注模型的部署性和检测效率,通过参数量(Parameters)、</p>
	                    <div class="textFrom">——计算机工程与应用 陈乐；周永霞；祖佳贞-《改进YOLOX-S的偏光片表面缺陷检测算法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>则说明目标检测算法的性能越好。⁞F1=2⁞PR⁞P+R⁞(10)⁞(4)AP为不同召回率上准确率的平均值,mAP为各个类别的AP平均值。<em class='similar'>式中:</em><em class='similar'>TP(</em>True position)<em class='similar'>表示把正样本正确识别为正样本的个数,</em><em class='similar'>TN(</em><em class='similar'>True negative)</em><em class='similar'>表示把负样本正确识别为负样本的个数,</em><em class='similar'>FP(</em>False position)<em class='similar'>表示把负样本错误识别为正样本的个数,</em><em class='similar'>FN(</em>False nega⁃tive)<em class='similar'>表示把正样本错误识别为负样本的个数。</em>⁞3.2结果与分析⁞</p>
	                    <div class="textFrom">——数据采集与处理 赵凡；李琳芸；魏仁杰；张志伟-《基于通用目标检测器的大坝裂缝检测方法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>2实验验证指标⁞方面级情感分类主要关注正确率指标,为了考虑到正负类别不平衡的现象,本文也采用查准率、查全率和 F1值。<em class='similar'>⁞TP(</em><em class='similar'>True Positive)</em><em class='similar'>代表了被正确预测的正样本,</em><em class='similar'>FP(</em><em class='similar'>False Positive)</em><em class='similar'>代表了被错误预测的正样本,</em><em class='similar'>TN(</em><em class='similar'>True Negative)</em><em class='similar'>代表了正确预测的负样本,</em><em class='similar'>FN(</em><em class='similar'>False Negative)</em><em class='similar'>代表了被错误预测的负样本。</em>如式(4-1)所示,正确率(accuracy)为被预测正确的样本除以样本总数。二分类的实践中经常出现负样本个数远大于正样本个数的情况,当 </p>
	                    <div class="textFrom">——电子科技大学硕士论文 李佳洲-《面向文本的方面级情感分类研究及系统实现》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong><em class='similar'>True Positive)</em><em class='similar'>表示正确预测到的正样本的个数,</em><em class='similar'>TN(</em><em class='similar'>True Negative)</em><em class='similar'>表示正确预测到的负样本的个数,</em><em class='similar'>FP(</em><em class='similar'>False Positive)</em>表示把负样本预测为正样本的个数,<em class='similar'>FN(</em><em class='similar'>False Negative)</em>表示把正样本预测为负样本的个数。⁞本文采用常用的准确率和召回率作为评价指标</p>
	                    <div class="textFrom">——北京交通大学硕士论文 马嘉斌-《基于图像处理的桥梁裂缝识别与测量方法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_21" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=数据科学入门" target="_blank">数据科学入门</a></span>
                      <p>（美）JOELGRUS著;高蓉，韩波译 -
                        《
                        》- 2016 
                      </p>
                    </div></td>
                  <td><span class="green">2%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=知识图谱分布式表示学习方法及应用研究" target="_blank">知识图谱分布式表示学习方法及应用研究</a></span>
                      <p>张金斗 -
                        《中国科学技术大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>论文选择在验证集上表现最佳的模型作为训练好的模型,</em>然后在测试集上对其进行测试以进行公平比较。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>有持续的好表现。)⁞在这种情况下,你应该把数据划分为三部分:一个用来建立模型的训练集,<em class='similar'>一个为在训练好的模型上进行选择的验证集,</em>一个用来判断最终的模型的测试集。正确性⁞当我不做数据科学的时候,我会涉猎医疗研究。在业余时间,我做了一个低成本、无害的新生儿测试——准确性高达98%——测试新生儿是否会得白血病。我的律师确信我是有专利权的。</p>
	                    <div class="textFrom">—— （美）JOELGRUS著；高蓉，韩波译-《数据科学入门》-2016 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>"↑"/"↓"分别表示该项指标越高/低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14], DSST[16], SAMF_CA[17], MOSSE_CA[17]和 CT[23]⁞等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>⁞表1部分跟踪算法的速度对比结果帧/s ⁞视频 LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA 本文整体20.2017.5027.80210.105.1264.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>8710.7910.7970.7250.9810.9380.9370.861⁞(+3.4%)(+2.9%)(+5.8%)(+7.7%)(+0.4%)(+0.9%)(+6.7%)(+7.4%)⁞注:黑体数字表示最优结果,<em class='similar'>下划线数字表示次优结果,</em>括分里面的数值表示⁞FKAPR与次优的结果相比提升的百分比⁞表5.3和图5.3分别给出了所有方法在四个数据集上CTR预测的AUC、F1值⁞和Top-K推荐的Recall@K指标值。</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 张金斗-《知识图谱分布式表示学习方法及应用研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
            	<h3 style="line-height:40px;">全文对照</h3>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_23" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://mp.weixin.qq.com/s?src=11&timestamp=1621424192&ver=3078&signature=jcHyNOoq23FSbGF5zLFBCq6YbjMzq8hRMLq7wQ7dipYyzxuLNNBT0ZJ4PC3V9GR7v6vwXjg2Rq4Vh0JdhmlZA7-KMinGIXXpVkwefQS2j56eRoBROAihxqWFaCSSlDRt&new=1" target="_blank">喜讯 | 香港中文大学（深圳）数据科学学院宋彦教授团队十二篇论文分别被各大学术会议及期刊收录</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>从而提升模型性能。</em><em class='similar'>在MixATIS和MixSnips数据集上的实验结果论证了本章所提方法的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并把其引入模型。相比于普通的GCN模型(即不区分词与上下文信息的相对位置关系,并用对所有上下文信息同等对待的模型),D-GCN可以有效地区分不同上下文信息的贡献,并据此更好地利用这些信息,<em class='similar'>进而提升模型性能。</em><em class='similar'>本研究在三个标准数据集上的实验结果表明了该方法的有效性;</em>该方法超越了其它图结构模型达到了目前最好的成绩。图10:基于方向建模的图神经网络模型架构图Paper10MeetChangeswithConstancy:</p>
	                    <div class="textFrom">——网页 -《喜讯 | 香港中文大学（深圳）数据科学学院宋彦教授团队十二篇论文分别被各大学术会议及期刊收录》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第5章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_24" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="https://blog.csdn.net/bluewhalerobot/article/details/81587039" target="_blank">TX2刷机和使用常见问题 - bluewhalerobot的博客 - CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于端到端学习的自动驾驶决策算法研究" target="_blank">基于端到端学习的自动驾驶决策算法研究</a></span>
                      <p>王奎霖 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.6%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向危险化学品的知识图谱构建研究" target="_blank">面向危险化学品的知识图谱构建研究</a></span>
                      <p>程钊 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用残差稠密网络的无监督单幅图像深度估计" target="_blank">应用残差稠密网络的无监督单幅图像深度估计</a></span>
                      <p> -
                        《小型微型计算机系统
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>接着将论文第3章、<em class='similar'>第4章提出的模型分别在驾驶数据集上进行训练,</em>最后集成、移植网络模型至 TX2并围绕搭建全套硬件平台,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>与对应化学品有&quot;避免接触条件&quot;关系⁞图5-4甲醛溶液的相关特性⁞5.1.2应用模型进行风险信息补全⁞为构建更加全面的含有风险信息的危险化学品知识图谱,<em class='similar'>利用第4章提出的模型,</em><em class='similar'>在第3章建立的数据集上进行训练,</em>并提取出语料中的风险信息语句补全知识图谱。⁞值得注意的是,对于识别出的实体,需要对其进行关系拼接,以&quot;甲醛溶液&quot;的风险信息&quot;其蒸汽与空气可形成爆炸性混合物,遇明火、</p>
	                    <div class="textFrom">——常州大学硕士论文 程钊-《面向危险化学品的知识图谱构建研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现神经网络的无监督训练.通过将预测图像输入网络模型得到对应的视差图,再根据视差图与深度图之间的几何关系,得到图像的深度图.<em class='similar'>本文所提出的网络模型在 KITTI 驾驶数据集上进行训练,</em>在测试集上得到了优于现存的大部分方法的误差值和准确率,以及更为清晰的物体边缘轮廓信息,从而验证了本文所提出方法在单幅图像深度估计中的有效性和优异性.⁞关键词:深度估计;</p>
	                    <div class="textFrom">——小型微型计算机系统 -《应用残差稠密网络的无监督单幅图像深度估计》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过注意力机制(AttentionMechanism)对卷积网络提取的高维特征信息进行加权,通过两组长短期记忆神经网络和全连接网络分别对车辆下一时刻速度和方向盘转角进行预测。<em class='similar'>本文中所提出的模型使用 Comma.</em><em class='similar'>ai驾驶数据集进行训练,</em>训练结果表明基于深度神经网络的端到端驾驶决策模型对车速、方向盘转角可以取得较好的预测效果,并能够有效降低模型预测的平均绝对误差(Mean Absolute Error,MAE)。⁞(2)</p>
	                    <div class="textFrom">——吉林大学硕士论文 王奎霖-《基于端到端学习的自动驾驶决策算法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>CUDA(Compute Unified Device Architecture)<em class='similar'>架构升级为 Pascal,</em><em class='similar'>每瓦性能提高一倍。</em>同时,由于支持 PyTorch、TensorFlow 和 Caffe 等深度学习框架,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>性能强大(1 TFLOPS),外形小巧,节能高效(7.5W),非常适合机器人、无人机、智能摄像机和便携医疗设备等智能终端设备。 Jatson TX2与 TX1相比,内存和 eMMC 提高了一倍,<em class='similar'>CUDA 架构升级为 Pascal,</em><em class='similar'>每瓦性能提高一倍,</em>支持 Jetson TX1模块的所有功能,支持更大、更深、更复杂的深度神经网络。2. TX2刷机系统要求要给TX2刷机,需要一台装有Ubuntu 16.04系统的主机1.</p>
	                    <div class="textFrom">——网页 -《TX2刷机和使用常见问题 - bluewhalerobot的博客 - CSDN博客》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_25" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于小波变换的汽车语音特征指令逼近与端点检测方法" target="_blank">基于小波变换的汽车语音特征指令逼近与端点检测方法</a></span>
                      <p>石海燕 -
                        《浙江工业大学硕士论文
                        》- 2009 
                      </p>
                    </div></td>
                  <td><span class="green">2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://www.docin.com/p%2D1784871189.html" target="_blank">2013年上海大众帕萨特NMS电器培训教材</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>字信号处理器(Digital Signal Processor,DSP)用于降低车辆噪音,<em class='similar'>如发动机噪音、</em>传输噪音、<em class='similar'>轮胎噪音和空气动力噪音等。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>高速行驶中汽车轮胎在地面上的滚动、车身与空气的作用,是产生汽车⁞噪音的根本原因。汽车噪音一般可以分为发动机噪音、排气系统噪音、风扇噪音、<em class='similar'>⁞传动系统噪音、</em><em class='similar'>轮胎噪音、</em><em class='similar'>制动噪音、</em><em class='similar'>气动噪音等。</em><em class='similar'>发动机噪音,</em>除了发动机机⁞体发出的机械声外,还包括进气系统噪音和排气系统噪音。高速气体经空气滤清⁞器、进气管、气门进入气缸,在流动过程中,会产生一种很强的气动噪音。</p>
	                    <div class="textFrom">——浙江工业大学硕士论文 石海燕-《基于小波变换的汽车语音特征指令逼近与端点检测方法》-2009 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>功率放大器信息娱乐系统售后服务培训中心页数:70功率放大器另一种执行DSP功能的方法是根据车速连续地改变频率特性(加重低于200Hz的频率),即:部分降低汽车行驶时产生的物理噪音<em class='similar'>(空气动力噪音、</em><em class='similar'>来自轮胎的噪音、</em><em class='similar'>发动机噪音)</em>.信息娱乐系统售后服务培训中心页数:71双低音喇叭箱(2Ω装在后座衣帽架下面信息娱乐系统售后服务培训中心页数:72功率放大器安装位置在驾驶员座椅下方诊断地址:47信息娱乐</p>
	                    <div class="textFrom">——网页 -《2013年上海大众帕萨特NMS电器培训教材》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_26" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=非独立同分布词语相关度计算方法研究" target="_blank">非独立同分布词语相关度计算方法研究</a></span>
                      <p>张玉腾 -
                        《齐鲁工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>"↓"表示该项指标越低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>即低层次的显式共现⁞耦合,低层次的显式超链接耦合和高层次的隐式概念耦合。由于 CCE 具有全面捕⁞捉概念耦合的强大功能,因此在所有对比方法中获得了最佳结果。⁞(1)<em class='similar'>加粗表示最优结果,</em><em class='similar'>下划线表示次优结果,</em>*表示 CCE 比次优结果提升的百分比。齐鲁工业大学硕士学位论文⁞21⁞表3.2所有数据集上的平均斯皮尔曼秩相关性系数。。⁞Families  Methods </p>
	                    <div class="textFrom">——齐鲁工业大学硕士论文 张玉腾-《非独立同分布词语相关度计算方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_27" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的在线字临摹分析系统设计" target="_blank">基于深度学习的在线字临摹分析系统设计</a></span>
                      <p>张承强;张永爱;顾兴权 -
                        《信息技术与网络安全
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络分类器链算法的肺癌证型分类研究" target="_blank">基于神经网络分类器链算法的肺癌证型分类研究</a></span>
                      <p>刘梦玲 -
                        《江西中医药大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=视听觉信息特征提取与融合方法研究" target="_blank">视听觉信息特征提取与融合方法研究</a></span>
                      <p>江彦桥 -
                        《电子科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=知识图谱分布式表示学习方法及应用研究" target="_blank">知识图谱分布式表示学习方法及应用研究</a></span>
                      <p>张金斗 -
                        《中国科学技术大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.6%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>和分别设置为0.9和0.1。</em><em class='similar'>训练过程中各个模型在验证集上的损失</em><em class='similar'>(Loss)</em><em class='similar'>曲线如图5-4所示</em>(从第10次迭代开始)。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>随训练轮次的变化。⁞在验证集上,使用基于多层 CNN 的视觉特征提取模型并分类测试,准确率 acc⁞性达到88.8%,但模型的收敛较慢。<em class='similar'>⁞⁞图4-4多层 CNN 模型训练过程的准确率 acc 和损失 loss 曲线⁞在验证集上,</em>对多层 CNN 提取的视觉特征采用 T-SNE 方法进行二维可视化⁞后,效果如图4-5。</p>
	                    <div class="textFrom">——电子科技大学硕士论文 江彦桥-《视听觉信息特征提取与融合方法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>设置batch_size、学习率和网络输入的大小,指定模型保存路径,损失函数选择sigmoid交叉熵,优化器选择Adam,并设置其他相关参数[11]。设置完所有的参数后,对模型进行训练,<em class='similar'>如图3和图4所示,</em><em class='similar'>分别是模型训练过程中的精度曲线和损失值</em><em class='similar'>(loss)</em>曲线。图3迭代次数与准确率的关系图图4迭代次数与损失值的关系图3字相似度算法本文的字相似度算法比现有的传统字相似度算法简单,且符合直观感受,</p>
	                    <div class="textFrom">——信息技术与网络安全 张承强；张永爱；顾兴权-《基于深度学习的在线字临摹分析系统设计》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>表中&quot;↑&quot;/&quot;↓&quot;分别表示该项指标越高/低越好,</em><em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em>从表中可以看出,第4章所提模型在 CQUPT-DS 上除了 Latency 值外,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>四种不同基分类器下的二元相关分类模型下验证特征集合的性能,性能比较结果见表3-8,字母F 表示特征全集,字母 S 表示最优特征子集,<em class='similar'>加粗的数字表示各个指标中的最优结果,</em><em class='similar'>&quot;↓&quot;表示评价指标的值越小越好,</em><em class='similar'>&quot;↑&quot;表示评价指标的值越大越好。</em></p>
	                    <div class="textFrom">——江西中医药大学硕士论文 刘梦玲-《基于神经网络分类器链算法的肺癌证型分类研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>8710.7910.7970.7250.9810.9380.9370.861⁞(+3.4%)(+2.9%)(+5.8%)(+7.7%)(+0.4%)(+0.9%)(+6.7%)(+7.4%)⁞注:黑体数字表示最优结果,<em class='similar'>下划线数字表示次优结果,</em>括分里面的数值表示⁞FKAPR与次优的结果相比提升的百分比⁞表5.3和图5.3分别给出了所有方法在四个数据集上CTR预测的AUC、F1值⁞和Top-K推荐的Recall@K指标值。</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 张金斗-《知识图谱分布式表示学习方法及应用研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_28" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于端到端学习的自动驾驶决策算法研究" target="_blank">基于端到端学习的自动驾驶决策算法研究</a></span>
                      <p>王奎霖 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向危险化学品的知识图谱构建研究" target="_blank">面向危险化学品的知识图谱构建研究</a></span>
                      <p>程钊 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用残差稠密网络的无监督单幅图像深度估计" target="_blank">应用残差稠密网络的无监督单幅图像深度估计</a></span>
                      <p> -
                        《小型微型计算机系统
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>接着将论文第3章、<em class='similar'>第4章提出的模型分别在驾驶数据集上进行训练,</em>最后集成、移植网络模型至 TX2并围绕搭建全套硬件平台。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>与对应化学品有&quot;避免接触条件&quot;关系⁞图5-4甲醛溶液的相关特性⁞5.1.2应用模型进行风险信息补全⁞为构建更加全面的含有风险信息的危险化学品知识图谱,<em class='similar'>利用第4章提出的模型,</em><em class='similar'>在第3章建立的数据集上进行训练,</em>并提取出语料中的风险信息语句补全知识图谱。⁞值得注意的是,对于识别出的实体,需要对其进行关系拼接,以&quot;甲醛溶液&quot;的风险信息&quot;其蒸汽与空气可形成爆炸性混合物,遇明火、</p>
	                    <div class="textFrom">——常州大学硕士论文 程钊-《面向危险化学品的知识图谱构建研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现神经网络的无监督训练.通过将预测图像输入网络模型得到对应的视差图,再根据视差图与深度图之间的几何关系,得到图像的深度图.<em class='similar'>本文所提出的网络模型在 KITTI 驾驶数据集上进行训练,</em>在测试集上得到了优于现存的大部分方法的误差值和准确率,以及更为清晰的物体边缘轮廓信息,从而验证了本文所提出方法在单幅图像深度估计中的有效性和优异性.⁞关键词:深度估计;</p>
	                    <div class="textFrom">——小型微型计算机系统 -《应用残差稠密网络的无监督单幅图像深度估计》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过注意力机制(AttentionMechanism)对卷积网络提取的高维特征信息进行加权,通过两组长短期记忆神经网络和全连接网络分别对车辆下一时刻速度和方向盘转角进行预测。<em class='similar'>本文中所提出的模型使用 Comma.</em><em class='similar'>ai驾驶数据集进行训练,</em>训练结果表明基于深度神经网络的端到端驾驶决策模型对车速、方向盘转角可以取得较好的预测效果,并能够有效降低模型预测的平均绝对误差(Mean Absolute Error,MAE)。⁞(2)</p>
	                    <div class="textFrom">——吉林大学硕士论文 王奎霖-《基于端到端学习的自动驾驶决策算法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第6章 总结与展望</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_29" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">16.4%(291字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于双流CNN与Bi-LSTM的施工人员不安全行为轻量级识别模型" target="_blank">基于双流CNN与Bi-LSTM的施工人员不安全行为轻量级识别模型</a></span>
                      <p>马莉;王卓;代新冠;贾荣豪 -
                        《西安科技大学学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=回归测试中测试用例优先级排序技术研究" target="_blank">回归测试中测试用例优先级排序技术研究</a></span>
                      <p>王一婷 -
                        《西南大学硕士论文
                        》- 2016 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=环境规制对制造企业创新投入的影响" target="_blank">环境规制对制造企业创新投入的影响</a></span>
                      <p>王飞飞 -
                        《浙江工商大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">1.6%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=便携式相位光栅轮廓全貌测量技术研究" target="_blank">便携式相位光栅轮廓全貌测量技术研究</a></span>
                      <p>陈新禹 -
                        《大连海事大学博士论文
                        》- 2014 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=污水深度处理" target="_blank">污水深度处理</a></span>
                      <p>夏明伟 -
                        《大庆石油学院硕士论文
                        》- 2008 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向海量数据检索的矢量空间索引" target="_blank">面向海量数据检索的矢量空间索引</a></span>
                      <p>韦祎 -
                        《中国矿业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=合成甲醇催化剂的研究及合成反应优化操作" target="_blank">合成甲醇催化剂的研究及合成反应优化操作</a></span>
                      <p>赵忠尧 -
                        《大庆石油大学硕士论文
                        》- 2006 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响" target="_blank">根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响</a></span>
                      <p>黄毅 -
                        《中国农业科学院硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的素描人脸合成技术研究" target="_blank">基于深度学习的素描人脸合成技术研究</a></span>
                      <p>李凯旋 -
                        《北京信息科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_29" class="simMore"><a href="javascript:$ShowMore(29);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>互的一种具体技术形式,<em class='similar'>在车载终端控制、</em><em class='similar'>智能客服和智能家居等领域有着广泛的应用。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>本章还通过对比实验验证了提出方法的有效性,并通过消融实验验证了各个模块的作用。⁞ ⁞第5章总结与展望⁞5.1总结⁞自动语音识别作为人工智能领域重要的研究方向之一,在智能客服、人机交互、<em class='similar'>车载终端控制以及智能家居等方面有着广泛的应用。</em>其中,基于编码器-解码器结构的端到端语音识别模型是近年来备受关注研究热点,而优化其使用的注意力机制以及实现模型的轻量化也是当前的研究难点。本文首先回顾</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>和自然语言理解技术的研究现状,<em class='similar'>然后分析现有方法存在的问题,</em><em class='similar'>提出了相应的改进方案,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>本章介绍了测量系统中多视数据拼接的方法,在相较各方法的基础上,本文选用基⁞于粘性标记点的多视拼接技术。详细介绍了基于粘性标记点数据拼接方法涉及到的关键⁞技术,<em class='similar'>同时分析了现有方法存在的缺点,</em><em class='similar'>并提出了相应的改进方案。</em>本章主要研究内容⁞如下:⁞(1)详细介绍了现有特征点立体视觉匹配算法,分析了现有方法的优缺点,同时针⁞对本文研发系统的测量特点,提出了一种同时适用于动态和静态测量过程的特征点立体</p>
	                    <div class="textFrom">——大连海事大学博士论文 陈新禹-《便携式相位光栅轮廓全貌测量技术研究》-2014 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>脸合成方法改善了合成素描人脸图像的纹理效果,提高了素描人脸图像的真实性,但是合成结果仍然存在面部细节丢失、清晰度低等问题。本文通过对现有的素描人脸合成方法进行分析,<em class='similar'>针对现有方法中所存在的问题,</em><em class='similar'>提出一些改进方案,</em>主要贡献概括⁞如下:⁞1、提出一种基于双层生成对抗网络的素描人脸合成方法。传统的素描人脸合成方法存在复杂的图像分块、拼接步骤,容易导致合成结果出现栅格现象,缺乏纹理真实性,</p>
	                    <div class="textFrom">——北京信息科技大学硕士论文 李凯旋-《基于深度学习的素描人脸合成技术研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>QRB+树相比常用空间索引有显著的性能提升,⁞可为大规模矢量/空间数据的高效组织提供技术支撑。本文主要工作如下:⁞(1)梳理了空间索引中树状索引、网格索引、混合索引和精细查询策略的发展现状,<em class='similar'>并分析了现有方法存在的问题;</em>依据对研究现状的分析,制定本文的研究内容和研究路线,并说明了本文的组织结构,为后续研究奠定基础。⁞(2)针对 QR 树索引在空间查询中存在的 R 树冗余检索问题,</p>
	                    <div class="textFrom">——中国矿业大学硕士论文 韦祎-《面向海量数据检索的矢量空间索引》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>针对基于深度编—解码器的模型参数量庞大的问题,</em><em class='similar'>提出了一种基于残差分组线性变换的解码器结构。</em><em class='similar'>该结构关键模块为&quot;钻石&quot;型缩放单元,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>通过研究全局注意力机制和局部注意力机制在不同拓扑结构下的识别效果,提出了效果最优的&quot;局部—全局&quot;级联结构的融合注意力机制;提出了基于该融合注意力机制的编码器网络结构。⁞3.<em class='similar'>基于分层分组线性变换的解码器⁞针对编码器-解码器模型参数量庞大、</em><em class='similar'>计算复杂度高的问题,</em><em class='similar'>提出了基于分层分组线性变换的扩张缩放单元,</em>该单元内部采用稀疏连接,同组神经元共享同一权值矩阵,在实现较低计算量的同时大幅降低网络参数量;</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>所提模型能以识别准确率的小幅度降低为代价,</em><em class='similar'>实现参数量和计算复杂度的降低。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>7493.1⁞基准模型1+ CBAM 7.735.3293.5⁞由表7可以看出,在引入 CBAM 后模型计算复杂度与模型参数量虽均有较小提高,但模型识别准确率有较大提升。实验结果表明,<em class='similar'>CBAM 的引入以模型参数量与计算复杂度较小幅度的增加换取了识别准确率0.4%的提升,</em>可满足文中模型设计的需求,因此,文中将 CBAM 引入该模型以提高模型识别准确率。⁞3.3.2 LSTM,Bi-LSTM 引入前后性能对比⁞为了验证 </p>
	                    <div class="textFrom">——西安科技大学学报 马莉；王卓；代新冠；贾荣豪-《基于双流CNN与Bi-LSTM的施工人员不安全行为轻量级识别模型》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>即无法在输入语音信号的同时进行识别,</em><em class='similar'>这会在一些实时性要求较高的场景中导致语音识别的体验降低。</em><em class='similar'>下一步可以考虑使用分块技术对编码器网络中的注意力机制进行优化,</em><em class='similar'>以建立在当前输入时刻语音帧和历史信息之间的联系,</em><em class='similar'>从而支持流式自动语音识别。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>最后,本文对未来的研究工作进行展望:⁞1.<em class='similar'>对流式语音识别的支持。</em>本文提出的改进Transformer模型目前还不支持流式的语音识别,仅能在完整语音信号输入完毕后开始输出识别结果,<em class='similar'>不能做到在输入部分语音信号的同时进行识别,</em><em class='similar'>在对实时性要求较高的某些场景中会一定程度降低语音识别的体验。</em><em class='similar'>下一步,</em><em class='similar'>可以考虑使用分块技术对编码器网络中的注意力机制进行改进,</em><em class='similar'>使得其能够建立当前输入时刻语音帧和历史信息之间的联系,</em>进而实现对流式语音识别的支持。⁞2.对非自回归语音识别的支持。目前采用的是自回归式解码,在进行识别时,解码器将逐个输出识别字符。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>可能会影响模型推理效率。<em class='similar'>下一步可以考虑采用非自回归的训练方式对模型进行训练,</em><em class='similar'>以进一步提高模型的预测速度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>解码器将逐个输出识别字符。随着文本长度逐渐增加,采用自回归式解码方式的计算复杂度会以平方的速度增加,在某些极端情况下,会严重影响语音识别系统的识别效率。<em class='similar'>下一步的研究内容是考虑采用非自回归的训练方式对模型进行训练,</em><em class='similar'>进一步提高模型的识别速度。</em>⁞ ⁞参考文献⁞[1]叶硕,褚钰,王祎,李田港.语音识别中声学模型研究综述[J].计算机技术与发展,2020,30(03):181-186.⁞[2]俞栋,邓力,俞凯,等.解析深度学习:语音识别实践[M]</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>在即将完成学位论文之际,</em><em class='similar'>我想要借此机会表达我最深切的感激之情。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>转眼间又将是一个毕业季,在与西南大学相处的7年里,我过得⁞特别充实,感触也是颇多。期间,老师和同学们的引导、帮助和激励,都让我受⁞益匪浅,<em class='similar'>所以在学位论文即将完成之际,</em><em class='similar'>我想借此机会向他们表达我心中的感激⁞之情。</em>⁞首先,我想感谢的是我的导师丁晓明副教授。丁老师不仅是我学习上的导师,⁞他也是我生活中的朋友,他幽默风趣、待人宽厚,在研究生的这三年里,</p>
	                    <div class="textFrom">——西南大学硕士论文 王一婷-《回归测试中测试用例优先级排序技术研究》-2016 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>途。回首研究生两年⁞半的生活,这期间,有过迷茫、失落、痛苦,但更多的是充实、快乐和满足。点滴收⁞获与进步,除了靠自己的努力和坚持,更离不开这期间帮助我的老师、同学及家人⁞们,<em class='similar'>在学位论文完成之际,</em><em class='similar'>我想借此机会向他们表达我心中的感激。</em>⁞首先,由衷地感谢我的导师蒋樟生副教授在整个研究生学习中对我的指导和帮助。⁞他严谨的逻辑思维、渊博的学术知识以及令人称道的道德品质都在我心中留下了深刻的</p>
	                    <div class="textFrom">——浙江工商大学硕士论文 王飞飞-《环境规制对制造企业创新投入的影响》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>您的教诲将对我今后的学术生涯产生深远的影响,</em><em class='similar'>我将终生铭记。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>、创造性的思维方式和献身事业的敬业精神令我终身难忘,这不仅使我在研⁞究生学习和论文工作中受益匪浅,<em class='similar'>同时也将对我未来的学术生涯和人生之路产生深远的⁞影响,</em><em class='similar'>我将终生铭记。</em>在此向导师表示深深的敬意和衷心的感谢。⁞在完成学业期间,得到单位领导和同事的大力支持和帮助,在此向他们表示深深的⁞谢意。最后感谢化学化工学院的全体老师对我的培养和帮助!</p>
	                    <div class="textFrom">——大庆石油学院硕士论文 夏明伟-《污水深度处理》-2008 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>、创造性的思维方式和献身事业的敬业精神令我终身难忘,这不仅使我在研究生⁞学习和论文工作中受益匪浅,<em class='similar'>同时也将对我未来的学术生涯和人生之路产生深远影响,</em><em class='similar'>我⁞将终生铭记。</em>在此向导师表示深深的敬意和衷心的感谢。⁞在完成学业期间,得到单位领导和同事的大力支持和帮助,在此向他们表示深深的谢⁞意。同时,对在论文中给予帮助的博2005李金环同学,</p>
	                    <div class="textFrom">——大庆石油大学硕士论文 赵忠尧-《合成甲醇催化剂的研究及合成反应优化操作》-2006 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>你们的意见和建议帮助我不断完善研究内容和论文质量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>提出许多的宝贵意见,让我受益匪浅,并且在生活中给予我最大的帮助,向李老师致以衷心的感⁞谢!⁞也感谢在开题报告、中期检查和毕业答辩中为我的论文提出宝贵意见和建议的老师等。<em class='similar'>您们⁞的意见和建议使我不断完善课题研究,</em><em class='similar'>提高了论文质量。</em>⁞感谢在我研究工作中提供帮助的课题组贺超兴老师、闫妍老师、邢师傅;感谢已经毕业的慕⁞英师姐、马俊师姐、郭允娜师姐、于二敏师姐、常蕊师姐、张小翠师姐、</p>
	                    <div class="textFrom">——中国农业科学院硕士论文 黄毅-《根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响》-2017 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
          	</div>
          	<div class="report_explain2">
              <div class="repExp_left">说明：</div>
              <div class="repExp_rig">
                <p>1.指标是由系统根据《学术论文不端行为的界定标准》自动生成的</p>
                <p>2.本报告单仅对您所选择比对资源范围内检测结果负责</p>
              </div>
            </div>
            <div class="clear"></div>
            <div class="report_footer">
			    <div class="assist_tool">
			      <h2>写作辅助工具</h2>
			      <ul>
			        <li>
			          <div class="asst icons asst1"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommendtitle/">选题分析</a>
			            <p>帮您选择合适的论文题目</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst2"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommenddata/">资料搜集</a>
			            <p>提供最全最好的参考文章</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst3"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommendoutline/">提纲推荐</a>
			            <p>辅助生成文章大纲</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst4"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/writing/">在线写作</a>
			            <p>规范写作，提供灵感</p>
			          </div>
			        </li>
			        <li class="bgNo">
			          <div class="asst icons asst5"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/reference/">参考文献</a>
			            <p>规范参考文献，查漏补缺</p>
			          </div>
			        </li>
			      </ul>
			    </div>
			    <div class="repFot_bot">
			      <div class="reportCopy inlineBlock">版权所有：笔杆 www.bigan.net</div>
			      <div class="shareTo inlineBlock"><span>分享到：</span> <a href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https%3A%2F%2Fwww.bigan.net&title=%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%EF%BC%8C%E6%8B%BF%E8%B5%B7%E7%AC%94%E6%9D%86%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E5%BF%AB%E4%B9%90%E7%9A%84%E5%AD%A6%E6%9C%AF%E5%B8%9D%E3%80%82&summary=%E7%AC%94%E6%9D%86%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%86%99%E4%BD%9C%E5%B9%B3%E5%8F%B0%E3%80%82%E7%AC%94%E6%9D%86%E4%B8%BA%E4%BD%A0%E6%89%AB%E6%B8%85%E5%86%99%E4%BD%9C%E6%80%9D%E8%B7%AF%E7%9A%84%E9%98%B4%E9%9C%BE%EF%BC%8C%E6%89%BE%E5%88%B0%E6%89%8D%E6%80%9D%E6%B3%89%E6%B6%8C%EF%BC%8C%E7%81%B5%E6%84%9F%E8%BF%B8%E5%8F%91%E7%9A%84%E5%BF%AB%E6%84%9F%EF%BC%8C%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BF%A1%E6%89%8B%E6%8B%88%E6%9D%A5%E3%80%82www.bigan.net&pics=https%3A%2F%2Fwww.bigan.net%2Flogo_80_80.png" target="_blank" title="QQ空间" class="inlineBlock sitem1 icons pngfix"></a> <a href="#" title="微信" class="inlineBlock sitem2 icons pngfix"></a> <a href="http://service.weibo.com/share/share.php?url=https%3A%2F%2Fwww.bigan.net&title=%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%EF%BC%8C%E6%8B%BF%E8%B5%B7%E7%AC%94%E6%9D%86%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E5%BF%AB%E4%B9%90%E7%9A%84%E5%AD%A6%E6%9C%AF%E5%B8%9D%E3%80%82%EF%BC%88%E7%AC%94%E6%9D%86%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%86%99%E4%BD%9C%E5%B9%B3%E5%8F%B0%E3%80%82%E7%AC%94%E6%9D%86%E4%B8%BA%E4%BD%A0%E6%89%AB%E6%B8%85%E5%86%99%E4%BD%9C%E6%80%9D%E8%B7%AF%E7%9A%84%E9%98%B4%E9%9C%BE%EF%BC%8C%E6%89%BE%E5%88%B0%E6%89%8D%E6%80%9D%E6%B3%89%E6%B6%8C%EF%BC%8C%E7%81%B5%E6%84%9F%E8%BF%B8%E5%8F%91%E7%9A%84%E5%BF%AB%E6%84%9F%EF%BC%8C%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BF%A1%E6%89%8B%E6%8B%88%E6%9D%A5%E3%80%82%40%E7%AC%94%E6%9D%86%E7%BD%91%EF%BC%89" target="_blank" title="新浪微博" class="inlineBlock sitem3 icons pngfix"></a> </div>
			    </div>
			  </div>
      	   </div>
  	   </div>
  </div>
</div>
</div>
</body>
</html>