<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<title>笔杆检测报告单（全文对照）</title>
	<meta name="keywords" content="" />
	<meta name="description" content="" />
    <meta content="0" http-equiv="Expires"/>
    <meta content="no-cache" http-equiv="Pragma"/>
    <meta content="no-cache" http-equiv="Cache-Control"/>
    <meta content="no-cache" http-equiv="Cache"/>
	<link href="css/report.css?v20180524" type="text/css" rel="stylesheet" />
	<script src="js/jquery.tools.pack.js" type="text/javascript"></script>
	<script type="text/javascript">
    function $ShowMore(n) {
        if ($("#simMore_" + n + " a").text() == '收起相似文献') {//收起
            $("#reportTable_" + n + " .trLike").hide();
            for (var i = 0; i < 5; i++) {
                $("#reportTable_" + n + " .trLike:eq("+i+")").show();
            }
            $("#simMore_" + n + " a").html('查看更多相似文献<span class="icons inlineBlock simDown"></span>');
        } else {
            $("#reportTable_" + n + " .trLike").show();
            $("#simMore_" + n + " a").html('收起相似文献<span class="icons inlineBlock simUp"></span>');
        }
}</script>
<style>
    em.similar{color:Red; font-style:normal;}
</style>
</head>
<body>
<div class="report_bg2">
  <div class="report_bg3">
    <div class="report_top">
      
      <h1>笔杆检测报告单<span>（全文对照）</span></h1>
    </div>
    <div class="report_Wrap">
      <div class="report_tab" id="report_tab">
      	<ul>
                                            <li><div><a href="全文标明引文.html" class="green">全文标明引文</a></div></li>
                                            <li class="rep_curr"><div><a href="全文对照" class="green">全文对照</a></div></li>
        </ul>
      	<div class="report_priSav">
          <a href="javascript:window.print();" class="print inlineBlock"><span class="icons inlineBlock"></span>打印</a>
          <a target="_blank" href="https://www.bigan.net/report/explain.html" class="report_explain inlineBlock"><span class="icons inlineBlock"></span>检测说明</a>
        </div>
      </div>
      <div class="report_content">
        <div class="report_main">
          <a id="toTop" title="回到顶部"></a><!-- 回到顶部 -->
          <script>
              $(document).ready(function () {
                  $("#toTop").hide();
                  //检测屏幕高度
                  var height = $(window).height();
                  //scroll() 方法为滚动事件
                  $(window).scroll(function () {
                      if ($(window).scrollTop() > height) {
                          $("#toTop").fadeIn(500);
                      } else {
                          $("#toTop").fadeOut(500);
                      }
                  });
                  $("#toTop").click(function () {
                      $('body,html').animate({ scrollTop: 0 }, 100);
                      return false;
                  });
              });
          </script>
           <div class="report_Mtop"></div>
          <div class="report_Mbot">
            <div class="report_result">
              <div class="report_info">
                <p><span>标题：</span>查重版.pdf</p>
                <p><span>作者：</span>黄子恒</p>
                <p><span>报告编号：</span>BG202303191404576795</p>
                <p><span>提交时间：</span>2023-03-19 14:05:23</p>
              </div>
              <div class="report_ratio">
                <ul>
                  <li style="display:none;"><span class="icons ratioIcon ratio1"></span>总复制比：<span class="green">12.4%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio2"></span>去除引用文献复制比：<span class="green">12.2%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio3"></span>去除本人已发表文献复制比：<span class="green">12.4%</span></li>
                  <li class="inlineBlock"><span class="icons ratioIcon ratio4"></span>单篇最大文字复制比：<span class="green">0.7%</span></li>
                </ul>
              </div>
               <div class="clear"></div>
              <div class="seal">
                <div class="SealArea">
                  <div class="SealBg"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAIAAAAA4vtyAABpGUlEQVR42sx9B3xkVdn+uVMz6clMerK77LLLUpcmIAgiCCJFigU+BUUUBUFUQBAUBMUG+v+soIKgUqUsbEmfzEymZVJ3s733ljIzt/d7z/997ywhbHbXRT+/3ze/axyyyWTmOe953uc55z3vJdJ/+CHKzldRhK+KosATnufhuazC/zhBzElSVpE5+A4vqIJgcaas53hBUSeppeUVOiEqkqoIogQ/JPC8KIj4EpIqa4asCzl+n6Rypi1ppiwqmqGKtsRpOVnF1xSlvKxwiga/K8Kf1lVNlRWqaVTRNVEVNI03DUFTeFXMa5wuinBpEvw5GR7w/uDXOEme+YnkaY/CR5t6HDss5H8H98LbLbwzeAIocBx8Rg3hU2RdFhQxL4l5RYVB4U1B5hTlgKpwsi6qRk7XeVXlFEnSVMMy4aHrumlbOrVFS5+gFqvqumrZNlVtk9VkAM+yDFXX4K84Lw7jLcmmmrPk3UpOy42rQh4gprJmqyYMqsTxMNKqKBQuWZQKuMMFw/+fAP1/A3dBgCjl4V2q6nufgWc5+EiipAm8Ahd+ePhJiRUV1lYR1UlVPqBKom0ZlGq2Tk0NUKVwSZw1MWYd2EsnD9D8BOUn7fEJKgiU47V94/r+CYuXqW6bpi0YNmdYvGlxhgmhLcNkUFQYUVXIyoYomApOHR7nnajrsm7IkoCXeBBcmF4F6A9Gz7vITgd9+vcP/tb/HdzfCwoZYx8HQFacuTwuK3knxkxeo5xO4atoUnjAZxapblBN2bqFDcf4pcv0xUv3v/7qnuef3/TzJ9c+8IP19z689t4HV9334KrvPbz/Oz9U//LSjt88Hb3nwQ3PvED376OWwu7dDYEv2YZCqUyRhTTRgBGgrJEV8jBvVNtmTTNvGJxmsBpMBRUmx3TgCu92arLOxH16vE99//8Q7hBBSOuFz6DIEP4CzGtZycljrJrlFAFiSpcMM6/aYyzdNzmxcf2eeELds5Xu3bL/x0+lzrwkMW9RunFBdPaJ0Yb54ZKmHk9txB1qd1Ut81S1VzYuLa0dOeuC7uNOfs5XHfvktcJrL068+lLynu9kbvvm5p/+il2+XN+8wRaylq0B3JMw82DWSKYuGKJiChYVVU3OsmYOUoKCMQ5D7rzPKbink0mBIQ/BfeYk+L/B77xQmLa8LMElAP6iZGn6ODUEWzd4wdi8Te6O7v/Dn9bf+8DIrV9JfuLGntMvXfvlb4z98PHV5368g5S2uwJdxNdJinqZ0hQpHSClQ6Ssn5StKGnY2nJSet6CZMPsDlf5MlLSN2fh5osuGzjp7NdJWZQpi5c2pOecMnjBZau+9LWNP/vF2NK39dFBc2wCyB3py7JVSMRAQHmW5pH3eFnh3w1zB0bRSUni9KCejvsU0P8XcYfQBuiBTDkYAlmCxEhtClRLVY3u2iMt79rzgx+PXnFt/LgTOgLlrcTb5q1YSrydZQ2JeSenSpvjpCLtDg4xoc6iylhJKF4civtCcXcw5gn2l81a23jy3nMuXdl0Uq+/Ju6ryRTV9bmr4g7oPcQdJ0UJpriXKY+4qrp9dcn6hWtP++iGh3649+UXtc2rKTdJVZmahqHp1LJR3qgqK4O0EjE4QB6hkML8NJ3BZ0Isv//xfwh3Ls9CvKsmCD/NAhHCC5vWrNv8+z8O3n1v21kXvFMcCpOiFAmkXEUxxhcnZNAT6HUFOkgg7A6GvXVRT8Oge3aahPpddRlXQ4JpiLuaokxTJ2mAK1qxoK/m5IHKE/p8Tf2+upQ3lHCXD/mCXaHazKzjhhvnpEtqAfoYKYuQcrjeIiVvV7fEr/z02t/9fmx0hZDNshN5OS8LpsHpGugoVhQctcoj9LI4hfuR8C38p/Lu4z+F+8xRLUxDXprUJB5FrwzaAAUyx+ZYhYXpzImWzJoUJ/U4u3p471/+OvCNuwc/c1P4xLOixU39RU2j9QtH556RCM3v9DWlGIjZhn5vU8rTkHTXwwVPUh4AdFbC3dzLNMIFuMNz+ArPl7pKl3vK271VYV8w5q9JBOoS/vqEpzZWc8LogvNWLzg/XjG/h9T3MY2DnqY0U9PpJj2MK+KBcS1KLTp94y1fWP9fn994953cimFIAxo18oaSFxXQWsDnADokoby0nzUm8lSEDKzwIFSVnMLDP01pmOkDc4yykvxPKRaeZyE1Kaqe51heyGm6BJYkp+poZyiQi7xnfd+q3z2ZvOTK2JkXjz3xJGV3bf7lz1tnn9RFytc1n7Du+NMzZXMHXLMTpAagT7vq4WuS1OJXB/2Yuw6uhKsOvpNh6geZhiHSMEzqk6QxRZrgSjPNfa5Zfd45cKU9s2OBplRwXjq4IBZoieNv1aRcwbi7OuWrH/TVD7lr06Siy1W6LFC61BtYEggsP+f8LT97Qt200jBFHchHNkHgjkHog3syVdC4di5PORG82xjPQVYopNkC0NO56H8Vd+QTzZ4QQHQr++W8bghUE23bFik1qDW5Y9VE22srvvrF3rkLWgmzpCwkPfZzW9qz64/PRBeem3DVrA7O7atoCpOqfqYpTRrgSjENAHoB98LV7aqGq8cVjLqB32vgt+BKumv7fDgb4Al8M+ap6fXU9/oaEkVNkBUSnhCkAfj5pDuU8tQA6BFPRdrTDGQFrAXfjLsqokxJj6+kh/jafIHX3P7IOedn//QMndipUJ2lpqyYYzrNSZbIqSLLSVzOUERN07Lce/lWcB5Tauc/y+/yjIeqmFlFBVEsiLKlqVSXqaUrkwfEWHLdzXcOtZzW462KMH4g8TZvSeKkRdGrr42d9uFk8XHDTHO/q6GHlEfdVWl/rYN73cHLVV+4APcRgtcgqc0wtX2u2rSrtoB1glRC7oWvKVKdZoIpEoILfmCQqep3hxKkKkqq4IcH/PUpXw28h4ynGuDudVV1FlXHA3WZ0paessa0vyFDynpdxR2EedtbFL/2ymz3UrpnN9u3lpM1UTB4xcqZJtCokc+bnKSYVHz/Y0rt/Gf5XZnxECQe3hayyqRELXA/ujTSN3zffUvrT9989nVbFnw0VlzX4a9IBkLD7qo+4ku7ylOkvI9U9hdIwFM3EGiMk8qpMAew+tzA9fgErowr2MdUp0gVXq5qCOekB6+UtznpaYKvff45Sd/sXndzlGmEK0OqMhDmTE2chGAIB+BnPHUQ+/B9GKR0cUO4tC7MVPeSyiipXkkaVpKaXn8oWgqj6I+RksSCRYPX3DR849d3PP93ddtW0P75nACix5RVMNtgOBRFQwuIhlYpXBDxovgf0zMzEVedB1h8SeFVCwy9ZU+Oj//jrfgnb/gbKV3+8evo6KDy9xcGmk7pIRUd3vo+X91qpjwDcttVGiclYaa4y1PZU1SXKGqJk8aEKwhXnKmeetJLquCKeiuBJSLuchAnCVKeYiqAoDOkAkR9lBRHSDFox5irPO6pTPqq00WhtKsStE3SCyPa0O9uhLwKw9kLc4XMjrma08GFg/PPAL3fW1kf85YPkOK0rynMhMCRZfz1fZ6aTlK6lAks9Za82TJv1b33i0MDqsAKoN0VXHJA9fAu4lPo/8/gLh/hoRzhAaCbtmVbGr92xaYf/iBy/Cl/h6g59xJ+YidV9q1+9CFQ0BkS6i1q7PLWh70NPe4qAAU+JHyNeGu6PbU9rhoIW2BhIIEYUwlXlFRESGkBzQ5S0UkquzzBbl9NuLg+Ut4UqWiOVrZ0l5SEi4t7fEURjz/u6NEMCfSDcveURD0lMFSg6/u9DcA8SYKJIUmaou6mVONJa8+/ZOzzN2+7+pre2lmRQDW8OCTtNGnqJY0xb2O8qLbXVxHzBdqYon94ShI3fGayt0uUshD4kqZnVdFRO5Ijag5CX8D9GIX8B8b9SA8QLbpN96eH+2/8Uo8rECFk2RmLaCxCFbrq3keXljZ2kTKIxBhTFWeaM55TAOsIqekjLUNk3iCZM8TMcjikHMIWsA4zB68eV0ncX5kuCY1cePXoZTes/fQtG2+7Y9O992394SPbnvrJ9l//YuO9d2361p2bvvrVtZ+5afjiK5InndMWPP4tXz2IxU7G3cH4ul3FEPj9vlr4Cp6rj5QmPRW9wea+eafkb7sjd/PXI745va7j4qQaxGs/09JHgOub+5j6DKkeJcGhQEWPu2hpSXXq6k+PLW3lBHbCUEHVANwF3J0YVwrDwPPiB8B9KooPG9oFGpn6AUG2RNuSVE5n85Q3aR4Eo8hTmU5OZJ//2/CZ54HxSRDS5i/vv/4Ldrp/z/cffKki+BbxJSvqgTcgSXaRmp6ihrhnVsqNgjoNMsZdDbQA6RH4vZtAkFb1Fjf3zT599WWf3vnAo5N//Xu+o1Vct23flq10b07hJPD4mmpBFgG7z1MqWqY+aQmqsWty4kCsf/ydzL7n3lh/2/19H72qM9QEgd+HlO2HrDvkbe5hKlOBenCwYVflcGjuaP2CvqLGBAmCy4Vs0esFLoJM3ojZm0BGqRzyVCT9JVGXD6Zd31mXHnjxNVuTJg0ZzKwhGpB1WVOVZE4U8qaqmZPKMVpWMh3lY+ET3bDAEMkaUrkoqKDMqa6wG9Zs+e73uk879w1f2XJ/SdgdiBfXpk74EHzyTGX9clICyqHfA5+kAnQFpMEB0tJFSnr91cmiWhiMGAn1+JoTzacPn335us/dvv3uhw786ve5xW/zQ4PK3p2GzBuWiksL1BJMhRoGNWwOPrdpUBUUqwD8Nm5Tkeq6JoHvt6khKbuA36xN64xkdN+Lf4l/5ctvNy9YTsqAuwZIdZJUdpLiDk9FTyDUA1oTsq53DrxDUJaANeiiOBNC8+Wv7yVBsLhpd9VwoAaEELBczxkXbf7dM3TygDQxrvBALKbEylRSVE0YF3KmYhyJDw7FfXqkH5ItZ44EflPmLY6zFPBs8oSuQBblM/2Zr397aXkZOMAuoGNv7aC/KcOEepiKDnfpauIfZMpA0g2QIHwTUhYaH1dTxuNNM0U9pLiN1Ha2nJm+5oubf/5rvr1T273XzuVgLA0KGFMIa0WnoEs1Bbc+IIEplkZNDSSFpqJgnaBU5iTLVkVLh4jbu2H79nBM3rMD3DGuvOiqJnJ0fMwaHNj5q6eiN36ms2VhuLqlxw3Q+7shRRc39vlnJUkDCP8IqUoyIEZxYGASJCvmdAZa+t3NaQKsVd3pKYuSojAJ9C44e/uDj9KNGwxZyBq2lNdoHkiDHTc4XHw+Aksfivt0fA+L+9QLFb6pCQJVTTOP67sqNYSVQyu/dPviotpuQtL+8hW++hUENFxjH0ECifrK+wMh8CYpUgouETwkJM8k8Li3MkZcCaYU/OTKq27e/dzfuS0bgTZh7oDbsqhtmLhYKGmmqBq8pOd5RRpnVV4E8wIe3dBxxdziJF6QOM2gkkbxndrsls26rtuyIJkikIBuWyrP51ZuYFdtgkCB/wKhJXZ1rLn/e+GTzu3x1YOgTDJVfa7QgLs+7RjajLcW5iUwUtpbHy1qXOKt6SVAiS0RT0PEC1wP0qC0nQTC1U1r77mXH8jkNCkPcSHrpsiLmgTv+Vj96pFwn5oH03FHnlFsjlVFQaOgXrZuGL3zGx3FwSTxrXSH0r4aoEiwKuAqk/4mSFMxUhsrbljmLo94qsHmRH1oJpPodAJtNccPXPPZ7X94mh0ZsngWjK1ODZEqAK7i7KGCaIMQlmzcAs1BBpEMwBtkA4wGLmDpmqwbkm0ZpmIpBjzd8uyfQL3sWbxYkcHmW6qqywawoqQKeYgVy6KmDlPDVilQkqh096y45faOugVA9P2kEkxTxlsz5K0fAptGauMudLzJooaUrzYO/+ltiPkb4v5mXBRiwFtUJElRq7d65VfuyA8NKKqAU48X1KwAqeYY9/yOyDNH4ilWoTkeKJbSsb1bH36ku6qxh7hHApUZ92yw4L2uEMA65K5N+Bq7PY0pMivqq+0hoQHfLBDRIMPDpCIaOn7VJVdv+9sr/MCgLeQNhFvjJBHeuiUqhd01EaWxpIJPl1VbUCiLa/eWopm6xavO9psiUpGXbUHVLHbv9sFb7wBnEG08btfbiy3Lwg8AHKSJwPgwMMA2Ku7QClmL36uaE5YFJEbH9mVffiVzzQ1tlc1A4pDP4+5gwl2P2d4zCzQlJPk+VxBGAiZoD6mMuUBizu5zzVlZ0pLxgOQvebu8duCOO8V1I3kq7tdlSdS0vHKIuzwizxwprx7pkTVM3Iwbn9z+37+NzD21hxT1e2FW1qYCcyOeppi7bgVTPwqe013fU9QUJ/UJT3CQhIZd9YB4q68mdvr5Gx/9MR1dhYRAKahPUZdF1dmQAqw1E3C1uYMXPIcUCeirGL3OKpBu6qKcNwWa3x8551N8ulMcSvbOPaeb1PV+6gt0LC/v2TBww83SphWGJIHQUFFYK7KuQRJWbJkFxlJVVtXzhsEC9LZOd2zf9dRvFp95YVtJ6C2mbAlTHg80jARanMCHORqKedDBgakecjWnSGMaJKZ/FriQfn91K/G8WRna+Ogj+sQegVo4BdUjRvAH0JGHfXBUt2xt7yuLe06/uI2U4R4QLhzOHmaaw/7GsK+5z9UCigV0AhDOMFhwpmbIVR4m3nd8geHLrxGXLjOUnIzLZhTpm8eVblApnGXkNENQbQ3IG2DStUMeNmgHS4UnsqlaOjfyzQeWk9p2X+0yT0nytA+vfPz+Nm/DztffidTPBf7d/PzLkg5ow6AJCmRbQ4c0bKkmfMuWcjKX42Uta9JxkwL3UFDdq0azN96aWXhmq7cy7KrA5QdXNUiAfk/9YEk9sA2EUS+pAckQCdRHmUbwHFF/1WCgOkZ8vSefM/7qYsrKCifIEneksoPDxPvMYYEnOK/hh0Ermaog4ozXFJ2DALWF/a+92HvOh7uYADKdt67P3TRImsOkptNdCW6zz12Hb5RU9pMgDMCQB7VzZ9OJo999WFy3xqQqZ4p5vfA+wO0Jhe20qQudr4JxqmnK9EswDV1ziluoYoJj2LY2XF6/3NOw6pavSZO7t/zyqeWkuhs036WfZPtWcJAsZA0+hW5QyMwagA95wnJ2YTQVppeAJTuQCjnwOsDOmg0iVJ3sHdz4le93NJwMCTZCivsXntrtq+gluDKx0l8Hij7packwIH5qwr5gyh9cE2jpIf5XfEUjZ1+8N7WGVwF2Vs2zkKw0XteQIwVOzqu4f6Udnt9nxjskMSmfh+CbkHngUF3CihRqa2x3e+pTnwkXhfrcFWFPZRj0ePHsblIz4mkEHsQtIfcsMOJ9RfWD/pp2kMmkNHrK2Vuf+KmyYbUJhAsiW3HqkN4zxgexdqoMREC8cB2CO+5LQ/o08vA+d//6rx0Voe7QfH5sF6+bE6tXD172qVZS3uYLrvnNU5APQMcAvqqliJpggowxLZBfVFbgbyPXY07WEH2JB//JSTKv6ICNrarG+vX7n3k6ddbFS+tOyD/00OZPXtlTVAVyE+TZINMEWSrjaex3NaRIKEogu4bSxU2t3qIYE+j7r9v4tStAR8I4s7K8T+LfDXOIEUGR5KPh/r6HYbIsC3JhLA/JAt8wiDx5ZEX6uusWF1WnSdGqovowUw3ckiid08UA4jUDTHCFtwVyaS9pAjUGarezqLz9/Cu2Pf0nI7sHRCe8pg1yDhwv/74FCUehItaHjfTCZWG1jZDftib6sY8DEY9ccu2aW77c5avY+MiPYrWzw6dfsLezIxKc107KDwxlzIk9OY2jMJY6J6l5qmMqBmaHkYOXUnUFFQgmFVw6BzHKCiqwPUgdGByZ3ZVf3rb9uRfHXn/5nRMXxUhJxl0DiSrsqksGGhMe3G5cTVDUD7tqk67mDo8/TZhooGjrg/cZ2SwQhMxz+0H9Crg6awBdyIoosUfUM4fizkngjDTLhhcCNDTw5Ad2Ddx5/xv+onaPf6CocgQYhmlMulocVx3qIBV9nlAfUx0nVRD7Q6RyOSkavuCine8sNybHJGpNKBKoT13QBUGCYDzUFhx8KEe6RFvYG4m2gc/ylmz5xW+AQHZ1x1pJ8XISWHnXfVSVNj35VKyqvnfu2Zue/B1kb2XygIVhjQt2soVVU1Q2wEyByHGSraOb5EKZBvyfzurauMxPmjxHeWqaYA72d3aHz76k3RXoh0TlbgBGzbghk1WBw4p7m6KBOXFX2QBp6POH2lwlrYT0LTiZe+lN4BaeywKhafAxwVPrFlg3TuYPr2emZ9eDOp2TOV2BGLEFzbBMMDX7/vzcm40ndBEmU1KR8JXCRAO9lSLNMN0GXaF40eyVpY0R4uvxlXSTQIerfPDyq7S334RJAsIcuA+GHwu2NAVY1QDem+aBp6VP5ciXAaQ3eMmV4DNXfed7O577S7pqzjIX2MiaoQe+O3zZte2kctU3v7vr2Rci1XPamKKx1k5RV2UQjLoBOdk0NKwaUcFN4XxSNIfNFCzvwfUsQQU7ltOEnJSDt4dKH5TWgf3jb72WufBiyFt9pAxMEzgsIBwAvd1T1+c7LubygHaILzwzfcMtbWef8ypxx66+Vl+/mhMngFuAUyHkdVPDwj9FO+J65CECCGYHzkFRgHlPQe2l07FzLl3ClA55KkbdFSlS3O2t7vThvn7K0xD1Vg+4G0eY6u6yiuGPX7Rs0anLP3LR+OuvUSqBdIHI0jnRFPCDsrhdzOlsbvqiG+ANtIue3uHfw+KuqwYkJ2WSDx93BngWddto5LTLxIk98TMuaifurqraXc//YcM3H3zF3xA7fdESVxUbjfOKABEjC+P5wUHIppBUwE6ByClQDf5FGAAZt+R5TtbyOZxVWLQJMBkKJAdqyDSvLn6j9+LL3nGVtBFf0hvKMPUpEMdukMU1keJAmClOf/RSmh4Q44noBZc/y5SsvfMBKkzkJQFyBrwSJBjAXeNn4D6zAq2ACAw7rn+BmaWWPT6x+d7HlpJqCGdQ4kOkOuWtDhfXd3iRZzL+5m5vVZpUxEig78ILjba39y9fMrG8k+byE9TkTVwilTgAQYQpDk94noUPpb77KGA9Bff059MvyeCoKbDW5IF0EtT6stoWumMrGNXccKbvpMv2vb08etzp7RUVO//7D1u+/0uI0MmNqyUrN7HkrfCFH0+de43pZBdN57VC3tadkdakQshDdKHtlCRIjJwuQcpVDBuw06gMrm7Ha6+GP3rZUlI64KoYRWNY3etvRsvir1pNylZUzt7548ctMa/sW7f0sqsisy9QOsO8MMHilNKlwq4IKx4T7lhDqsDk4yVDEag22ZvpWPixKKkcAQ1OZkXctcsC1a2+IPDMKHNcP6mDQOj2epa6izJfvo3yeXSzMk7VnKqbCvJpVpPGUdepVNBBRfPW+1hlJu4zoQd5JQk2xC/Yn62/+GM7U5n57A0Ytwd2r/zOXUtIdcfxZ0rbNoBQHL7m8z3HzWWHRka+cHdXUe1SwvRWLZAV3hAN1eCdV9NQ7cBEhkkAWkZyKvMgB0BKlHTbMrQ8C0wE2stQIPRtg81t+90zPfNOTbmKR5nyIaamx924zFUKVjztqmx1ef9WFtj+3V9SnbVHRjYtunbFV+4V9m4B9FhJtVSw1RKWI87Mq9P9amEA4E3x3CTEAq69Ksrm7zwSBjnoCsSK61aQJlCyPZ7qdm8wwqCLGyD14OvCJPDa2efuT8aBlfIWhbcLklHQ4E8qACZqKVPlVA4krl2IcRPmNoXgMk1eUfJUxU+Y37S2/4bPrbvnm4ACzDUNfakEzy3gY0ME+wrjYWg4cslzP/EO8e9565XUGR99h/F1ukLtxB89/pT+cz/VE2xexpSFXWVtTHX7iR9e/+Rvtb17wOvBtDtkLA9Zm0K3qU7T044IZE0zS2V7Yu/Wn/935+yTw8Q9HKgbYmaFPaV9TCXYq65AsIuUtFU3bfret7SXn92+8COD88488PZLrA5CiSqyDfod2Obw62Iz9XtW5sBcYOBmBocv/0yUlKdIKbi1NMHt/MGihrivLupsGff66pZ7KsBrrP3OfTQ/blo0L5t5RctzrJO+8CGoYh6HQKKmZeCCFwRqDmumDSkvg85zFq14adXjjy0hFSAH+dWjWMIoCJZNQU8JRk61NFYWBfRygm5TIR7pCjR1LTh7oqNn27K31AObd/3t5dR1N0WCzUv81YPXfGH0sZ9OJKMG2FILDAy+DRmZ5vC4T+0by+o0KAriW9YmYaaYsrZ+7eg931nsKYuRMpjoQ0xopasu7Q6BU+nz1YFTiZe09NUu7Cir6SRla7/6tQPrhkBQaVjmrbKichjcDx12531kTS1vQwRObnr40WXVjXGgNqYOsO5laqOu2n5Sk/DU9pfNgr8arZ/TO//EHlfd+l/8jKpAoFZe1OHt4hKdo5RNVTEkydJUw2EPGAMeHI0NZtKyRPz82c0bRcrJeJ5AzXzsulZSNfTV22U5h+c3cCsDHKpsKmg4BZulhgq6GCJpzc13gI7c8/xfIT6AM0TF3N/xDsq+i65XNdBNKm7JUArzTZc0UDXO6pg8E/eCwZlCIENCU7hjStQMDhQwSH8QF6uHMlddD28PQOj0Y2FaryuUIcEhb33MWxsn1WBolheXxYk/MWv+ht8/pch74FOAu7ZF6/DrBNMZpnBAIA/vFt736IrURZe8TkjcXb3K2f2C6O724MZ8b0XLQP3xiZK6vuNPHP3Qh7ubz1z33LNgEMBgcfAxVYMKisMziD6aVAuXViDogGfgn2Aa2vDBTJ0d295ZvzDVtHDDI08Y+3ZLe9fGaha2Ef/u6DI826Gh+1AVE7CzDXivHLwU0I5g68royJLiUHzOyZQVbErHhjLttfPDtXP19Zt10xB12eAFSxDhrysWbgxSxFydBvp7H3yq+AtAh2uKZzDlggAWZSpR0Cc21YW33u499cM9JAQgJN21IOrTzo55T1EDXMD4MW9l0lv8NiHJq68a2zgEf10EaQqK9v0Lk+/DfWq64VtRDZih2b88l5o7v8ddhBVuWCBXmyJVEX/DYOMpq0/9cKpuTpgU99fNG553+orP3cmvXAHkDh5E1ExkYV6A0LZMFQQM8jJcuDSuYeGJoYAjk0xRF+Xcju3r77x3SfnsTlftUk9Z+rav7nvzdTD98bMvUUXJoDbYP1AjOD8U3lZNoB0DTIEKOkuOnXZBJ6nck4ofiESX182NksDu5/6M799EQ6obMghHxZSQXk0JEgz81jTQpZm11O/DHZCBlCuyQJjgZYWcqFAbiHTXj37aXTkn4+wXAr/HA8C0DXFXQ9SDFVejTEWPK9Dqr4yeev62P/5dwHJRM68eWqtNZu5vFB7UtsYSsfQVV0d95SPFWFXS46uPeYIrXFVdTFXXrJPXnHfp6tknDfhCqUBjcvbpEy+8YUNoUJud4CFAcPnbqWOGi9omkgxEH4o4MKuAvmLs27npj3+mugEkrm5eL+/avOV7TyyvmLPq1jtAb6SuuxWs6Y6/Pg8sAQlDlkB6ymB1QSOpOH0EHhmI3/LDX7QFylJ3f23HKy/3nX/N6L0Pg9cHrUIBbcNhGFmhCg65YIISBeTfW5AomNVDPnUB9+n+ESZlVhZwDUcUOBO4yzBWDPVd9dm4qyrhBR9b1euqiqB1x/KpBO7X+3oWnCw9/uTeX/525V0PrVjVB+Sqs+rR9j2mQh4+Oc1N9N919+u+sm5SNOip6y9ujgZqwR8lSeAdpvz1E07NnHPxQO3clD+4zFMzcPWNdMdezTLHBEnOY1EDMLhsgFsGJaUB1cAFNoQDTKhBOWHV3xe3kZL2kiZVHl/3w5+3heblejpxc25sTJzcqQKRrNnQ7a/ubVkAPpnXTTz0hBJeAbbBmFAkm8JEUnb2RJeTwOAV19ncGPCiLamSaDq7TxIMD3CyAhnEwhVhmGo2KCNnMhcWPp3V0PctE8HXqXh/zz/yuEQIbpZX0GODEzNkYc8Lfw+X10dJ0QioAFdl1IM7ximCBZcp4olfdx3ld2mTGzd99mtbf/uMKXL7qXV4v/q+ShhNsyyLHxhoPeWcJYQZKGmMkdq4vxEL/l1VnS5f/4ln7HngwbHb7mz3Vr1BPMuaTlBeeRmskGQYkxOcrQF7y1klDw4AdbciQ3rUDNx01tBDCOBgtP37u2saQHSPjY5ueuhHnd7K/mu/CGjyNuh9mBYyZ+j9X/wqTKwdL7xoAZhg7g0djz1BpsUtPM1ZV1eEjVu2P/yjTc+9CkIeKIVqnGqLMN6OOYBMIBqKCGIGMoql6TAPnH1nYdp16GMm7rxigKtSkXqzNi8bBlA9zY2sGLruUzGmMslUhH3VTp0hUE1V2lMGKPWedMHuP/1x5+//X/u8szbd9X1jbP/Mv0UkQdZyclYVs/lxiis5IDGAFnTxwe+/UlwOqXm9uxoEU4xg/X/UHYoRsulrXwe2Gx8Z7jr7wjbiSV/7aTqRFahCJzk6xoEKymqKzPIQZRCksgnog1HVbBCBVMNDH0DNqrzlkZ+0uiu2/fGPwL/pCz/e7qvc/fTzqPpNQ9i5VTZzwvYDbWCAzz0HPAHuy0GsmTCH8IJpBJQlUqARacptzbC4miMRpvM4TEbu6NueAPqM+i112hEyZHxcWTfkHS88mwyemiDliUAIa/ZdczKuhgzxx0nFcNnxCTDPDSfES+d3Lzo/37XcdPYz4AFA4G69rINflXVBlwyNF/MwE+Gbhmlru/eu/Pgn3vCUZNxl69y4S5dyN/Uy9UmmOuIt7jv/4q1P/37viy/ln/qV9szv97ct4WSex4oxO2uLBzTO5BQKygkABvEm4jIIZ4ro9cEVGiakVmDq8Z0bukhxZPYZoGeUbevDwYW9pS2TW9fBhNj1+JOZ6z4vs2z/BZ94izBdNfOXFVeMXP/ZXc/+gd04CkLG1ix4KdYQnJOt8nTfO/Uc7RrypzjF46LIF9ZjC0FduP4p7oXXeZeKVYeE0Qew/fEVV36h21MPPAOI97tmp72NYC37UGQ3gOrr8lX3kmB3acuuHz2hbdohSFP73YooKQTPkeICCs/JLMSIpFvU0A+0di2tDi1n/AOeKgj2PtLQ58UTAX0kOMAEe72hjvo5b889aeTrd6lrVysCjyhIwILqhKFnqW2AkFQMQwdbxGOZgC7LJos8K+mgDIEfBRvXQ5IfuuAd4k1e9RmT53YtWb7M7Ytd+gnImeu+9e2lrjLe5jc+9EhnccO6L34jccGFi4tKl7lCI9960BBzIMYpMoekG0JBnExfY3g3xtWpLa13o5WfjvhM6A87EvJBK4Vpr1CUimYQbLY0sfXpP3fMPiNMKvpddQOuWUl/S5evwtnZrx0tn7Vu1oJVdXPBZK365PV8V+K9LVYFl2YJWClQZsBfmgHBjnu+lMttfuLJZcQd8ZZgeYm7IebUkEQJbu+OkvpRUjPsrmglTPr6z8vb9+JqjKiPW4ZmU2BiIYe7zwCLoQqSyqk8EK6IR6RtS0WHIxWWxSEfrPrWvT3+0HJSvOs3f9RlYegzt3SSwMbvPZ6+8ur4CYskKm969PFuUi12D4AUFZct6bzsprHX3qG0sNyEJA6J9H1rlk68OzJYcIp1pek8fgjQM6Gfifv0n8FVBEVzDnHLoI9BIEysW5269hagXwxH0tjra+oM1CZcNd3e0GBV8/oFp61YcCoursw+YexPf8cD4ZoCghKX3hQJcYeQhxSFC/Zg6A1L37wh/cnruxlPoqgq4qrq9TR245YuZFcnezAhzCf+si5/2Zb7HoRQzSp4FgICG3Q6ZEUAFP2RCUSt5AZHd/zmGcUSIOvxXJ5akGDRmoHxgSS56rEfvUOKe8vqe6uPm8ikjQO5yHGntPlD4bpZKy+7CbAevvX2xcSV6+k1nEIaoEHFGUuUFqhATZidM5Zc5He1yj/B/UgjcVjQ3/tJWRVx91oEYwETbutPfpNsOKWXlGeYUNSFdc6g/TrdlRFS0Vc8J1mzIEr87UVl2x94RM2zWGUjS3lJgJEjABIkekHO59lx4GgIXi7Ss7RmVoTxJwMhUEhgCnqYajBmKW9jr7s5EahL+rCEYVltS/aFv0D0Abkj54LSBZbCJWfJBoeuiHtefakzeFxr6WxhzQrc4sRlAB68DPK9pkq2tfn7P10eaF77/e8vKa6OnXmRJdt7I+3LPVVgOka/+ZBqsLHZZ7T7q8X92zmDV5xZAi+CkW7rWP8lgJw0puA+Mu4Hp/dhOf1IuL8X5qIyHffCXAPodbRvlF0eHvrQ5RFShsdI3DUJdyPY16gPM22GzE54Z8dJ0VKvf+0tXzf2TVAN3q0GuEPIE2AqwAP3FSUWXk01rbEXXw77K4GYcDXGUw9uuN9dPeQODviao65ZMaZqhTfYQYoHL73WHhkBiaKJHDgmCGGs0gJ3Rk1+bMe6ex9u9dS2M2WdnmD4yhvo5AGwO4AIWBgQgPCuQVaqa9Zseu4vu0dXbL77viip2PDoz6nC91//haWkdNsPnhqPt7WR2sTpl4BGRLuig+HCJWWMfayNAVGhUKwVei/Spxmi/xnc8dckFV9vWm5QcPNIAR8LuOvrN6/93JfxjLKrLOmt6WPqI0wd7gh66tPM7BipjxPvOx7P8OU3Hti4heI7NsY1MWsqBOQo2HHW5lSFNxULBN/O3/wWdGjaHUq46xMMktdqT2glqRxwN8aYOcDIA94K4If133yQZrNjKspkSRc0k8P0bGvj7W2JE87sICWDn75FGN+dvuSidlK98Te/Bd0tQwYwTFbngOIVUwasDMMAO6/t2xGbs7DVV7OrOzLR1dpz7nn7X3un/2PXLCFlW37zSwhtiHQqayzYIANcP4+pWsP1YchuU4v100GfnkILoBeG4UgUf3Tc4fUEnn0v5CG2REVUWMhYgMCOu78b91R2E2+vN5gEKiaz+gmupgA3ZDyNI96SNpc3edLlWxL9lMOaZXg1kOoEhDXLTYLH2c+LugYjKG7/yRPhIiDxIKQIPFvE1MCVdOPmVsxdF61siblKXy+pHP/ds6ArBNUA64g1iJoiTO5b/c27WsHCVZ6w6a+/pzqVQOZMjLeTqtaS0ly6C2QlHh2WcKMZNKyqCYotU9mWDXtsKL3U3xidc7w6tk/UsPZib3d46y9/p47v1zRDMo6+9XqI5VaOpBSPXc9M/SuemVfBMbz3mhCizlkDAaQaZNexXz+dKG7udmGJa9pTEXXV9pKaDKRZkCHFDQlSubS4Yc3Xvq6MbYMZzwow2W0Q8URTLR4bvwgTEsBC7ey+VXfd3Y3rAXgoC89lMSGsB3fVJBzoB5jQO8SdXnSeuWoNoAO0C/kZ1CGVjQPpZEf93A5XRbazW7TlvMBzK4Z7zji73RtcSgLhMy6nyM8WjxUWqmojUwPd6yKOgCbmtj/2RCspH7z5NkPLZimYCp4qMnhgTYT4Vo+E+Lv08t4S01GQnfmvR+ecKSUzHXeLx4VoQeWB/WRqTb7y2uCc07vwOGAVQA+sADpyEM+B4uHNLlKenHWK9ujjdHy7QfVdsnJAVnKmSUB98RqvaiKv6BTYenRF7LIrulxYqQOggxoFjwoXylJ3LUycbnfJa4TsueMbksUDTcv9ychZl493deFRfkp3PPv8UlLVd+n1Cj+57dnfdZOSttq5k6++ufrLdy5zl4/e+wDMAMsClqBOflKwQl2TsGCIWvLerdEF5/e4G/dGOqkAIa476yMWpA0FHP4RI106ZGXx6EF9dLP6T/WMjptgWAvCYX24JVHK9/etveK6MHhAT1WcwXPJYTzdidANeOui3mC8pGXjhy/b8ZMn9W1bC9WJuqQRUO+C5Swcmha19PziN5fNPbGTFA8gSSHcEefcV9Q5kwj6PUHKooEaUJD5nduoIq3/+597SV300ss0XaR8fv2vnx66/Y4oKUrMP3s5qUp87GPinvWyRYV928LNs9o81WxXhyzkYMYBB8EAQI7FLigaHusWqTz22uIdzzyfU7NY06uJpoYFghLQuioeCfeZVZ//Du6HHYn3mN2p2tQdr8+bAnCsZFNt/+6d990fISVhT3nSOT0LnDxA6vGYHINavpNULHVXh0+7iOuJgugAs6rneCLlOfhgTrKyqc7v/cnPlpQGe0hgCveYF4RRLZ56Jlg90kaKh447e+yPz6+JxIA0VI3rvf2Oblf1+sd+mjj9vLc9ZdtffSW24MzlpGTVvfcDcQOCgpjf/OvftwbqepjK8Pyz5dxO3ESWNd2QeKzuwDIyNCQ6SBQN9JFEbSQfbCMhwnTGkzWKeFh6getIYfsvQH/Yn8EleOFgczTdeUCI2hJ4ZYGDcNUpEPbYn/4Y99V0M6VJ4rACUwvoRfwNuDvkCoFC6fFU9809S2hvFymuzYHdA9zzwLO47wyflt23+dbb21xY5QsyBtIp0DoetfLWOicQcTDBTw2fdaGcioyvXYMjb5l094a2eScucxW9Q8q3fOchYV92b0+k1R2MtpyiHpgQN6xNX3oFDEz4oqs33PXt5a7K1ZffyIOXpZDVWdnkKQ4AxSpfTVVUrPvgFfhHE1gIDJ4FwQBWWtNxs06XpuvFQzokHdYNHTv0R/qBKdxxpRZ8vYa1+eDP4T2wnIBq1jCyXe2ZhpO6QXkz1XF/fYoEIan2FjWmfS3D7qY+4AyI48bT+MVvQ1hBdjAFmYB9BZEE0ccDEHvWr7rsmggpTrnLYZTSDrcUEmyhHwAk2CjDxM47j25ZbWbH0SuvGklddgO4+VaXN3LiR1ReFDZvNrXxtT96OAIu7obrwqF5oHC2PfwDcFW2rvUt+gik/t1/eQE715myI3Ac+HSYglYhzEFlQoAjk5owjS0EGbK3g/thdy2OgvvRV8GOBfeDulTGFR6YlGA18xKkNtVUjDzH4mI/uMG1oyOLPtbNlEfc5RDpw6Qm6gEpiCfoBj1N4aJgO/Gm5pyWf2sx+JCchkNI4GML2Tx47hzVsptXjJx7cZQUgx5KOrg7J/7x0P9UP4AlpCjz+Vvo7l0qbuhI63/yVCupXXXz54c/ek2rp3T4nvvDx52QWnTB7mefj552Yau7Kn76BfsGk4YJbAI8oo7c8uXl3tL28vlc/yhqSkVjLUE3QZ7jyXPDVLD2GOvoROAiMNYwi3FGGIfH/bAnWo6C+9FXIo+EO1yFTlEKlhdIBdwtlbK8U5Oi6MKe7Ws+9uked2XEW4ZHpUh1my/onPBqGiINHUVgZYs7mhaMvfgipXhsCN42wSVcnsUNQGoKA5nkGReEmeIMpAim2mkMUJ9w1TkXxHsQBqON8a2//iZrfDeuvygK5bgtPXF4f1ufe6mTKUuUByc6u9pCs2NnXziZynSGmjor54sTe2zVzG4c6Tv7orf9oehpZ4XdVdFFV+rqJG7zqxZLsYRRAOmoq/9Uof/TA6JHWYf5F3A/bNMXQRBwvZNjgTBNU9f2TGz4r1s7mZKoFyAODpLaNKkLe+ti7oYUaRrw1/cRf6Rk1taf/dxW8jrMYUEhWD8n4AFAjVpSfyZx+vnTcS8038HDPqjiq+Fa5vauvfkrGjtm4sKgDMraPDBuUXNyJLnYVxMrm9Nz3CJl8yZ+3S4Izw2//k2r15+8/qaN/++pnuqmrsqWTS+8CNZs5V335friOsVdfA2iXZPhtQxLL5TtHTaFHnsjqaPA+j+FO0IvYoMIVseiXXNC2PCVOzu95TGmspdUgXhPMdh0At2+qyVBgkPusi4S2vDQI3p2Px5o4WUiQJ7A6lXsziP0pZOnfbiAO64TuGqcXkcNcabWsU6QLqrai32bvvOAZqg2HsFDu081Rw5q4mJf3chV179ZVTF0xZdAdFsaSyWx/+JPtJPqDldV9OJP6uvWyaB5DcMENUUxuarOUd9CyRzoGVUzZoJeUOjH/jgWm3qMYuYouGOvS5bNwTs2bZCVm++7v7M8FCdYv5UkNU6votoEqUt7ZsVJ9RAp6XaFNnzvYXN8Hy6NsCLBEyAiFnjotsUnk4lTzwMR2ecuw7Y4TKjQZqrX8VB9nhqYBG1+1+r7H1ZMCiLSVATewFNhgAsI28ypF2y+7a7YNTd0e3x73nwDKz4hfW/Y2FE7bykp5TauBVuN9WIqh91qRB4EjOSUdUAuBUIH0TId9+lUfpQs+q+R+7GjfKQHK2ksy2clPKABemzLoz/ormkAc5Nx10RJEBii34OVwzHSCDBmSPESpnzl/d9Vx3aZeKpWPoh7oQUsH4/HTzqngLsT3cEC7mB8sQOMtxZw7/R6Ru59UDFsGxIgD0IQlzDx5BzPZy6/vK3heHVCjJUv6A02c1s2WzrkS2njr5/sdDcM3fotCBHcsjZlpwTGFGwdSwFl3G61IFVgVtVnIj5z7/+QIoBjFJFTZRr/I7jnweezAkS9gqcy6dYnHgvXNiZJGajGhLsej7mSYJ+7qQNCtqh5ZWnt2+6K1Q9+z548gGvkkk4EB3eQpaZpctFY4sQPAe5pV6nT+wXjPeNphOyK/XewfVFlorRyx2NPgMGBeNcELGODBGtrAB5d/eiP47VzRWUy25le6ia9i87HVQFT1YWxsede4dVxkSqGgSIRBCXMMBYLyBTn/B4WB8C8wUK9dxH/pxF6WLo/UnRPL4+Z9oJHqy2YrmemX/Du4AKGUfN4PEDDXl50x+OP9ASBWErS2D7L6Y9GQpBXu0j9xllnbJp7UntRzZaHfkAnDwBQOcyrKuQIDnHXDTYciS88ewp3p4HXwU5TiDsDzFUVCVTufOQRU80CTWNxDFK7jGWbwNGyJcl7lvlbTI0d/NTn3imp3vDtb+GJARVrt0z0DDqWOeoC1i9CQjY0GDAQVKKF8HPgk9TDoHMk6I8R90OqVN4/GOK0KXWkBsfiTNwhNrIQcXlB4zUFD/fTHQ88ECmpiDFFKU9dhAT7nQ2QTldtvHTerpMvXLngxK7Kpm2PPmYe2J/T9QMF3ME3Ae5Ar/nunt4TzgLfBLinPNh7CuZLocEdtvRigjCJWj3lI3d8VRf3cNTKKTaWqEDS0wWqK7oswKQBfYVrABO5SEXzwIXXQcLEJhqmllcmbezuoOuGRZ3zY1joYsjAOvCnIXIMRVZF7iigHzbkj75OcLguDeJM0I+CO8g9UB7TL/A92GdXV+0cp3PYhRiiavu37unxFUddRdhCkdT0uxpioOK9df3Bk9bPPSvc0Lhi0bnsM3+iishTmjVsAp5Vs+ysgc0vpOHBxCc+EWZKhz214ariCCkbdM+JuZqwZZG7Ekgm7G/s8Pgzn7pG3LmaBdwnRCOP3bwL5Y/gOZElZOdQjyRwB8bAlB7pfN70OuSjQPaBvP70nz+kT8Ahp1lmnustAAqx7GhzrCLICzykH0XmsawTRkbgJnNjQMuCaghYskbFiUlsmEmpmJ/ceOudvb6KHrcPaLnXWWKBqAUNM1g5D8xmm6u8Z84ZG377a3Xl6AFTAMtKYLLA3M/JznzZuKb/05/u9GCflh7i6wk1dNTPAeuV9Nb0eoNhX7DLW9tFvIMXfVxbOQA+K89jXZLidGBAijAcQCFrmLhNoXCcoR9l3Vw9pPvcPxXXHygfHmJlj9Szawp6odCe9t1zByjGeOdokoEHEDmOoxR7UOS53Hiel3QqgJ/O5vAgB+RJPr/py98Asxp1+fAUPTpVTI2drlCmZDYMQDtT/jd3deZ7D5kbNkG8s4JKKAtKGvuwi/DCe3aM3nrbck95G1O8/ewLhfu/ufErn402znJO6tcmA439rrow8Q0tOp/GeqltsqrB6xaWI+gIdwF3vKmAib1fQCYe4j+nFhGnVrWmdw05urj+N3E/bD6YPgMgyeNhsEJfZgh0QVQ4QefESU7JK9q4KORVQcIzQ7h+mucVFg8n84C7bIPh5DfedkfYUxonRT2+5s6qOR3lTVFffdzbkETjGcqUNnYGWwbvuptu3wrxbSrAM7Ju87LAIe+Ayll35z2t3spuX8X6z31ee/KHO+64qaehEfu0uBp7fQ1RUhlxF8fnnKq8uYQahqBifxjM7yjiEXfHAeEiF4yErWsHjyu+h7U0jVLf173+6Obl2HE/loGZ2fQRT6RoinNyHtKohGXycEm4F8bpNKuonCnj4U+BxTo9yYALvm9IErZ9soBo2HVf+kqHuyhJivpqTs7dec/e27+WrluAK+egR/wgBauWujxdn7xMXNOPlRecSiRNV/DGGXwO4p1nt9z//e6S+kxZbbT5jN6a+R2eylY82VTbzzRlmHog+rirbGlZi1PmyiuqCRgjJ0p4Tg5XDXElq9BaEc94gxk+Sk+KQ0rvj3LLgGMH/Z/+2Mzm1gdL/gXR4Uj8Di6ya7i0CswDNMLmJ6jKaXu3ZTdvNljR2Yk3BcMG0s/rkB0pHd8/+pmbOl3+NCkKF8/Zfevt2790ayI0L+34HmwVTcrbCJP61JXG9tU21SngzuoGDwZAFSepbavqnp/9d7Rmbn9pMBNYGPXNHznzE+s/f1v/xz+ZaT4JDFga61L9iwMNwz/7hZKfBIBZDtfqwLVCyIMihK+G01oRPoheuFPD4Zo4T4+1Q6rv/2VAjzH9FvopT+9Xd/B8EydYmq7j58ANSNG5wE7vWDu65rWXcy/9beOvfrXpH28BN0OkTogcbteJYt6UcNNm/br+Sy7vYnz9pLinqKm75rhwdUuqtHm0akHaW49niyF8mdI1X/8GndiDHYh4iwiK7uh3eczEHSfur6/G5p0SdgcGL702+/TzdMd2ZWRg7cPfHTr/gkSwpcMd6iT+6Pwz1j39NOAOvD6BvyxhpwVRYkVsgKC8u0tQuAnNkajgA92L5IPG+1F+curOOtObBE4V/k8Nv+G0NoKfOfDG6y995MLnKoN/bp4z+MTPqSjyJq6hq4Ki5LNZWzZNm02mYovA93iGGeSGmGN0QIiny1r6i5v7fXVdpOytQGjnU09SrP6gkmgSmVNkLqeown4JphQ1lnclTj9vCWGWXnGFsG7EtK1Vv/1r4oSPrCxtHPCFEq661qLyVZ/41N43/qGyWVDrgmngdnveOXSLh7uxAhtiCvdFOX4m7lPusbCaCvw2s6H3v4n7B2rj/R7dQRQ6dXS4z8WhPgSi2bN5W+eV173gLVtKPP+oqBv50RMUcq+NGwloVsfHJijgbo61d3TOPSFCPCvc5QlPqNcbSjJVMVIZ9dUm/PVxprrLVZ445UPCstdNmxNMjVd0MmFxssLrLGeLpg0Wdvf2gZ889tf6xuRpH84+8v19d301NguYvajLW7ycMF0MSZz00c6FH9r6yOP6BFpeoHgWDyuZHyhs4cqJLAhkXA8DScxrIo9WUFUOr0D+/UXE99Zvp/HM9MEWDQhgXDHBHhGignfSyY4NvfX6201Nb7l9bxLP38uCL3300p0dbdSUIcXqEFWTHGtTeL7viZ90Ek878fYVz0l5jkuSpohvVszTkiKhhKe0m/jxYMX3fkZlDo8J5bJUkonoHE/E7jgc9r+Bf7C2rsz9+udbr7lm5KSzujyVSxgmyrjbXYFEzeyVH/pwquHEdyobV33hy+aatbj5qdmirh7LOu1M85njOWf/zMnJzg7Ssewf/TvK8pC8Mn2AUYkDt8Pwg/l2jv3ZIj+xft2OX/3krQWn/LWmOfPte7a99Q9+xWp+bHyc6kI+J2FHQaof2Df02S+0E0/MXTzkmeOYpiAe7HNjjWq/H5xQoLuiafUfXqLwJ01VzrKQRQivYK9PwC4LqQUUCjWNHWu3P/KDdYvO6SkPgntqd/veqahLXXHdjptuG5p7aqyk8h/EFb/go3IkikWslpVXpZzKflDQ4cJurzInySzoMlU72JLkkPvzHMv+0QcK+UPs0tQw5ESHFSEnFe6NJokOSho9sLP/Rz8Nf/v+/Eg/NlcXsanifsvIsfnCZpEw2N8695R2lz/jqR4hLUlXWZopiXkrYQAyruCAB3sdJ+aftTs+THULC1PysqiZxILJzuUmTHESOy/iGs+BtvbF88+FF2p3lbR5KyIXf2zdz36874Entp98eT+pSjPFXcSXmnc6/+Jr2KfDpnyWY3HT8QPj7pTXAqFykF0Kil5636GWw/ipf3kZfXryPGw73iyP3UqwPQdEoSwA12cVjTMhDDV2/abxlaM6m8OzOwaVLTScvCBlQSVbws5n/7QsEOpxBbD9Dmlymp9XJL1Y9pLAOwmUR73B/ouv4CayWCiD7eR1CFYCydWQBcB9XFURd5vuTyWXXXbD6y6m//iz9//w53LX0t2PP5qe/6GIpwlVPKnIMKHeqvnbHvkpns6mVBrnsSL1mGXGIcChVRbUwollFP5Hxv1fDvN/eh8aRxTg8RdnfQmr51QULcY+MCgGtQUN2FzUpCzHcyx4FFwAx18zFIPbP/jFL7dDOiUl2NjbBZZ+dp+7KQUX05D2N6RJRYerYsWXvqhQ7JGhcNivIWuZJMvnQAGymojNMkSsXBfHdm/8w9MD//VZ+Y1X8q+9svJTn4vXzoUUEYEBdLWkmZqMp7HNXZ+86jP5lYNANWD1DqsXj7EEjs0rsuBUZ+OH5o/CMx8U9JmEXrgx42Hv7AZwoFnVnCodVXZq9c1xFWt7QCezEoen5fFoEjYrhFwKoQbkoA+kO084o8NdnCKlINU7wJqS4xLe2b1MY4zUg4RPkLKlrorNTzyiQoArOUHMgy3IasDvIod6QuItEeSgImd5ftXqtT/9ZeazN6246KoVs89a5W9Muaozrqbe4jmtvuAIqe131eFtIern7vzVr0DFm+iYtQ+0WXMIiIUTMrgUddS8+i9k0UMWA6bfI/CQwLc0FVw3K2NcA82rPI+HKCESWDUvKhOgLQVeF/AoOoh3jcvzJt6lZ9fjv2wvquvxlqVxO7uuoyjYy9R2e0Nxf33S3xQpb4iQsvaK5uxbL0IO46VcXhWcczYKgSATZW5CBoqXIf5hrPXRtaseeDwaqOkndXGC/arDvmqnv1NDxB1awdSkfDVJfzkY16Gbv7B7yxrsNKOY0gd8HEr0iuTkNPkoOvJfUI1TuE+1GZrpkAsNn6iOZ68mJTYPb4IXtDxrKqKuiVpez7NizjncRCUrL8gHhDzFejc1v2976uLPhklForQq460ZJqFwUbDHVbKc8Q7XtKxtWthdWd9DypKzF5mpiI0nvjnO0lgs3VeJwzCy00jeWdfXFZXN7evNZFpOj3vKsV+lq6rXXxwjZUDrcXcw7WrsInVgxpLEs7y+ae/zr+BOh63haSuYfXi7KRmPq+LdTOWj3HYBtNrMo0N4p6rD9Rs9EuLT795zaP7E5UOZ51ChQlTk9BzYOg1vCaQBh3DwISEv4oIdnhPiTLGwe3fw5qvOqTvsDaRrBjs+QcW8plJWNvJ5VufBypqTCpX3D19/c9hb1+2uSDLVsao5iaoWAL01tKCz7pQVx523+8Rzu8tK3/b6tt74Rbp/i4jV/qqzVYVrtgTmFDalEZwFLAFrE8HKKHv2rb7qRniVHhfelyRCfF2kBG8Y46tJkeaYe3bCVTNAAp3e8rW3f8dYv9mwFXjdwougChYR+vc+w+EevKwcgrtTy//ebtzMe+AdY2gf7OuK5YtgP5HBZNDKCgsvLkyoeUE0FGxOnmfHBQkbVmgqSMjc1Mbpwdng3CPRoXJWwCo2w2DRZQO9YJcQycp1tEWCC7pJACK6xxWMn3hKtOn4kS/frPz3r3fd/s2t531yRXBur6fk7aLKvU/9StPyhbOA7+EOn5XnWc5Z8tekQjcU0RKlid8+naptaXdVdZPqzvK6SGh2wl3d6wZxOjtdNDfprh3xVMeJP7nwQ8Jbb2NyNSxewFO1TgUhLtRowlF54P0HX97dJDoiqxx26XwqCRduojQ9hYIvyXNs4QVFgcP+BBqVBTMHYcFy4M9hPqJ0gfQmcjqfn9o7Pfia795A05AkVC+iMgkvY+uYDrGRgD14420JUpr0l3Uz5cNNJ4/dcvOWj30y++oL1st/2/b1uwZPPAfmQQ8p7jn1XGEgA8ZewIYqzoU3/wO/Kgs40RTccMHKW1l3PoGo9g2suPjyVhKIlDauufXOjZ+9rR/Q9wTw/mCehoTTKh3+cLuvcvODD5n5/ZDdJ8ACiRK2rpAl3OHjeVxH/WcK79h3saUj3H92Ju7YwEHi8/ksx4EAFJzW2ljTzck6HqcT8TiDrloiL3BcXoIgdjrxTv8TB29BpsimZFo57Mt2wMK7KLK5vGXq0sR4pH5BH1PZU1zZ7g2ualq0/eNXrDn9gu133JM6/2PdTfOWl+A/tbor1t/7gM5N6hoV3n0U3j8BZYq7FqpaqPkDSgMLlKWmtu/Azh/8qJspTbfMNYeGpMVtfY2zIMBxs9tp0YkV8d5QFylKXnBJftkyEKd5Q8nK2I4RS8VlbG8qaMo/NTJHAv2w2uaQrvaH3H92+n/ifYxl7ACM26TOvSaB2bB2RZNzpjmBdyEz8qoCxgW7myhOv/h370lTuEmK83qqxoOVF+AnOUMHFwuChJri3hdeTbjLwSIBv7d76iDndRbVx8ua46VN2CSZFHd7fFFvcWdwdn7p2zJVcTdUkqeXgZCp4m7MJdgzRubhzWI3N0WO9KYbT2oL1tt7d9rjE4PnnN9HyhKBWmCbAQ9WRTm13uXh4vott3zN2LJRsxUee2lg70kcS5AnmnaUupTCdIaYOnZ5PvNuAoe9MyGMuMHj0ShJF50beqlOczyRTk7Q3H5KDZbSSQVvAMtTCVAVJgU8d+LclqZwX6CpAYAMkeM5TBSQGSZYiRr6xlV9F16TJEWDJDTgmR1lmvrxdEcwFaiPYQu2yjRTFPN4O0nRqis/R7dt5am6f0YdDsF5J787eXVNB57PcpIjK4x9e9feePfrpU17X3uZ6vzO27+V9DQAbcWLsT47QWoj7noUOSSQaDxu12//oE/uVqipOK0aCve3FY4saAq5BPLKzAKjo8+P6aBPvx/w9GZRgDt4FOzDaGLrffhX3ELaum3Fb5/Z+fTv7HVrcJMaO5DnhZUj+zIDwv4xPDXo3Bqo0IBnCnpntV0AS2+DjFd1PT+x9fEnOgK1fUw5JLw+0pBmmofdDYmiYJiUx10N6dK6MPF2EHfr3IU7/vQXyoqGZguWWagBwW1bp/M6Kdx0HHOgyBc0JUQK+AULzVl23zNvts8+Z+s3vkW5MfaJ37f5mlpJcaoKa1z73c1d7oaMv3HQXb6MIbGrPp0f7Yc5JQnOsQ3njJ3IH/k+ijP0DIa5Ih92V3o6h8zUkdNXd6e2yxVWOcCPY9GOLKh5lpqWOjjy4uXX/aqorOMb39i2YsA2RHtoeOCeh+I/eMKamDBMG3s384U/hesWhTvfjukitngGysRyTyrEM10nnNvqK0mT0PKKYIypSvtmR0hFsrgi6q1OMfNH8URZ8WjzvF2PPaKIExSobb+i5UTdOeKtO7JGw3XgI9xMF/snqzzdvnf09nszp1695Zv39196dW9ZbcpdPsg0pElL1D875Z01QBp6vbXt7tK2stC6b91rb1hrU7zZBWRqXcIdxIL9w0GVOOz1LelUxE6SMBMOreoq9FETkZeBnTXs9qM4Tgq7Z7JSHg8jYBkLD/Hi3OhV1FRxCminYxFoa0vHMhKDVXXw9JOqOikqYl6WqCXu3RG++Y7nXJ4/B0pjl1y2+/Y7uk790Cunnbv1H2/ZlOZtDc0Hy/Jc3mlvZWqTMpgmfeIAYDVu0klq0QM7193+9VanzVI/qelz1zndN0IrfA0r8ExTdRpvpFH0VtOCvc+9zI5P5kHnmdjGYr+tFurOCrVm8CBH0mqWCGQNgLETHa2Z8z+zrKhpuacqyQTS7pIBMLGBOTFv4wAekG0eKJoz7KoFJds1Z+GuJ39h8mM6tUHKwLzJiSzMJ5XH0Ybh5uWD3XO4d+90Pj2FFnAX8H5BSoH9Dp6ykEXsW+XMT5DkoJdkp1gE8rZZuHn3e7t3IPEMDbteY8WrMcmpgjIpylmON6hBd20d+uKdb7rcbYGKN6prnveXvsiUr/3Gt2kuq1kUxknjNcprTs9IvLUIDDlIdo0FrafnLZvaxt4//aW1YcFgSSNmNW9d1FUb99VFnBN3K111I3hYu3qxv6L/tq/QrZthLLOQM1gsSshZ6lRGLTzIEY80YHtRCSSKLU5sefhnbwFnMb5Y8f+v7kqg26jP/H+k0WX5kmzZsmznbJO03EcIYYFSYLnKli6U5WhLobRlS3m0C7SlLC2QNpDtAm3ZbnehvL5SytWSy3F865Z12JadOyHOHRIfkiXNjDQzmtFo9vtGjuI4cWB333ZbvXl5sq3Y0jff//t+3/mzRKrsOwxNcXMLHLFBo3NA7wJDD9582AhIn8QuXD629k/gXCGCzaXT6CeyuFYANVfA2gKLu8YgeuSnAfIZOkBBwHhjMjJuDdE2vHICl4HPjzoOv6kANluC18CpktlZ+S+xdMENSApMEUFt9jCfLoDQ+fT4O2+8vezc31FkPaV720T/gaa7zHW7vvHtzMHdEL5PAv7KwF8VUiwATWwa5AU2iXV73ASArrinx7/82h5SNWhs9OptXSYcCxjQKE3clD2qb4yZmwdcS4du/nyyr01Rs9iFlxPYDCczrCjN5vogc2IGEZOf2Aoo59KRyMDylQO0bZCYNxED/G3sFtZVDZq02oquATDskLEuSky9xOC9/kaI5QoKphzyafSymDXAej2cAba0T4/TJs3PLPccw3IpLeVQ6qPA9CxqfQ4Xn4FMAVtAgAYX2pssd2okNc0RiYovY4PJJPxlVVQPHty6avW7ly7/va6ivaKik9DrTNTGSvMGovt9ZaP76afUfIpVi1xBhuDoeCYNv1lh4LxyYGwZRcmrMjsYDtx8e7vOHjc5Q6TWY6gDTDFINW8lrSB6P+100/WempaRi1cm1rykZscyKpauAFGxsgj3TuaYWU2JZC6ghiMA6VQeggvMijMfrnquz+RCct/zL1m7aOlag71Xbw3orV5S4atuCdI46hCxOADgt+nN8dvvZKJhFRSTzSVFPi3nM3m+hHDAOEhsRmGYueSeUZKMMIWRJJuFgy/mChwPxlpOSDkAqXhYMzx8H05EhsH44NSmu5Nyh/8DHl5bx5jYseaVF12feFlf8S4xbSTWTp2lnVB/IqRDb1pLzG/XLY48/rgscoViHjDfFMQc4DimuFwah8ZlRSzs2h6668vrDXY/hcxCgzROe4VJU4xqjlDOiLHZb2zqMzq6zI7+pk9u/8mLcJtYrRE3LxXg3MNnKXW64755Yfqgz8lHmcYMHItd1KBTRUXYMth5xS29S1eo696c6H5r4G9v6YbowFzpJ5VeQx2A+iCxg7GLWxo9hO6y1G554B+lWBy3sak4X5DWDAvOgjKZXCKpJjNzyZ3LTwkispKInLaSGleWSxI4KFUBKcMJkHMQ78u4uxrsjDZLP014jAqVL8s9zQppqYA58rGJRHt37F9eCP/gsY3XXP8b57zfGyo3EuPaiqqO8y90r7im7fLrfI88rBw8qACgk7FlHBvFctiMD6ojjUS33/9Qd0VTLzLeY142pmvCJQR60PGGXrrBZ2r00Y6gydlFKvt0tVv/7beY8UX2Oo01Q6O0SGFMdlLo8ITMzW+bR0MBoT+TSHG8mmEOvfh6/2dvk3rfV5M79n/rEW3VBwSuDmTzRZodGw6U6Bt9hloAsJ21rt1f/7YSDgK6gTePSza1FjgwuBC7w9GbJtA8bVIUO5uxiiaktQ1c+YnJRHxkIhAsfHBoYnjn5OghbFzB2JLH5ZRalnzGptd8OfaZkuVxOT8hQqAASgwG83ghO6bu/WDqzdfaXEveIhWhL909vv7d7NZ4Zv9uMXNMHUthawaLXggMIq9KKpeRB4b3f+3rG4w1YcoKAapfZx8yL/ASB8QxoOB9eqxfB/QOnAzQ128y126/6mph70Ec+EIWO/T9YKvlnDApwUfRPrv2qeEekLlKYmpOgZfijkY5BbAPZKEeG488+1T0727f8Q8P+Fzn95tbcMCVNISNuHrMbaob0EaVPYbGIXNDF5xiW+OuBx4SDx4B8At6C4LGCjiYUkVj8plD7tlMcYopjGULaVEBFJYf2hp98rn3r78t8Mjq4E9+dSw8XCwogPnA7ODCYTZdDlBLSl8O8QWN1oTHMiiAaJA9l1Nxb4l6YMC3bIX3vMu5WC8u1ZVlRlXBBxbyapLLpxhRZiTUuWI2MxCJfesJONbYK0AbgnRlwNLcSzUFzPM76PoOGmkrh/WNcYI1CQ+p/mOLK/faC0jnCGcxLTB5GcIl0LAih52t4KvhArlzWppzTn3PaOqJwJtlS9qUSqWOHDkS/uJ9GyjzJpqAa91FPjGga4mQxoCuGWClh3IEjI6wuT6qq4kTZGPuqagP3X8/63cXVCWpqhk0EQpA+CSTHROSE1xC4bIqC6ZQUlgk6DsOyJvjEtn0ZJ6dFCCYl5Sg3/vZawGEvKc3+W+5VR3dLUPoLPNT2ak0n4L7KIxP5SZTioYsS5EqbsIWsb0RPgOiKTCyeUlDKbgiWzl86A9fedDz4x+r4HqKRZ6BaANiwkNyOg2vnFIUBru3RK6rfcvnPu/WWZHtWG/vN9TjRTtKM70RCFBJY8TUgqShplrwEx266h1feSCf2gOOEVskNBRRAgUzeYjLHnROuZfMEIpeUyWMswFWM5nJTeu8l13dQyoi5ka30Ykhq3lhP3K/u/qpxn7AOXo7XCEaYrnaHqrmj+BtvnB3urNLLUiClrNkGE7C3wvuQwRcCfaH51NZPpEQ02OKlOVSosDmJG6CTyaP7Q88/fSr1XXgA9cS6l3nwi1rXsyMH8sVZcCU8K4SBf7AyI7RLTv4DFsiJMHPhodG2+OHDeyYOhcwhtI2buLQYuagz5PcOiAA7FDkHFdUp8BxJxkZid4KRVllJo+/97b32ps2mmq9lNWvswVLcqcdIX3DSbnrHAP6hripwUcsHTrr9i/cKXncmkETOfzLuTIH90ze7TLknZvXXODLoSDmUbHYjx45pU7u/vXrQceF/cTqsTkiFQvipNVd2eIj9vJypn6jE7wNtqsRm5dY2/S17iuuPfqfr6tjY6BwPADzxDhWIAQxlVdAzYrg/1OTWWYcwnpcgQXWQ+SSfGps397Yy7/Y8DeffYeyvmkwvrf8so4nvj82MIxJJD4PgDIp5A/u2HNo916chtFqp5gBBvir0YngDdDUJ6fZH4Q3WSwPSAoPig4OP1FUs6IKhkVR5ClcFi8r+3Ye+dnzvgsubidmP7GMWJDKQbtwTQAO9CLRPco9VNEYomx+Yt1MLLErr81sWgeB1VRanplc03aTaSE3x8/K6J2NX3tmKbLsiLFVZmJi36qXg7b5vYQOmRvipKGHrgWf4zc0hEhDlDhj+havDgcwh+EwWhz9utpuUtnlWrbzHx/l3O4ikwBbAcE7WF6wZskikiAqrKTmBIXPKLzCANqRJDitSOmcSsm+QO+Nt7vvv+dYx/tHByP8KDgMsBgyfDCJk4QUU+JOLG02Ltl6bdrn5FwYEmEzaHbAUWEsg+xZ+YKgTPHKh5w4LoqMWgAvyvQHtj36qKd5gY/Qw7qquKk+hpN1JYk3lq/Sd7oM1u765raq5vZzLxt/7w9gtSRFHePUaaui5XZwqY7WmiWws/NO5OxFiXIZvlT6wkgwJ6mCVDy4/8APngrUt24m1KC1YYBUxnC4uxHnu4kzomstyX2EuII0VkjidGOU1HTrazovvHTHmjXCzh1qEbRLKshoBUBz07jBSEkUC1w2r5XXCnBUwTIIqqIK3IE/vv/hcBDpxFRF60tnuGxaAWfPpnDTuFzQVBs34uI20nKjq/aGsQUTizuIjnCpmaDAn0thGkhiC+BWVCQXOrD/w399IXLzrW3Wuj5ijpvtcYPdi2/YXhI6TqwT3HKnfVmHpTdb8+4HH9yzavW+N95S8hk4x1wym5LVmZhYWzCHoyMSL8zc8X82+3661pemrXJgDCGMVkVubHTyRz8J0g3txODW10IUB1AyiuSwTvCxbm0ZWZRyRnVNbp0DQY4FXL+1m1Cd9kXDN96d8HoyzAQIsigUQX9BYkyBHwe0k0fAC+CPBW2X8+OpJMB5VcTxNa08IIFFwU5W8KhiBqAfmnVm2vODoHGtM8A1ji3BtZzGgohMcBnAiDlkpcTxAgniGoxjIbRIHmE2bjzwwD8FbI3dlLWXWPuNiA48+nowld6KJm0TDJzjktC16XcQOlXtm3de6k9vFQGvKtpIHsdLU9nMLNo3rdaBkbYglue5SlWns9j37MyxWmSXKj3hc8k8q43WS/mxsQ9eeGnTZVcHms/ztyzu0tVEkEkNVzT16urdpB7JQEid39jcBQeT1MSM9SOGujCp8pOq9fbWbd//Ibt9a0HIKhDUKZwoZuDtC4qMC3+yGTicgOgmE1OY1FQFXpXRXKSmQ7+sxi3G5MqVMjQyyPuIeyb50qgGzg5IIjhcEAdYLU6zAEURN2iAWqrbd/Hvrx394ZOhFVf1ENsgsYR0VSFzYxg3wzZATOS1NPiMddpyu8Z+qgn5cA0u8K4BXY2HMnesuGkiHAADlVXVJBhxeI9aE1GJFEdLEYmnxnRCGfKeTe5cDrvvSjPqfPniswUmDZgUfFA2q6Y5dExgFrl339xx7529rgVRqn6AYL4MzgHASp/BGUWw1QBRdYhu7TO2uKucgWqbx6DbpKvoNtUFll+1d/Wa7NaRosyD0Zd5DlmWpHxRQWL2JFh4sQg/GBP440VMcch8AbPkqTQgRVANKVvEkWkpn2GZafSlhQVYWweV1wY2WFkEkC7iXH8R+Z5E9sDorj1vrt35pcdCy65ab7Z3ElPMgMUcMIkBUh+kmgeNCyEYdJNKj1Hbf4QYxhWmWyJGED2W29zEuH/VL9UMxHY5pF7Q2MABq2JLhqCtHC+ZOC1GnVWP/Ai5z2olnMm3M+ubpSejz6xaW9kCpiZmbUSqZ0OL3+zsxP1DjTGqOUbPj9KukLZJBYK9gHF+jxVebBok+l6bre3Sy7d+7bGxl14Vwv5c4nCOOy4cP1DAZXVKTlEBaaRUlVVzk4VMRsGwgsnwDJ+fEjNTeayli5g+YAF+pkQIT/ATg3bDeeVV/BVSUVUUwOQKRO6J7SNHXloTu+OOnqZ5bj0gFoNfZ5mulOqRDStKzdtK5g8TB9j3kK6iT2/x0IYhyhEn83uNTe5Ku4/oPPYFR556DnxMacv8DJRSKhCeoTmw3CLIao+z2fczyr1UXphJR1E+QQd+/8b6cy/dRAw+yhzW1/kIhNGOcEVzv6ElYHK6DTY3VRuhXAO6+Ugdq2sJmpxBE0IdcF9densbVbfB4uo+f/m2rz+47TsP73jk2wdefSUb9BSOHlD5jJrPFTGcUXEXs6LC0WbzKoONMAqr4NQDZgh4GVSPTSDFoYzlMsBLk+rEhLrjg1yHJ/vmHw//6AX35+4M2l0BujoMzpNY43pbRFen8SU7Q8ThN7QGzAtA+h6Do99UhxUFSx14VPgyUNHQb7AHSWWwcenok/8sj+3D7LSQO3Ub0Slynyn68oxDuaXgI+Q+89bNKr+VO9xKwFnNMZNvvhG95po2ovcS4xaTK2Zu7iLVUeM8wJfgeL16e4RyDpLWmH4enNl+Ugu3B1DQIAQgtKOfVHt1lg003Wa2dFqtXYTubmjqX3nF0P337fzxD/a+8Ny+P2xMjmyXVH5Smho/dkidTKk5rbpUSgHgXgqsqRUU3NIAX2RCwaGfvTj82A/i9z7gXnF1YNnFvvpFm5HK3goGGoM7IyazQgZc5wsBRxi8EXFg9Ec3Rawu+Gmb2RG79qY9X3u0c8k57RTtI4ZA63mjz/0s/+FheBslnzfTdp/Ihp5hPrbcl/mx8PusZpVZbbrleKr0h5NgCfIJtuNPA7fc3GuwhUhFFDTF1NxB13dCME0aRmjXMF0fpe3grDoNdR2kykOsMaoSJA7SH6GcIwZH0FjZS4xhumqAWHzE2EeMm3TmzXQF/LvWOS967z3cW29sfea5vr//0r6Hn9j11D8PrX5mxxPPbn3imZ3PvzjZ3l4c3Vk4vJffv0s6vn/q2dXrl170pr5mHV21HvvdKiDMiRkb4eo3uLyUy0NaQqABIGhiQ1dvbYxUtwDejRP7NktTJ6lYt3iZvOkdlT0MsWgXsfQuv2z3b16Tkklcd59JI5blmNKhPyHf/FxyR7t/onPmo/H7GeVeTteUy80l0WcEhQVNA1/m9e361jc3NTvXEarHUNle4QhWz49b5oNww3qbz1DthQNrcnrqFw6fd8mWFSvbbYB5arfrm+PYA4ugLWxwRkwN4OUGcBNF3QgBX127QUd6bM7jN9936N7HRr/71P7vPbH5vAvWkQqPpQXu7mZLY9fiT0X+9saBL9wWv+uuI9/9zugNt7jtrj7cpQMoqyZG7MjfSJy42Juq7wfVploipgV+jSgiZKztIlUbSIVPVw0+Nmqp7dNbAxesKK5/N9v2dviOu8N33TfRsRk3V6gqMncJOYZJ44SQdtxPqGCpEyR7xsn8stznrDfN1ak8S+4znSrOmSvqUaYwJauCkpcObZ387S+GbrhuE7H2zTt3z/krtzg/AdoNwCBmbvURO450WlsPP/iQ/PYbI1/9Spupxg8SNDjcFQvA9AMQwuc0Div3G+aBgDx0s9tm67tgxfjLr+Wjw1x//9FXfh668XMDl1w5sGSp1wxHRx8gJjfqtRHwSRtl6bHWeumqqK4GDtkI1RCnXHHd/DDV6jHDL0eqjH4jTvR6SYWbmALYwN7SaW4CuBWsqPXT5kEA8lST55yrwitvDv909cE9W8Axg/1iciLmU3lsNAOLUEpbnehmyJ8gt5jdSThLiT+W3OdaqFYeAS39VBJYlcHc+fFcJleUsW9iy57Rl3+3Z80Lx1et2nLzbWAuvUiY3IzklaZaD6kMXXeT8N5bqedf8DUtxlZCvQ2w5qBhHqg8YCHsItc19hmawqQBngBG2nbPferWwWzQG7/7/lDr+UNX3sD82y+Fxx8NLFnaTVmQw4dY+qmqiKk+YAQ4WOnX1/h19jDlGNK54ob5EQPccofX0ALoFncGkBq4Itam2KJzYxevnHzkudQza7Zd+7kOqqKX0BG9DZSg4/Ibjv78deXYMfDkUwKupy1q8sDKJcQRWNcQZ0hGmCn3s9iPj5b76TssSseqBIZmJnBYGdNbIpdmeFZilUxaGS8oaYDk4oTKjqfcXf0PPNDeNB+UK6LtFeqnrO3Olr3ffOjINx/tdXyqS1ulCxYGQEWQ1A/SjQPEPkzALtVG4PjrLZ3E7Lto+YGHHw5fsbKb6EKE9rrmHfzy17ZfdUOwfnE/qQe0N6THmQiIFQIEZyXcpvo+a7NX34ypC30TTpZS4EuawjjaiykjX8PiD+79RnbDRvX44WIxW0gdHnn8ifeNtRv0lvilK46vepb7YCCvKqKiFgRF4wRlhSI2YuREtUTBPnNm6kTjDX/2BYgflY880zT/6YxyJ7ENh1BOo6tmtNY4ZA+Z4nOpYpGROTWTlA7vT/37b3YuuGgTIV6LuYtQfVX18aXLRy+7cc+yK2N1i/wmQNA2r6FVI4qyY/e9sRZnHAyNPl1zl67Zo7N1EqoN/jtVNUjqgqR6Y5U1QKq0vCCuUtPiGtf0+nQDFiDBTA1SzTvxXtZombs6v6neQyq8xNBLdH22pp0PPcwFg/ljY8ff+c/dD38ncsENsYv/ft8PX+IGtuEOLm1k+1SlPgPe+8i559MfH40jZz1O/2a5ln8ic6k1G2thG/a65HAuWRWQx5A5uP/wqjW9nz4PRW+o6NRZui11g65P7Ft0wb6Wc4aq5vdRGA0GdNpCbwpJ7yKkFa4oaR0wtkT0jT7K5tHV+fSNAQMEX/U9enOvvipodQw6FsGd66Ubukmtz9CAJCQEb4avalF8yeVbllziocGFmEO0bTvlipL6iK4BouheYvdWtfY3L+lrWPCOdfH6JVcMffNxprtPZcBP5ZGgQZJnzYec7vD+rHIvnZdT0D12aJTa9bUyS3lNlAjRZVbIiAzGnCp/5OiB117ddee9XbamzXT1ZohXKaO/qjZQ4/BhGrk5BuASqR6dftLqIfM8xOWnMAUYJ9WDdNOAfsGwfmFM3+KjHYAIAepsAOzhaN15zmW7z1npty/uAUtldgVMLgh84ChEFnz64Je/HrvmJi1yrh00LvToXD36Rm3ZdF07sbQTM8ZErkW7vvjd9H+8pRzcn1XZJAQjBWx0g9B/rq01/1dy/5hziDMWW+RPeABEU6X1RXAzJgrihCBySYC8U1xegLgmn+EKe/Ym3n9n9/e+777w8jazrR1BiMVPbCOGVuzJMdZB2OI1Oj0GrVSvrwVv6aFNHtrWh6GNc8hcH6YrAWIO0/MgngzRTdvsn9rtOE/Lq7iGqHlxMs9vtEEEsGfFVflfvtJ/zz1rjVXweq9lAYQRYcruJWZAikHnwm1X33LsR89nurrVo2MqxyqqhEwNWezWQwYRuXAWdPe/efxP5D5L4tMPPj/d4q21j5+o4YqZnMjmJAlzdVMMO5Xl8hwulcSESTE5mQ2Fjv38le13fdWz7KL11Q3rLDVuQ41bZ/UQY5AYY3TVoMEe1WNGsKeyGsIxjHsNYC5IiBBwkh7rQsz7E7vGt+wKmZvA/gTBIlUs8Fc1BXRV+6+8Vv75S+E7b9tAkzChAPasJQQCt6GFF+364v2Tv3g1F4jIExO4ekdVE5KQ0OZekP4Sk5dZjUfx/+RBPv5LZ7rj09ek4SzZ9JZqzFKB3HEvjSgWsPEKc9Aa93Auy4gsIyQzXD4hFgTkhy8InDp2RImGEr/99Z5nn4hef3vgoqv7nAsh5gLvFyDmIJhsqs5L7FGqfouxAXE6RaLVtn6IlYjDbajymmrc5hqPpdZf6fAYa3upGvCoHmM1gPpIVfO2y67rm7+sk9BhS02geZH387fvfvLpY5s3ZcaOaN3YALrERIEFYM5KhUxBSuFeR1biUasYIfeXJffTAwGN4bZk41i8tDQR2BklC1Ymw3AZnKTnZVxxiCVD+FobY8EFnhKXR+ZKNZtSp46oRyfFSPzwa78beuS7/utv6vrkOW22hvVG63rK6a1fEqxb2mZpiX3m1vHvPbn9hlsh0O0iFX26ml6qslt74qPrAP9AdNZhtvVVtfhaL/RccF30xnu23/fQoad/evRXr050eLlde9EfqUWQ8pS2iwXC7EKaz6ZYhuE0TmLMMqY5Ni1l/9xyPyOCPKVRe8ZIEV+qq2h+tST30ko67GAB/yTAB2CzIjLT4PR/Lo1r3UUmlZ1McUnNIxTzvMrn1XRe4op8TpUkVUbe0NEPsps3HH/xp/v/6aHhr35jbPXzB773dPDuRybWu9Vcctcrq71NTeF5Fwx88pLIpy8JnntJ7PLP7LzpC/vu+NK+O75y6NHvJ15+Nd/mS3UHxR17CpOTEpvOppNqMpFjUoB6i2wBKUW4QoGVC6zEaONeuMoQYDD2YGITrciy///6fvbRxVK+v3yVeqO4aYRzcpC1PGgyXaOY7iyZ7vNH4FNyDLggUZKKCuZ48xgEMokpOc3lPpxMHj5WgGhM5I/v3bcvGBvt7D3Q6z0SjI4Nb01+MJo5/CE3Mckmk4JcEAvw34vaVYBfVbpmvsmZ15/5Qf6XQj+JI080/5WuEp4pN+F8TLkjOdiJ7p2siFaoRLWFK7dzuHtKLMhgc7EWKGn83VlOzXEqn1XFnCqLyA6FtEMFEDTym4r5E5dw8prxJmdef2VyL1uh0+Vebv34OHLXXodyx32CWK3kpg8+7uxDJwG+LpFlJhUhUcD52Ewmg1W0IhoxiJW1idzcjJo9XxqvKLdxl6+/VrmfZR3hGX8064OdbHA4Re58We4lG5XRCtOo4zmhwPEAirDLkMkkRRx7xOWOGeyPANdXGt/RHDuvbXwUCxxepZmW0jVTG3J/GY//ttzPyN5zemB1cgvyx5X79GwniFhisthll53ONsMrWbAnnICjC9qggSLkC5lsHoLJDE48MwJS97JaKypiWHgRw8+Ue9nH/Pn1eq7HfwE7ZtUgHnyphAAAAABJRU5ErkJggg==" /></div>
                  <div class="SealPercent"></div>
                </div>
              </div>
          	</div>
          	<div class="repeat_words">
          	  <div class="repWords_box1">
                <div class="repWords_row">
                  <div class="test_range"><a href="https://www.bigan.net/qa/?key=%E6%A3%80%E6%B5%8B%E8%8C%83%E5%9B%B4" target="_blank" class="green"><span class="icons inlineBlock"></span>检测范围</a></div>
                  <span>重复字数:<b class="red">6,152</b></span><span>总字数：<b>49,496</b></span> </div>
                <div class="clear"></div>
              </div>
              <div class="repWords_box2">
                <table width="960" class="reportTable">
                  <tr>
                    <th width="160">复制比部分</th>
                    <th width="*"  class="bdrNo">章</th>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.107%"></div>
                          <div class="perNum">2.107%</div>
                        </div>
                        <span class="wordsNum">（80）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">中英文摘要等<span>（总3,796字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:15.656%"></div>
                          <div class="perNum">15.656%</div>
                        </div>
                        <span class="wordsNum">（1,136）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第1章 绪论<span>（总7,256字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:27.982%"></div>
                          <div class="perNum">27.982%</div>
                        </div>
                        <span class="wordsNum">（373）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第2章 对话系统基础理论<span>（总1,333字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:37.772%"></div>
                          <div class="perNum">37.772%</div>
                        </div>
                        <span class="wordsNum">（451）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总1,194字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:25.404%"></div>
                          <div class="perNum">25.404%</div>
                        </div>
                        <span class="wordsNum">（236）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总929字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:20.276%"></div>
                          <div class="perNum">20.276%</div>
                        </div>
                        <span class="wordsNum">（235）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 2 章 对话系统基础理论<span>（总1,159字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:38.684%"></div>
                          <div class="perNum">38.684%</div>
                        </div>
                        <span class="wordsNum">（494）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第3章 基于残差分组线性变换解码器的自动语音识别<span>（总1,277字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:42.523%"></div>
                          <div class="perNum">42.523%</div>
                        </div>
                        <span class="wordsNum">（472）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,110字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:26.244%"></div>
                          <div class="perNum">26.244%</div>
                        </div>
                        <span class="wordsNum">（327）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,246字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:22.052%"></div>
                          <div class="perNum">22.052%</div>
                        </div>
                        <span class="wordsNum">（245）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,111字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:10.077%"></div>
                          <div class="perNum">10.077%</div>
                        </div>
                        <span class="wordsNum">（171）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,697字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:24.533%"></div>
                          <div class="perNum">24.533%</div>
                        </div>
                        <span class="wordsNum">（368）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,500字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:8.431%"></div>
                          <div class="perNum">8.431%</div>
                        </div>
                        <span class="wordsNum">（158）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,874字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:4.045%"></div>
                          <div class="perNum">4.045%</div>
                        </div>
                        <span class="wordsNum">（68）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,681字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:7.403%"></div>
                          <div class="perNum">7.403%</div>
                        </div>
                        <span class="wordsNum">（126）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 3 章 基于残差分组线性变换解码器的自动语音识别<span>（总1,702字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.345%"></div>
                          <div class="perNum">2.345%</div>
                        </div>
                        <span class="wordsNum">（31）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第4章 基于标签感知图交互的自然语言理解<span>（总1,322字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:27.021%"></div>
                          <div class="perNum">27.021%</div>
                        </div>
                        <span class="wordsNum">（244）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总903字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.993%"></div>
                          <div class="perNum">2.993%</div>
                        </div>
                        <span class="wordsNum">（29）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总969字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.627%"></div>
                          <div class="perNum">2.627%</div>
                        </div>
                        <span class="wordsNum">（32）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,218字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:6.83%"></div>
                          <div class="perNum">6.83%</div>
                        </div>
                        <span class="wordsNum">（106）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,552字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.679%"></div>
                          <div class="perNum">2.679%</div>
                        </div>
                        <span class="wordsNum">（48）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,792字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:0%"></div>
                          <div class="perNum">0%</div>
                        </div>
                        <span class="wordsNum">（0）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,608字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:4.03%"></div>
                          <div class="perNum">4.03%</div>
                        </div>
                        <span class="wordsNum">（49）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 4 章 基于标签感知图交互的自然语言理解<span>（总1,216字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.308%"></div>
                          <div class="perNum">2.308%</div>
                        </div>
                        <span class="wordsNum">（43）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第5章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,863字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:1.397%"></div>
                          <div class="perNum">1.397%</div>
                        </div>
                        <span class="wordsNum">（20）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,432字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:1.393%"></div>
                          <div class="perNum">1.393%</div>
                        </div>
                        <span class="wordsNum">（23）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,651字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:6.155%"></div>
                          <div class="perNum">6.155%</div>
                        </div>
                        <span class="wordsNum">（93）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,511字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:2.058%"></div>
                          <div class="perNum">2.058%</div>
                        </div>
                        <span class="wordsNum">（22）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第 5 章 面向车载嵌入式设备的本地智能语音对话系统<span>（总1,069字）</span></div></td>
                  </tr>

                  <tr>
                    <td><div class="repWords_left">
                        <div class="percenter">
                          <div class="perProgress" style="width:18.693%"></div>
                          <div class="perNum">18.693%</div>
                        </div>
                        <span class="wordsNum">（472）</span> </div></td>
                    <td class="bdrNo"><div class="repWords_rig">第6章 总结与展望<span>（总2,525字）</span></div></td>
                  </tr>
                </table>
              </div>
              <div class="repWords_box3">
                <div style="float: left;"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkwAAAASCAIAAAAmHRY6AAABP0lEQVR42u3VSwrCMBAA0N7Dk3hZt97Etadw7dqVghBkko6phqDwoJS2+Uw+k75ldz4l1/VwzCuMvZJwj6JQGr6U57paEujZybRpNgdcXm+XfTLf0iR0EuaSRGnWDCvwdrma3a4NI0TpWYRQrXN36olsTeZ6/GsrPzNhRh3POjEGRplziD7o/0e2adM/4S/G/GVG5dvUf06T5q/3BXKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5CAHOchBDnKQgxzkIAc5yEEOcpCDHOQgBznIQQ5ykIMc5EYidwce6Sowvd/kxgAAAABJRU5ErkJggg==" style="width:588px;height:18px;border:1px #19c2b9 solid;" /></div>
                <div class="percentTip"> （<span><b class="inlineBlock pert1"></b>无问题部分</span><span><b class="inlineBlock pert2"></b>复制比部分</span><span><b class="inlineBlock pert3"></b>引用部分</span>） </div>
              </div>
              </div>
              <div class="clear"></div>
              <div class="similarLiter">
                <h2 style="width:100%;text-align:center;margin-top:15px;">中英文摘要等</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_1" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=浅谈人工智能应用领域及发展展望" target="_blank">浅谈人工智能应用领域及发展展望</a></span>
                      <p>崔玉敏 -
                        《科技经济导刊
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://my.oschina.net/u/4330033/blog/4535922" target="_blank">智能手机的应用</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识嵌入和边界增强的嵌套命名实体识别研究" target="_blank">基于知识嵌入和边界增强的嵌套命名实体识别研究</a></span>
                      <p>廖晶晶 -
                        《西南大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能语音交互中的用户意图理解与反馈生成研究" target="_blank">智能语音交互中的用户意图理解与反馈生成研究</a></span>
                      <p>宁义双 -
                        《清华大学博士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>自动语音识别和自然语言理解在深度学习的驱动下取得了重大进展。</em>然而,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>神经网络算法近年来因为深度学习出现而发展到了高潮。统计机器学习往往需要设计者描述数据的特征,而深度学习的多层神经网络让机器可以由低往高逐层自动学习复杂的特征,能很好解决一些更复杂的问题。<em class='similar'>深度学习在语音识别、</em><em class='similar'>图像识别领域和自然语言理解等取得的重大进展,</em>推动了本轮人工智能的热潮。4结语人工智能行业大数据+强大算力的+算法优化的基本方法论已经成熟。但是,现在人工智能的发展和普及还受到设备昂贵,</p>
	                    <div class="textFrom">——科技经济导刊 崔玉敏-《浅谈人工智能应用领域及发展展望》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>CQUPT-DS,<em class='similar'>接着将上述提出的两个模型在驾驶数据集上进行了训练,</em>最后集成、</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>另外,为了研究推理时间的影响,作者使用了两个不同版本的MobileNet,即最初的MobileNetV1和最新的MobileNetV3。另外,<em class='similar'>这两个模型都在COCO数据集上进行训练。</em>⁞⁞驾驶策略的训练流程⁞在自主导航任务中,研究人员用了一个类似于&quot;条件模仿学习的命令输入变体(command-input variant of Conditional Imitation Learning)&quot;的神经网络,</p>
	                    <div class="textFrom">——网页 -《智能手机的应用》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>关键词:<em class='similar'>车载语音交互,</em><em class='similar'>自动语音识别,</em><em class='similar'>自然语言理解,</em>嵌入式设备,<em class='similar'>对话系统</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>音助手仅作为对未来世界的美好想象,存在于科幻小说或电影中。如今,随着人工智能的发展,我们正在一步一步接近这个智能语音的目标,<em class='similar'>即任务型对话系统。</em>一个完整的任务型对话系统包括5个模块:<em class='similar'>自动语音识别、</em><em class='similar'>自然语言理解、</em>对话管理、自然语言生成和语音合成。其中,自然语言理解模块可以被拆分为三个子任务:领域识别、意图识别和槽位填充。</p>
	                    <div class="textFrom">——西南大学硕士论文 廖晶晶-《基于知识嵌入和边界增强的嵌套命名实体识别研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音交互系统的使用变得越来越广泛。这些系统通常⁞支持特定领域的面向任务目标的人机语音对话,如旅游计划、预订航班以及询问⁞餐厅等。一般而言,<em class='similar'>语音交互系统集成了自动语音识别、</em><em class='similar'>自然语言理解、</em>对话建⁞模(Dialogue Modeling,DM)、信息或数据库访问、反馈生成(Feedback Generation)⁞以及文语转换(Text-To-Speech,TTS)等技术[105]。</p>
	                    <div class="textFrom">——清华大学博士论文 宁义双-《智能语音交互中的用户意图理解与反馈生成研究》-2017 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第1章 绪论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_2" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于自适应学习和多尺度前向注意力的语音识别研究" target="_blank">基于自适应学习和多尺度前向注意力的语音识别研究</a></span>
                      <p>唐海桃 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(371字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于自适应学习和多尺度前向注意力的语音识别研究" target="_blank">基于自适应学习和多尺度前向注意力的语音识别研究</a></span>
                      <p>唐海桃 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.9%(358字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.7%(342字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=解析深度学习语音识别实践" target="_blank">解析深度学习语音识别实践</a></span>
                      <p>（美）俞栋，（美）邓力著 -
                        《北京：电子工业出版社,2016.07
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(129字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="https://www.doc88.com/p%2D9069970870647.html" target="_blank">基于循环神经网络的语音识别声学建模研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1%(73字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://cache.baiducontent.com/c?m=9f65cb4a8c8507ed4fece763105392230e54f73561868b4968d4e419ce3b4603506695bb27281405d2cf7c6d00b8492bb0b6692c23467df7cdc79f3bdeace12c388957230019913114c468addc3526&p=9060c016d9c11cb508e2947f5f08&newp=8b2a970e86cc41ae17f587625f0092695803ed6239d7c44324b9d71fd325001c1b69e7b121261205d2c6786d03a54e5eeaf633763c1766dada9fca458ae7c463&s=cfcd208495d565ef&user=baidu&fm=sc&query=dashuju+site%3Adocin%2Ecom&qid=cb8178880014014e&p1=9" target="_blank">基于学习算法的机器人触觉识别和语音交互的研究 - 豆丁网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1%(73字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多种机器学习算法的车载语音文本分类研究" target="_blank">基于多种机器学习算法的车载语音文本分类研究</a></span>
                      <p>刘威;张森;宋冠谕;丁晓雯 -
                        《信息与电脑(理论版)
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1%(73字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="https://www.doc88.com/p%2D0327887270012.html" target="_blank">多噪音环境下的语音识别技术研究_曹晶晶 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1%(70字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://www.doc88.com/p%2D8819199017088.html" target="_blank">基于注意力与神经图灵机的语义关系抽取模型_张润岩 - ...</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.9%(67字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.xjishu.com/zhuanli/62/202110823352.html" target="_blank">一种视频超分辨率的方法及装置与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(58字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于光流校正的端到端场景文本识别方法的研究" target="_blank">基于光流校正的端到端场景文本识别方法的研究</a></span>
                      <p>张文强 -
                        《哈尔滨工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.8%(55字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于端对端方法的任务型对话系统设计与实现" target="_blank">基于端对端方法的任务型对话系统设计与实现</a></span>
                      <p>贾志豪 -
                        《华南理工大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(52字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向智能个人助理的用户多意图识别方法研究" target="_blank">面向智能个人助理的用户多意图识别方法研究</a></span>
                      <p>肖泳利 -
                        《哈尔滨工业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=TDNN模型对电话录音场景的识别研究" target="_blank">TDNN模型对电话录音场景的识别研究</a></span>
                      <p>孔玲军 -
                        《福建电脑
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=问答系统中复合问句分解技术研究" target="_blank">问答系统中复合问句分解技术研究</a></span>
                      <p>李威宇 -
                        《哈尔滨工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.7%(48字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的工业机械手语音控制方法研究" target="_blank">基于深度学习的工业机械手语音控制方法研究</a></span>
                      <p>李莹莹 -
                        《华南理工大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于GMM-HMM模型的智能下肢假肢运动意图识别" target="_blank">基于GMM-HMM模型的智能下肢假肢运动意图识别</a></span>
                      <p>盛敏;刘双庆;王婕;苏本跃 -
                        《仪器仪表学报
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的电力调度语音识别研究及应用" target="_blank">基于深度神经网络的电力调度语音识别研究及应用</a></span>
                      <p>窦建中;罗深增;金勇;李群山;杨超;杨绪升 -
                        《湖北电力
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(41字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202011555183.html" target="_blank">一种同义句生成方法、系统、终端及存储介质与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.6%(41字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">20.</strong> <span><a href="https://www.doc88.com/p-2754529510163.html" target="_blank">试验数据管理技术研究及其在航空领域的应用</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">21.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的水下目标图像识别算法研究" target="_blank">基于深度神经网络的水下目标图像识别算法研究</a></span>
                      <p>方笑海 -
                        《杭州电子科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">22.</strong> <span><a href="http://xueshu.baidu.com/s?wd=脑电情感识别中多特征融合与分类研究" target="_blank">脑电情感识别中多特征融合与分类研究</a></span>
                      <p>韩小娟 -
                        《重庆邮电大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">23.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深层网络的城市街道场景的语义分割的方法研究" target="_blank">基于深层网络的城市街道场景的语义分割的方法研究</a></span>
                      <p>陈聪 -
                        《西安电子科技大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">24.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的脑电情感识别研究" target="_blank">基于深度神经网络的脑电情感识别研究</a></span>
                      <p>陈占刚 -
                        《合肥工业大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">25.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于非平衡电子病历数据集的智能诊断研究" target="_blank">基于非平衡电子病历数据集的智能诊断研究</a></span>
                      <p>蔡林坤 -
                        《郑州大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.5%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">26.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于双重多路注意力匹配的观点型阅读理解" target="_blank">基于双重多路注意力匹配的观点型阅读理解</a></span>
                      <p>鲍亮;陈志豪;陈文章;叶锴;廖祥文 -
                        《山东大学学报（理学版）
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">27.</strong> <span><a href="https://www.itcn.org.cn/news/p/4381.html" target="_blank">智能手机行业发展现状及未来趋势</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">28.</strong> <span><a href="https://www.docin.com/p%2D2594742824.html" target="_blank">汽车行业智能驾驶系列专题报告（2021）：全球车载语音交互龙头Cerence（CRNC）</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">29.</strong> <span><a href="http://www.doc88.com/p%2D6374701469595.html" target="_blank">网络考试系统及Web服务设计与实现 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">30.</strong> <span><a href="http://xueshu.baidu.com/s?wd=大口径光学元件面形检测中子孔径拼接算法研究与应用" target="_blank">大口径光学元件面形检测中子孔径拼接算法研究与应用</a></span>
                      <p>孙琳 -
                        《西南科技大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">31.</strong> <span><a href="http://xueshu.baidu.com/s?wd=页面标注系统的设计与实现" target="_blank">页面标注系统的设计与实现</a></span>
                      <p>李新 -
                        《华中师范大学硕士论文
                        》- 2007 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">32.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110671327.html" target="_blank">卷积神经网络压缩方法和装置、图像分类方法和装置与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">33.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于单字级深度神经网络的中文主观题自动评分研究" target="_blank">基于单字级深度神经网络的中文主观题自动评分研究</a></span>
                      <p>龚云 -
                        《广西师范大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">34.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于注意力机制的端到端语音识别技术研究" target="_blank">基于注意力机制的端到端语音识别技术研究</a></span>
                      <p>龙星延 -
                        《战略支援部队信息工程大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">35.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法" target="_blank">基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法</a></span>
                      <p>杜文风;王英奇;王辉;赵艳男;高博青;董石麟 -
                        《建筑结构学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">36.</strong> <span><a href="http://xueshu.baidu.com/s?wd=车载蓝牙语音交互系统的设计与实现" target="_blank">车载蓝牙语音交互系统的设计与实现</a></span>
                      <p>刘伟 -
                        《西安电子科技大学硕士论文
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">0.3%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_2" class="simMore"><a href="javascript:$ShowMore(2);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>语音交互是人机通信中最自然、</em><em class='similar'>直接的重要方式,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>驾驶员与汽车的交互方式一般有三种:触摸、按键和语音。传统⁞触摸和按键交互方式的功能操作界面往往过于繁琐,又不能提供有效的反馈,容易分⁞散驾驶员注意力,从而影响驾驶的安全性。<em class='similar'>而语音交互作为人机通信最自然直接的交⁞互方式,</em>则具有天然的优势。相比按键和触摸操控执行复杂需求时的层层定义,语音⁞的含义则非常丰富,一句话就可以包含多重信息,</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 刘伟-《车载蓝牙语音交互系统的设计与实现》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>截止2020年9月,</em><em class='similar'>我国乘用车车载语音装配率为</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>还未分拆Cerence上市的母公司Nuance占据全球智能语音市场份额第一,市占率为32%,谷歌紧随其后,市占率约28%,同期科大讯飞市占率约5%。2019年,<em class='similar'>中国乘用车车载语音装配率为48.8%;</em><em class='similar'>2020年1-9月,</em>装配率提升至64.8%。目前在中国区车载语音交互市场,科大讯飞市占率超过40%,Cerence市占率超过30%排名第二。BAT也已分别入局车载语音,其中百度发展更为迅速,</p>
	                    <div class="textFrom">——网页 -《汽车行业智能驾驶系列专题报告（2021）：全球车载语音交互龙头Cerence（CRNC）》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>64.8%,<em class='similar'>预计在2025年车载语音市场规模将达到32亿元</em>[2]。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>智能家居等领域大有可为。在智能车载领域,语音交互是智能车载的核心模块,智能车载正在从后装向前装市场渗透,语音识别及交互功能前装标配搭载率从2019年的49.82%提升至63.25%,<em class='similar'>预计2025年国内前装车载语音市场规模约为32亿元。</em>智能办公产品需求增加,翻译机、办公本、录音笔等智能语音产品应用加速,预计2030年仅我国翻译机市场规模将达到56.2亿元。物联网带动智能家居产业发展,智能音箱不再是绝对主角。</p>
	                    <div class="textFrom">——网页 -《智能手机行业发展现状及未来趋势》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>(Automatic Speech Recognition,</em><em class='similar'>ASR)</em><em class='similar'>和自然语言理解</em><em class='similar'>(Natural Language Understanding,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>旨在平衡机器人与未知环境相互作用时的交互力和偏差;迭代更新的轨迹趋于围绕力场的轮廓,可用于实现触觉识别。第一章绪论1.2.2机器人语音交互研究状况语音交互系统技术主要包括语音识别<em class='similar'>(automatic speech recognition,</em><em class='similar'> ASR)、</em><em class='similar'>自然语言理解</em><em class='similar'>(natural language understanding,</em> NLU)、会话管理(dialog management, DM)、自然语言生成(natural language generation, NLG)、语音合成(text speech,TTS),</p>
	                    <div class="textFrom">——网页 -《基于学习算法的机器人触觉识别和语音交互的研究 - 豆丁网》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>不论是从提升使用便捷性的角度,还是从增强汽车企业行业竞争力的角度,语音交互⁞都需要深入学习研究。⁞目前,语音交互的主要技术包括语音识别<em class='similar'>(Automatic Speech Recognition,</em><em class='similar'>ASR)、</em><em class='similar'>自然语言理解</em><em class='similar'>(Natural Language Understanding,</em>NLU)、自然语言生成(Natural Language Generation,NLG)以及语音合成(Text To Speech,TTS)等⁞4种[6]。语音识别是将人类的声音信号转化为相应的文本或指令;</p>
	                    <div class="textFrom">——信息与电脑(理论版) 刘威；张森；宋冠谕；丁晓雯-《基于多种机器学习算法的车载语音文本分类研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>然而,<em class='similar'>高精度的深度学习模型需要消耗庞大的计算资源才能快速运行。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>多是集中于离线的情感识别研究,在已有的数据集中进行模型的训练[61,62]。但是在情感识别应用中,需要对用户实时上传的数据进行分析处理,<em class='similar'>并进行快速识别。</em><em class='similar'>由于深度学习模型的高精度需求往往需要大量计算,</em><em class='similar'>会引发对计算资源的大量消耗,</em>因此基于深度学习的情感识别模型通常部署在远程云计算中心,而不是客户端。在实时预测任务中,客户端通过移动设备将数据发送到远程云计算数据中心,</p>
	                    <div class="textFrom">——重庆邮电大学硕士论文 韩小娟-《脑电情感识别中多特征融合与分类研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>001。⁞2.2.2配置 GPU 加速计算⁞由于 BEGAN 深度学习模型的训练过程是对权重进行调优的过程,网络中的每个神经元的连接权重都要经过数值计算得出,<em class='similar'>故训练 BEGAN 深度学习模型需要占用庞大的计算资源。</em>⁞配置 GPU 计算加速深度学习模型的收敛进程。相较于 CPU,GPU 拥有更多核心处理器与处理数据的晶体管,带宽更高,高度并行且多线程,</p>
	                    <div class="textFrom">——建筑结构学报 杜文风；王英奇；王辉；赵艳男；高博青；董石麟-《基于边界平衡生成对抗网络的十字板式节点新构形智能生成方法》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>模方式为高斯混合-隐马尔可夫模型</em><em class='similar'>(Gaussian Mixture Model-Hidden Markov Model,</em><em class='similar'>GMM-HMM)</em>,在上世纪末应用广泛[5];</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>动意图识别的方案,基于模式识别⁞与机器学习的方法,对此方案的运动模态尤其是模态之⁞间的切换进行了再定义,仅通过惯性传感器采集健侧运⁞动信息,<em class='similar'>在高斯混合-隐马尔可夫模型</em><em class='similar'>(Gaussian mixture ⁞model-hidden Markov model ,</em><em class='similar'>GMM-HMM)</em>的基础上进行分⁞析和判断假肢的运动意图,从而实现下肢假肢运动意图⁞的识别。⁞第5期盛敏等:基于GMM-HMM模型的智能下肢假肢运动意</p>
	                    <div class="textFrom">——仪器仪表学报 盛敏；刘双庆；王婕；苏本跃-《基于GMM-HMM模型的智能下肢假肢运动意图识别》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音模型训练过程、端点检测、与 D5000系统交互以及语音转文字的整⁞套流程进行了论述。实践结果表明,采用 DNN-HMM 的电力调度语音识别性能要显著优于传统语音识⁞别框架,<em class='similar'>即高斯混合-隐马尔可夫模型</em><em class='similar'>(gaussian mixture model - hidden markov model,</em><em class='similar'>GMM-HMM)</em>,采用⁞所提方法进行电力调度语音识别准确率达94.63%。基于所提方法开发的电力调度语音识别系统在某⁞区域电网调控中心的应用实例表明了所提方法的可行性与优良性。</p>
	                    <div class="textFrom">——湖北电力 窦建中；罗深增；金勇；李群山；杨超；杨绪升-《基于深度神经网络的电力调度语音识别研究及应用》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>随后由于出现了统计语言学,人们对机器识别人类语言又充满了希望。⁞其中,最具代表性的统计学方法是隐马尔科夫模型(Hidden Markov Model, HMM),例⁞如通信系统混合隐马尔科夫模型,<em class='similar'>高斯混合隐马尔科夫模型</em><em class='similar'>(Gaussian  Mixture⁞Model\Hidden Markov Model,</em><em class='similar'> GMM-HMM)</em>等。⁞长期以来,以 GMM-HMM 为主流的语音识别系统在语音识别领域占据主导地位,⁞其中,HMM 的作用是对语音临时变量进行处理,</p>
	                    <div class="textFrom">——华南理工大学硕士论文 李莹莹-《基于深度学习的工业机械手语音控制方法研究》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>Hinton等人首次将深度信念网络</em><em class='similar'>(Deep Belief Network,</em><em class='similar'>DBN)</em>应用于声学建模并提出了深度信念网络-隐马尔可夫模型<em class='similar'>(DBN-HMM)</em>[6],在 TIMIT 的核心测试集上达到了23.</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>ding; Kaldi; Sub-sampling ⁞1引言⁞声学模型在语音识别中占有重要作用,特别是神经网络模型的出现,提高了声学模型的质量。⁞2009年,<em class='similar'>Hinton 等人将深度信念网络 DBN</em><em class='similar'>(Deep Belief Network)</em>应用于语音的声学建模中,在声学-音素连续语音语料库 TIMIT(The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus)等英⁞文语料集上获得了当时比较好的结果[1]</p>
	                    <div class="textFrom">——福建电脑 孔玲军-《TDNN模型对电话录音场景的识别研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>台湾大学的Yuan-Pin Lin采用SVM将EEG的情感状态分四为类,验证了⁞大脑的额叶和颞叶是情感的主要识别区域,并且情感的平均分类精确度为⁞82.29%[35]。<em class='similar'>Martin等人应用深度信念网络</em><em class='similar'>(DBN)</em>和隐马尔可夫模型<em class='similar'>(HMM),</em>采用⁞多模态情感识别的方法取得了比传统的特征分类更好地结果[36】。Li等人提出了一⁞种基于深度神经网络的EEG信号情感状态识别模型,分类效果提高了11.5%至⁞</p>
	                    <div class="textFrom">——合肥工业大学硕士论文 陈占刚-《基于深度神经网络的脑电情感识别研究》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>进入到以深度神经网络-隐马尔可夫模型</em><em class='similar'>(Deep Neural Network-Hidden Markov Model,</em><em class='similar'>DNN-HMM)</em>为主要方法的第二阶段;</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>具有重要研究意义。⁞1.2研究现状⁞语音识别的发展按照时间顺序可以分为三个主要阶段:第一个阶段是以GMM-HMM框架为代表的时代,该框架在当时得到了广泛的应用[8,9]<em class='similar'>。第二个阶段是深度神经网络-隐马尔可夫模型</em><em class='similar'>(Deep Neural Network- Hidden Markov Model,</em><em class='similar'> DNN-HMM)</em>的时代[10]。上世纪提出的GMM-HMM框架被沿用了相当长一段时间,同时也暴露出模型泛化能力差、建模流程冗长等难以解决的问题。因此,研究者们当时的研究内容聚焦于对该框架的改进</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>文献[10]从降低噪音角度出发,提出了一个基于 DNN 的联合训练语音识别模型,前端使用 DNN 进行特征映射降低噪音,<em class='similar'>后端使用深度神经网络-隐马尔可夫模型</em><em class='similar'>( Deep Neural Network-Hidden Markov Model,</em><em class='similar'>DNN-HMM)</em>作为声学模型,将前端特征映射的DNN与后端声学模型的DNN调参过程相结合,即识别的误差会对特征映射部分 DNN 的参数产生影响,在训练集含噪语音信噪比为10-15dB,</p>
	                    <div class="textFrom">——网页 -《多噪音环境下的语音识别技术研究_曹晶晶 - 道客巴巴》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>直接且具有较强的通用性,</em><em class='similar'>能够减少研究人员对于语音、</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>而是直接使用各种神经网络对带标签的语音数据进行拟合。端到端方法解决的是输入序列长度远大于输出序列长度的问题,与传统方法相比,面向端到端的语音识别更加简洁,<em class='similar'>具有较强通用性,</em><em class='similar'>能够减少对专业语音、</em>语言知识的依赖,大大降低了系统搭建难度。其总体上可以分为两类:一类是基于联结时序分类(Connectionist Temporal Classfication, CTC)[16]的端到端模型,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>大大降低了模型的建模难度。</em><em class='similar'>基于 E2E 的 ASR模型总体上可分为两类:</em><em class='similar'>一类是基于联结时序分类</em><em class='similar'>(Connectionist Temporal</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>长度远大于输出序列长度的问题,与传统方法相比,面向端到端的语音识别更加简洁,具有较强通用性,能够减少对专业语音、语言知识的依赖,<em class='similar'>大大降低了系统搭建难度。</em><em class='similar'>其总体上可以分为两类:</em><em class='similar'>一类是基于联结时序分类</em><em class='similar'>(Connectionist Temporal Classfication,</em> CTC)[16]的端到端模型,CTC模型不需要像传统方法那样对语音数据预先进行对齐操作,只需根据输出序列和真实序列的损失在训练的过程中自动进行对齐。另一类是以编码器</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>些同时基于回归和分割的混合方法[7],综合了两类方法的优点,是目前的研究热点之一。⁞哈尔滨工业大学工学硕士学位论文⁞基于深度学习的场景文本识别方法也大致<em class='similar'>可以分为两类</em>:<em class='similar'>基于联结时序分类</em>[8]⁞(<em class='similar'>Connectionist Temporal Classiﬁcation,</em>CTC)损失的方法[9]与基于注意力机制的方⁞法[10]。由于自然场景中存在大量的弯曲文本行,为了解决该类不规则文本行的识⁞</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 张文强-《基于光流校正的端到端场景文本识别方法的研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong>Classification,CTC)[8]<em class='similar'>的 E2E 模型,</em><em class='similar'>另一类是基于注意力机制</em><em class='similar'>(Attention)</em><em class='similar'>的序列到序列</em><em class='similar'>(Sequence-to-Sequence,</em>S2S)<em class='similar'>模型</em>[9],二者模型结构如图1-1所示。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>这种方法虽然可以生成同义句,但是需要大量的人工成本构建同义词典,并且生成的同义句效果并不理想。[0003]近年来,随着深度神经网络的发展,基于端到端机器学习方法的模型开始应用于同义句生成,<em class='similar'>模型主要依靠基于注意力机制</em><em class='similar'>(attention)</em><em class='similar'>的序列到序列</em><em class='similar'>(sequence to sequence)</em>学习框架,相比于在传统基于规则的方法上,其生成效果有非常显著的提升。具体而言,该学习框架包含一个编码器和解码器,编码器对输入文本进行处理得到一个文本的编码</p>
	                    <div class="textFrom">——网页 -《一种同义句生成方法、系统、终端及存储介质与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>要有两种:一种是 DNN 与 HMM 结合的混合语音识别模型,其中 DNN 用于计算每个 HMM 状态的后验概率;另一种是端到端的语音识别模型,其主要有两类:一类是连接时序分类(Connectionist Temporal Classification, CTC)[28]<em class='similar'>模型,</em><em class='similar'>另一类是基于注意力</em><em class='similar'>(Attention)</em>机制的编码-解码⁞重庆邮电大学硕士学位论文第1章绪论4(Encoder-Decoder)<em class='similar'>模型</em>[29]。对于上述两种框架,循环神经网络都十分适用,</p>
	                    <div class="textFrom">——网页 -《基于循环神经网络的语音识别声学建模研究》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>任务中子问句生成方面的研究。本章通过从⁞文本到文本生成的神经网络方法来实现复合问句的子问句生成,介绍了相关⁞文本生成模型和相关技术,<em class='similar'>包括最基本的序列到序列</em><em class='similar'>(Sequence-to-Sequence)</em><em class='similar'>⁞模型、</em>注意力机制<em class='similar'>(Attention Mechanism)</em>、Pointer-Generator-Net 等,并提出⁞了本研究所采用的基于复合问句子问句生成任务特点来改进现有模型的方法,⁞以及提升生成的子问句质量的相关技术。最后,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 李威宇-《问答系统中复合问句分解技术研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>(Convolutional Neural Network,</em><em class='similar'>CNN)</em><em class='similar'>或循环神经网络</em><em class='similar'>(Recurrent Neural</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>小于对应的第一超分视频子图像的像素密度。像素密度,即每英寸屏幕所拥有的像素数,像素密度越大,所显示的画面细节就越丰富。77.而简单超分网络可以是基于卷积神经网络<em class='similar'>(convolutional neural network,</em><em class='similar'>cnn)</em><em class='similar'>或循环神经网络</em><em class='similar'>(recurrent neural network,</em>rnn)构建的神经网络,简单超分网络至少包括输入层、输出层和隐藏层,隐藏层包括多个普通的卷积层和一个亚像素卷积层。通过多个普通的卷积层提取该待处理视频</p>
	                    <div class="textFrom">——网页 -《一种视频超分辨率的方法及装置与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>工特性或内核[1-4]。而近年来,深度学习方法被广泛应用于关系分类任务,它能够在保证准确率的前提下大幅减少人为调整的工作。如今有许多基于深度学习的神经网络模型用于该任务,如卷积神经网络<em class='similar'>(Convolutional Neural Network,</em><em class='similar'> CNN),</em><em class='similar'>循环神经网络</em><em class='similar'>(Recurrent Neural Network,</em> RNN),它们有些使用最短依赖路径或依赖子树[5-7],而另一些则减少预训练的操作,直接输入原始语句来学习隐含特征[8-9]。这些方法都已被证明有效,但它们会平等地考虑句中每个词,</p>
	                    <div class="textFrom">——网页 -《基于注意力与神经图灵机的语义关系抽取模型_张润岩 - ...》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>COmPUtationalnetWOrk, CN ),它是一种描述任意学习机的整合框架,比如深度神经网络(deep neural network, DNN )、卷积神经网络<em class='similar'>(convolutional neural network,</em><em class='similar'> CNN)、</em><em class='similar'>循环神经网络</em><em class='similar'>(recurrent neural network,</em> RNN )、长短时记忆≠Λ.(long short teπn memory, LSTM ∖逻辑回归和最大嫡模型等O 一个CN是一个有向图,</p>
	                    <div class="textFrom">——北京：电子工业出版社,2016.07 （美）俞栋，（美）邓力著-《解析深度学习语音识别实践》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>13.</strong><em class='similar'>并且能刻画语音特征序列和音素</em><em class='similar'>(字符)</em>序列的相关程度。<em class='similar'>2006年 Graves 等人利用空白字符对不同长度的序列进行对齐,</em><em class='similar'>首次提出 CTC 模型来解决 MINIST 数据集上的手</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>更新模型参数⁞特征序列⁞RNN CTC ⁞音素<em class='similar'>(字符)</em>序列⁞特征序列编码网络注意力网络⁞解码网络⁞音素<em class='similar'>(字符)</em>序列(a) CTC 模型(b)注意力模型⁞哈尔滨工业大学工学硕士学位论文⁞-6-⁞⁞对于 CTC 的研究,2006年 Alex Graves 利用空白(Blank)<em class='similar'>字符对不同长度的序列进行对齐,</em><em class='similar'>首次提出 CTC 模型来解决 MINIST 手写数字识别和 TIMIT语料库音素分类的问题。</em>该模型利用 RNN 挖掘输入序列的时序信息,摆脱了⁞HMM 传统模型,同时也取得较好的效果[30]。2012年 Alex 对 CTC 的语音识别⁞模型进一步改进,将 RNN 作为转化模型。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>另一种是采用基于注意力机制&quot;编码-解码&quot;模⁞型。⁞CTC[23]是一种能在无先验对齐信息的条件下衡量输入序列和目标输出序列相似度的⁞算法,<em class='similar'>将应用在为端到端语音识别系统就能够刻画语音特征序列和音素序列的关联性。</em>基⁞于 CTC 的语音识别系统由 RNN 和 CTC 损失函数计算层组成。识别过程中,模型使用 RNN⁞计算每帧特征计算属于各个音素后验概率。基于 CTC 的模型假设网络输出的帧与帧之间⁞</p>
	                    <div class="textFrom">——战略支援部队信息工程大学硕士论文 龙星延-《基于注意力机制的端到端语音识别技术研究》-2018 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>14.</strong><em class='similar'>2013年,</em><em class='similar'>Graves 等人利用多层长短时记忆</em><em class='similar'>(Long Short-Term Memory,</em><em class='similar'>LSTM)</em><em class='similar'>神经网络进行建模,</em><em class='similar'>进一步提升了模型在 TIMIT 语料库上的识别效果,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>数据集上取得比 DNN-HMM 更好的效果[31]。Zweig 还尝试在⁞CTC 模型之后加入不同的语言模型,发现语言模型对识别效果有较大的影响⁞<em class='similar'>[32]。2013年,</em><em class='similar'>Alex 利用多层的长短时记忆</em><em class='similar'>(Long Short-Term Memory,</em><em class='similar'> LSTM)</em><em class='similar'>神⁞经网络进行建模,</em><em class='similar'>进一步提升 TIMIT 语料库上的识别效果</em>[33]。与此同时,产⁞业界也陆续开始对 CTC 进行研究。2015年,百度提出基于 CTC 的语音识别系统——DeepSpeech,使用长达10000小时的训练数据,将英语广播语音语料⁞集的错误率降至10%,并对说话人、</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>15.</strong><em class='similar'>基于 Attention的 S2S 模型于2013年由 Graves 首次提出,</em><em class='similar'>并被用于 MINIST 数据集的手写数字识别任务中</em>[13]。在此基础上,Bahdanau </p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>采用解码算法可以产生音素序列。注意力模型在识别过程中既不需要每⁞一帧的强制对齐,也不需要帧的独立假设。<em class='similar'>⁞对于注意力模型,</em><em class='similar'>它是2013年由 Alex Graves 首次提出,</em><em class='similar'>并应用于 MINIST⁞数据集的手写数字识别任务中</em>[38]。2014年 Bahdanau 进一步完善,提出基于注⁞哈尔滨工业大学工学硕士学位论文⁞-7-⁞⁞意力机制的编解码模型,并将其应用于机器翻译中[36]。同年,Bahdanau 还将注意力模型进一步应用于语音识别任务中,</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>M)在翻译过程中能够让不同字符文本自动进行对齐。语音识别任务可以类比为机器翻译任务,识别过程可以视为将语音特征序列翻译成字符序列,因此序列到序列模型能够应用于语音识别中[28]。该模型由J.<em class='similar'> K.</em><em class='similar'> Chorowski等人于2013年首次提出,</em><em class='similar'>在MINIST数据集的手写数字识别任务中显示出一定的效果。</em>2014年,D. Bahdanau等人提出了基于注意力机制的&quot;编码器-解码器&quot;框架(Encoder-Decoder Structure, EDS),进一步完善了该模型[29]。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>16.</strong><em class='similar'>因而相较于 RNN 等结构,</em><em class='similar'>其训练效率高,</em><em class='similar'>模型收敛效果好</em>[18];<em class='similar'>在对注意力机制</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并使用Transformer对特征序列和标签序列进行序列化建模,完成了全部建模流程的端到端化,也实现了错误率的大幅降低。由于Transformer模型采用全连接网络,<em class='similar'>因而相较于RNN等结构,</em><em class='similar'>其训练效率高,</em><em class='similar'>模型收敛效果好</em><em class='similar'>[33]。⁞在对注意力机制的改进方面,</em>文献[34]通过在注意力得分计算过程中引入窗函数,剔除了无效的注意力得分,大幅提高了中文语音识别系统的识别性能。文献[35]等人设计了一种混合注意力机制,可以在共享的嵌入空间中同时学习不同级别的</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>17.</strong><em class='similar'>意力机制对注意力范围进行约束,</em><em class='similar'>同时考虑最大注意力得分并采用启发式搜索的方式对模型进行训练,</em>在 SwitchBoard 数</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Chan 等在计算注意力模型的注意力得分时也引入窗函数,应用于⁞在线中文的识别,其识别性能取得大幅度提高[45]。<em class='similar'>Merboldt 等提出局部注意力机制,</em><em class='similar'>对其添加约束,</em><em class='similar'>同时还考虑最大注意力得分,</em><em class='similar'>之后采用启发式搜索对模型进行训练,</em>最终在 SwitchBoard 和 LibriSpeech 数据集上取得较好的效果[46]。Shan 在注意力模型中加入二范正则项和高斯噪声来增加模型的鲁棒性,同时还采用跳帧技术进一步提高模型的训练速度。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 唐海桃-《基于自适应学习和多尺度前向注意力的语音识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>18.</strong><em class='similar'>存在参数量庞大、</em><em class='similar'>计算复杂、</em><em class='similar'>难以部署等缺点。</em>例如,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>后者是未来重要的研究方向。基于注意力机制的序列到序列模型虽然对全局信息的捕获能力十分优秀,但对于同样重要的局部信息的捕获能力却稍显不足。同时,<em class='similar'>其还存在模型参数量庞大,</em><em class='similar'>计算复杂等缺点。</em>比如,文献[38]等人使用双向Transformer解码器进行解码,模型参数量达到了2.2亿;Google公司提出的Conformer参数量也达到了1.2亿[39]。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>19.</strong><em class='similar'>出的 Conformer 模型参数量达到了1.19亿</em>[21]。<em class='similar'>这些因素为其在实际工程中的应用带来了巨大的挑战。</em><em class='similar'>因此,</em><em class='similar'>如何降低模型的参数量和计算复杂度、</em>提高模型运行速度,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>部信息的捕获能力却稍显不足。同时,<em class='similar'>其还存在模型参数量庞大,</em><em class='similar'>计算复杂等缺点。</em>比如,文献[38]等人使用双向Transformer解码器进行解码,<em class='similar'>模型参数量达到了2.2亿;</em>Google公司提出的Conformer参数量也达到了1.2亿[39]。<em class='similar'>这些因素为其在实际工程中的应用带来了巨大的挑战。</em><em class='similar'>因此,</em>如何加强其局部信息捕获能力和实现模型的轻量化是亟待解决的问题,也是学术界当前研究的热点。⁞1.3论文研究内容⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>手机或者智能手表等嵌入式的设备上的需求越来越大。但是嵌入式设备的存储容量以及电池容量十分有限,因此导致庞大的深度模型难以在嵌入式设备上对特定任务进行推理预测。<em class='similar'>因此,</em><em class='similar'>如何降低深度卷积神经网络的模型参数量以及计算复杂度,</em>成为了将其部署在嵌入式的移动端上的关键。4.针对卷积神经网络的参数多、计算量大的问题,已有一些模型的加速压缩方法被提出。其中就包括卷积核剪枝方法。</p>
	                    <div class="textFrom">——网页 -《卷积神经网络压缩方法和装置、图像分类方法和装置与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>经过网络中的各种卷积,激活等计算,每经过一个卷积层都会需⁞要大量的权重参数去存储和计算,这无疑会增加模型的计算复杂度和对模型内存提出⁞较高的要求。<em class='similar'>如何降低模型的参数量与减小模型的计算复杂度,</em>也是近年来研究者们⁞所研究的方向。深度可分离卷积(Depthwise Separable Convolution)[43]最早被 Andrew⁞G. Howard 所提出,并成功应用在了轻量化模型 </p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 陈聪-《基于深层网络的城市街道场景的语义分割的方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>20.</strong><em class='similar'>Detection,</em>ID)<em class='similar'>和槽位填充</em><em class='similar'>(Slot Filling,</em>SF)<em class='similar'>两个子任务,</em>前者属于文本分类领域,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>三个相互独立的模块。下面分别介绍它们在目前的研究现状。⁞(一)自然语言理解⁞自然语言理解模块主要包括领域识别<em class='similar'>(domain detection)</em>、意图识别<em class='similar'>(intent⁞detection)</em><em class='similar'>和槽位填充</em><em class='similar'>(slot filling)</em><em class='similar'>等三个子任务,</em>因为前两者均属于多分类问题,⁞故后续只介绍意图识别子任务的研究现状,而槽位填充可以转换为序列标注问题。以⁞下分别介绍目前在意图识别任务和槽位填充任务的研究现状。⁞</p>
	                    <div class="textFrom">——华南理工大学硕士论文 贾志豪-《基于端对端方法的任务型对话系统设计与实现》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>21.</strong><em class='similar'>了两个子任务之间的相关性;</em><em class='similar'>Liu 等人提出了一种新型的协同记忆网络</em><em class='similar'>(CM-Net)</em>,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>为意图识别和槽填充任务提供一个双向关联机制。Zhang C 等人[32]成功实现一个动态路由的胶囊网络(Cappule-NLU)<em class='similar'>,同时考虑两个任务之间的层次关系和相互关联关系。</em>Liu Y等人[33]<em class='similar'>采用一种新的协同记忆网络</em><em class='similar'>(CM-Net)</em>完成意图识别和槽填充的显式联合训练。Zhang L 等人[34]探索了结合图结构的长短期记忆网络,将其用于意图识别和槽填充。⁞隐式联合训练模型通过共享编码器的隐藏状态实现两个任</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 肖泳利-《面向智能个人助理的用户多意图识别方法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>22.</strong><em class='similar'>隐藏单元数为768、</em><em class='similar'>注意力头数为12,</em><em class='similar'>总参数量达到1.1亿,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>4.3.2模型参数设置⁞本文提出的模型采用预训练语言模型 BERT 的基础版本BERTbase作为编码器,在目标任务上进行微调学⁞习。 BERTbase包含12层的 Transformer模块,<em class='similar'>隐层单元数为768,</em><em class='similar'>自注意力头数量为12个,</em><em class='similar'>总参数量</em>为110M。⁞具体来说,模型的实现基于 Transformers③,一个开源的预训练语言模型框架。实验中采用的具体超参数如表2所示。其中,模型输入的最大序列长度设置为256,</p>
	                    <div class="textFrom">——山东大学学报（理学版） 鲍亮；陈志豪；陈文章；叶锴；廖祥文-《基于双重多路注意力匹配的观点型阅读理解》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>在句子分类和问答等相关任务中有良好的表现。⁞仓仓⁞根据参数规模的不同,BERT模型可以分为BERTLn,.ge和BERTBnsP。BERTL吖9。包含24层Transformer,1024个隐藏单元数,16个注意力头数,总参⁞数量约3.4亿。BERTB口。P包含12层Transformer,<em class='similar'>768个隐藏单元数,</em><em class='similar'>12个注意力头数,</em><em class='similar'>总参数量约1.1亿。</em>针对中文任务,有BERTunse—ch妇se模型。⁞厂——、⁞I[SEP]I⁞I.一⁞句子1句子2⁞图2.4 BERT模型结构图⁞(2)ERNIE⁞ERNIE模型在BERT的基础上,</p>
	                    <div class="textFrom">——郑州大学硕士论文 蔡林坤-《基于非平衡电子病历数据集的智能诊断研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>23.</strong><em class='similar'>论文共分为6个章节,</em>组织结构如图1-3所示,<em class='similar'>各章节安排如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>关键技术是对数据库的检索、查看标注等。⁞3)服务平台与标注工具之间的通信。关键技术是标注工具如何取得用户在平⁞台的登陆或注销信息,以满足标注工具标注时与用户信息挂接。<em class='similar'>⁞1.4论文组织结构⁞文章共分为6个章节,</em><em class='similar'>各章节安排如下:</em>⁞第一章,主要介绍了课题的研究背景及意义、矶陌b页面标注及国内外研究现状⁞并对论文的主要内容与关键技术做了简要的概括。⁞第二章,主要介绍了本研究课题所运用到的相关理论与技</p>
	                    <div class="textFrom">——华中师范大学硕士论文 李新-《页面标注系统的设计与实现》-2007 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>计与实现考试系统的W eb 服务模型;数据库的搭建主要运用S Q L S erv er2000作为系统数据服务器:浏览器采用IE6,0版本;以IIS5.1作为系统W eb服务器。<em class='similar'>1.5论文组织结构文章共分为6个章节,</em><em class='similar'>各章节安排如下:</em>第一章,主要介绍了本课题的研究背景,网络考试系统的研究现状,论文的研究意义及研究的主要内容。第二章,主要介绍了本研究课题所运用到的相关理论、技术、</p>
	                    <div class="textFrom">——网页 -《网络考试系统及Web服务设计与实现 - 道客巴巴》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>24.</strong><em class='similar'>最后通过一系列对比实验和消融实验论证所提模型的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其中,分别讲解了 Siamese网络的整体架构,ESIM网络的整体⁞架构及计算公式,本文评分模型的整体架构、计算公式和训练流程;⁞(3)<em class='similar'>最后,</em><em class='similar'>通过多组对比实验和消融实验论证了本文提出的基于 Siamese和 ESIM网络的中文主观题自动评分模型的有效性。</em>其中,对比实验主要说明了本文自动评分模型在定义类学生答案、顺序类学生答案和一般类学生答案三个数据集上的准确率、F1值、</p>
	                    <div class="textFrom">——广西师范大学硕士论文 龚云-《基于单字级深度神经网络的中文主观题自动评分研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>是引入图像增强的EIRCNN水下图像目标检测算法部分。结合第三章提出的IRCNN和第四章提出的三种水下图像增强算法,本章将三个水下图像增强算法与IRCNN结合提出了EIRCNN算法,并与其他检测方法进行对比实验,<em class='similar'>最后还通过消融实验论证各个增强模块的有效性,</em>最终证明了EIRCNN 对海洋生物的检测精度有显著提升。⁞第六章是引入图像增强的ESSD水下图像目标算法部分。本章在SSD算法中引入第四章提出的三种水下图像增强算法进行实验,最终证明了针对水</p>
	                    <div class="textFrom">——杭州电子科技大学硕士论文 方笑海-《基于深度神经网络的水下目标图像识别算法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>25.</strong>高,<em class='similar'>最后通过一系列对比实验和消融实验论证所提模型的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>其中,分别讲解了 Siamese网络的整体架构,ESIM网络的整体⁞架构及计算公式,本文评分模型的整体架构、计算公式和训练流程;⁞(3)<em class='similar'>最后,</em><em class='similar'>通过多组对比实验和消融实验论证了本文提出的基于 Siamese和 ESIM网络的中文主观题自动评分模型的有效性。</em>其中,对比实验主要说明了本文自动评分模型在定义类学生答案、顺序类学生答案和一般类学生答案三个数据集上的准确率、F1值、</p>
	                    <div class="textFrom">——广西师范大学硕士论文 龚云-《基于单字级深度神经网络的中文主观题自动评分研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>26.</strong><em class='similar'>第6章,</em><em class='similar'>总结与展望。</em><em class='similar'>总结论文研究内容,</em><em class='similar'>并对后续研究工作做出展望。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>、安全控制机制三方面对试验数据管理技术做了进一步研究。第5章试验数据管理系统实现与应用实例:简要介绍了原型系统的开发过程,以及在国内多家企业中的应用状况。<em class='similar'>第6章全文总结与展望:</em><em class='similar'>对相关研究内容进行总结,</em><em class='similar'>并对以后的研究工作做出了展望。</em>本文的组织结构如下图1.1所示:第一章绪论第二章试验数据管理系统总体设计第三章试验过程管理第四章试验数据管理第五章系统实现与应用实例第六章全文总结与展望</p>
	                    <div class="textFrom">——网页 -《试验数据管理技术研究及其在航空领域的应用》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>子孔径拼接面形检测系统,并对口径100mm×150mm 的平面反射镜进行拼接测量,将测量结果与干涉仪全口径测量结果进行了对比,进一步验证了本文所提算法的有效性。<em class='similar'>⁞第6章总结与展望。</em><em class='similar'>总结本论文工作内容,</em><em class='similar'>并展望后续研究工作。</em>⁞2斜率重建算法⁞夏克-哈特曼波前传感器采集的为斜率数据,需要通过斜率重建算法重建得到面形,⁞本章对现有斜率重建算法按其特点进行了分类总结,主要介绍了各类别下斜率重建算法的研究现状及常用重建算法原理。</p>
	                    <div class="textFrom">——西南科技大学硕士论文 孙琳-《大口径光学元件面形检测中子孔径拼接算法研究与应用》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第2章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_3" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人民邮电  深度学习原理与实践" target="_blank">人民邮电  深度学习原理与实践</a></span>
                      <p>陈仲铭，彭凌西著 -
                        《
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">14.9%(199字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的对话系统研究与应用" target="_blank">基于深度学习的对话系统研究与应用</a></span>
                      <p>赵新颜 -
                        《中国科学技术大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">10%(133字)</span></td>
                  <td class="bdrNo">是</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">7.2%(96字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于卷积神经网络的宫颈病变图像分类方法研究" target="_blank">基于卷积神经网络的宫颈病变图像分类方法研究</a></span>
                      <p>宋丹 -
                        《华侨大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.9%(65字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://www.doc88.com/p%2D7018723512940.html" target="_blank">基于深度学习的开放领域对话系统研究综述</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.7%(63字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://www.17winner.com/newsdetails.aspx?nid=2686" target="_blank">基于深度学习的开放领域对话系统研究综述 - SCI期刊论文 - 一起赢论文辅导网--专业代写代发SCI、EI、核心期刊、代写MBA、硕博毕业论文。TEL15327302358 QQ910330594</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.7%(63字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向任务的基于深度学习的多轮对话系统与技术" target="_blank">面向任务的基于深度学习的多轮对话系统与技术</a></span>
                      <p>姚冬;李舟军;陈舒玮;季震;张锐;宋磊;蓝海波 -
                        《计算机科学
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=BP神经网络的改进及其用于手写数字识别的研究" target="_blank">BP神经网络的改进及其用于手写数字识别的研究</a></span>
                      <p>郑南宁;王龙;胡超;刘健勤 -
                        《西安交通大学学报
                        》- 1992 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向知识库和个性化的对话系统关键算法研究" target="_blank">面向知识库和个性化的对话系统关键算法研究</a></span>
                      <p>孟园 -
                        《电子科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识感知与推理的生成式对话研究与应用" target="_blank">基于知识感知与推理的生成式对话研究与应用</a></span>
                      <p>王健 -
                        《华南理工大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=空调智能客服系统的设计与实现" target="_blank">空调智能客服系统的设计与实现</a></span>
                      <p>丛旭 -
                        《山东大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://www.wanfangqikan.com/2016/jisuanjilw_0623/12912.html" target="_blank">计算智能在机械制造业中的应用研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的缺失多视图子空间聚类" target="_blank">基于深度学习的缺失多视图子空间聚类</a></span>
                      <p>叶泽慧 -
                        《华南理工大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于人脸识别的在线学习辅助检测系统设计与实现" target="_blank">基于人脸识别的在线学习辅助检测系统设计与实现</a></span>
                      <p>杜珏 -
                        《西南大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人工智能前沿技术丛书  计算智能导论" target="_blank">人工智能前沿技术丛书  计算智能导论</a></span>
                      <p>刘玉芳，张玮责任编辑;（中国）尚荣华，焦李成，刘芳 -
                        《
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度神经网络的视频个性化推荐系统研究" target="_blank">基于深度神经网络的视频个性化推荐系统研究</a></span>
                      <p>高睿 -
                        《深圳大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于PAD情感状态模型的对话生成研究" target="_blank">基于PAD情感状态模型的对话生成研究</a></span>
                      <p>刘磊 -
                        《华中师范大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于POCT的宫颈癌细胞图像识别研究" target="_blank">基于POCT的宫颈癌细胞图像识别研究</a></span>
                      <p>黄云奎 -
                        《大连理工大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://xueshu.baidu.com/s?wd=任务型对话系统新领域适应策略研究" target="_blank">任务型对话系统新领域适应策略研究</a></span>
                      <p>王晓露 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.7%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_3" class="simMore"><a href="javascript:$ShowMore(3);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>现有对话系统按照应用场景和目标的不同,</em><em class='similar'>主要可分为两类:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>经历半个多世纪的研究,人机对话系统已经取得了不少进展,在工业界也有了十分广泛的应用,为人类获取信息服务、完成特定任务提供了更多渠道。<em class='similar'>现有的对话系统根据其应用场景主要分为两类。</em>非任务型对话系统,通常对输入进行回应,以漫无目的的闲谈对主要对话方式,不需要完成特定任务,主要用于娱乐、陪伴等情感需求场景,如Weizenbaum创建的ELIZA对话系统口】,</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 王晓露-《任务型对话系统新领域适应策略研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>人机对话系统的相关研究,成为学术界和工业界都在关注的重要问题[1]。近年来,海量文本数据和深度学习技术共同推动了人机对话系统的发展,<em class='similar'>根据应用场景的不同</em>,<em class='similar'>人机对话系统主要可以分为两类:</em>闲聊式的开放域对话系统和面向服务的任务型对话系统[2]。在开放域对话系统上,微软亚洲研究院于2014年推出了小冰聊天机器人,它可以在微信群中和网友聊天对话,并且语气活泼可爱,</p>
	                    <div class="textFrom">——华南理工大学硕士论文 王健-《基于知识感知与推理的生成式对话研究与应用》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>任务驱动型和非任务驱动型[39]。<em class='similar'>前者主要用于辅助用户完成一些特定的任务,</em><em class='similar'>后者也可被称为开放域对话系统或聊天机器人,</em>主要用于与用户进行闲聊。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>人机对话系统主要分为两类:&quot;任务驱动型对话系统&quot;(Task-⁞driven Dialogue System)<em class='similar'>和&quot;开放域对话系统&quot;</em><em class='similar'>(或称为 Chatbot 和&quot;聊天机器人&quot;⁞等)</em><em class='similar'>。任务驱动型对话系统的主要用途在于辅助用户完成特定的任务,</em>例如:预定机⁞票,查找商品,预定餐厅等,具有直接的商业价值。而&quot;开放域对话系统&quot;聚焦于⁞在开放领域内的人机对话技术,它主要以闲聊的方式与人类交互,</p>
	                    <div class="textFrom">——华中师范大学硕士论文 刘磊-《基于PAD情感状态模型的对话生成研究》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>System)和&quot;开放域对话系统&quot;(Open-domainDialogSystem)(或称为&quot;聊天机器人&quot;⁞等)<em class='similar'>。任务驱动型对话系统的主要用途在于辅助用户完成特定的任务,</em>例如:预定机⁞票,查找商品,预定餐厅等,具有直接的商业价值。&quot;开放域对话系统&quot;是一种可以⁞和用户进行闲聊的系统。根据所用技术分类,<em class='similar'>&quot;开放域对话系统&quot;又可分为两类:</em>&quot;生⁞</p>
	                    <div class="textFrom">——华中师范大学硕士论文 刘磊-《基于PAD情感状态模型的对话生成研究》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>使得对话系统的构建变得昂⁞贵和耗时。此外,每个任务型对话系统都是为了完成某一特定任务进行设计和训练⁞的,所以导致该类对话系统难以向平行任务领域迁移。<em class='similar'>⁞开放域对话系统,</em><em class='similar'>又可称为聊天机器人</em>(Chatbot),其目标是与用户进行关于⁞任何话题的自由对话以满足用户的情感交流和社交归属感等需求。图1-1展示了一⁞个用户与聊天机器人的对话实例。目前流行的微软小冰(Microsoft </p>
	                    <div class="textFrom">——电子科技大学硕士论文 孟园-《面向知识库和个性化的对话系统关键算法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>此外,</em><em class='similar'>按照对话系统在给出确定的回复话语前需考虑的轮数还可以将其分为单轮对话系统和多轮对话系统。</em>前者简化了对话过程,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Task-oriented Dialogue System)两大类口习。另外,知识的使用作为对话系统中的关键一环,对前述两大类对话系统都至关重要。<em class='similar'>此外,</em><em class='similar'>按照对话系统在进行回复时考虑的轮数进行区分,</em><em class='similar'>可以将对话系统分为单轮对话系统和多轮对话系统。</em>单轮对话系统简化对话回复任务,只考虑最近一轮的用户输入,而不考虑历史对话信息。多轮对话系统需要综合考虑包括用户输入和系统回复在内的所有对话历史,是更复杂但符合人类对话逻辑的思路。</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 赵新颜-《基于深度学习的对话系统研究与应用》-2022 （是否引证：是）</div>
						<p class="paragraph"><strong>2.</strong>首先将其形式化描述为:在历史对话信息背景下,人将无领域限制的话语作为查询(也可称为消息或问题等)输入计算机,计算机返回对应的回复语句(也可称为响应或回答).以场景设置为标准,<em class='similar'>对话系统可以分为单轮对话系统和多轮对话系统.</em>单轮对话系统将对话问题简化,只考虑找到给定查询的回复.多轮对话系统需要综合考虑对话上下文(包括历史对话信息和查询),建立对话的长期依赖关系,给出更加符合对话逻辑的回复.</p>
	                    <div class="textFrom">——网页 -《基于深度学习的开放领域对话系统研究综述 - SCI期刊论文 - 一起赢论文辅导网--专业代写代发SCI、EI、核心期刊、代写MBA、硕博毕业论文。TEL15327302358 QQ910330594》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>能给出更加符合逻辑的回复话语。</em>值得注意的是,<em class='similar'>不管是闲聊对话系统还是任务驱动型对话系统都可以考虑单轮或多轮对话,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>只考虑最近一轮的用户输入,而不考虑历史对话信息。多轮对话系统需要综合考虑包括用户输入和系统回复在内的所有对话历史,<em class='similar'>是更复杂但符合人类对话逻辑的思路。</em><em class='similar'>不管是闲聊对话系统还是任务型对话系统在回复时均可以考虑单轮对话或多轮对话,</em>所以本文下面从闲聊对话系统、任务型对话系统和结合知识的对话系统这三个角度对对话系统的研究进行回顾。⁞闲聊对话系统⁞图2.1中文闲聊对话系统小冰的例子,</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 赵新颜-《基于深度学习的对话系统研究与应用》-2022 （是否引证：是）</div>
						<p class="paragraph"><strong>2.</strong>单轮对话系统将对话问题简化,只考虑找到给定查询的回复.多轮对话系统需要综合考虑对话上下文(包括历史对话信息和查询),建立对话的长期依赖关系,<em class='similar'>给出更加符合对话逻辑的回复.</em>假设狇表示作为查询的话语,狉表示回复话语,犮代表历史对话信息,(1)单轮对话:以狇为前提,得到语句狉作为回复;(2)多轮对话:在犮的背景下,以狇为前提,得到语句狉作为回复.表1给出中英文对话示例.</p>
	                    <div class="textFrom">——网页 -《基于深度学习的开放领域对话系统研究综述》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>基于深度学习的任务驱动型对话系统有两种构建方式:</em><em class='similar'>Pipeline</em>(流水线)<em class='similar'>方式和端到端方式</em>[41]。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>CC2018SharedTask4数据集上对自然语言理解的主流算法进行了实验验证和对比,并分析了槽填充和意图识别两个子任务的关系;最后总结全文.⁞2任务导向型对话系统的研究现状⁞目前,<em class='similar'>任务型对话系统的构建方式主要有两种:</em>多模块级联<em class='similar'>(Pipeline)</em><em class='similar'>的方法和端到端的方法.</em>基于模块间级联的任务型对话系统的设计雏形来自于 Young发表于2000年的论⁞文[3],通常包括语音识别(ASR)、自然语言理解(NLU)、对话⁞管理(DM)、</p>
	                    <div class="textFrom">——计算机科学 姚冬；李舟军；陈舒玮；季震；张锐；宋磊；蓝海波-《面向任务的基于深度学习的多轮对话系统与技术》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>主要包含自动语音识别、<em class='similar'>自然语言理解、</em><em class='similar'>对话状态跟踪、</em><em class='similar'>对话策略学习、</em><em class='similar'>自然语言生成和语音合成等6个模块。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>的形式帮助用户完成特定的任务,如商品咨询、售后服务等。近年来,越来越多的企业及国内外研究人员开始关注任务型对话系统。任务型对话系统包括<em class='similar'>自然语言理解</em>、<em class='similar'>对话状态跟踪、</em><em class='similar'>策略学习和自然语言生成四个模块。</em>自然语言理解模块将用户输入转换为结构化的形式,包括用户意图和语义槽信息,可以拆分为意图识别和槽填充两个问题;对话状态跟踪模块根据自然语言理解的结果更新对话状态;策略学习模块结合上文槽位</p>
	                    <div class="textFrom">——山东大学硕士论文 丛旭-《空调智能客服系统的设计与实现》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>按照输入—输出顺序分别为<em class='similar'>输入层</em>、<em class='similar'>隐藏层和输出层,</em><em class='similar'>前一层的每个神经元会向后一层中所有与之相连的神经元传递信号,</em><em class='similar'>如图2-2所示。</em><em class='similar'>由于这些神经元都是全连接的,</em><em class='similar'>故前馈神经网络也被称为全连接神经网络。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>一个典型的三层前馈神经网络结构如图2.2所示。在前馈神经网络中,数量众多的神经元按层组织,<em class='similar'>前一层的每个神经元会向下一层所有与之相连接的神经元传输信号。</em><em class='similar'>由于前层所有神经元和下层所有神经元都是&quot;全连接&quot;的,</em><em class='similar'>因此前馈神经网络也被称为全连接神经网络。</em>在该网络中,第一层通常也被称为输入层,最后一层被称为输出层。⁞⁞图2.2一个简单三层前馈神经网络⁞前馈神经网络通过式(2.4)进行信息的前向传播。⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>网络的输入可以是低级信号(Lowlevel滋gnal),如图像的像素或语音的幅值,也可以是高级信号(且ighlevelai肆班),如抽取的特征、网络中信号的传递是单向的,如图中箭头所示。<em class='similar'>同一层的神经元之间互不传递信号.</em><em class='similar'>每个神经元与低一层的所有神经元相连,</em>其连接的强度用权值叭,‘来表示,每个神经元的状态的激活函数定义为戌gmoid型函数,<em class='similar'>如图2所示,</em>即了(劣)二11十e一二(1)抢出层f(之)___二坦L____隐层+0.</p>
	                    <div class="textFrom">——西安交通大学学报 郑南宁；王龙；胡超；刘健勤-《BP神经网络的改进及其用于手写数字识别的研究》-1992 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>整个网络也能够正常的运转。人工神经网络按照连接方式的不同分为前馈式网络与反馈式网络,前馈式网络结构中的神经元是单层排列的,分<em class='similar'>为输入层</em>、<em class='similar'>隐藏层及输出层三层,</em><em class='similar'>信息的传播是单向的,</em><em class='similar'>每个神经元只与前一层的神经元相连,</em>即信息只能由输出层传向隐藏层再传向输入层,而不能由输出层直接传向输入层;反馈式网络结构中每个人工神经细胞都是一个计算单元,在接受信息输入的同时还在向外界输出着信息。</p>
	                    <div class="textFrom">——网页 -《计算智能在机械制造业中的应用研究》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>2、卷积神经网络⁞华南理工大学硕士学位论文⁞全连接网络(FCN)[67]是由多层神经元组成,也称多层感知器(MLP)。图2-1是一个三层的全连接网络,它由<em class='similar'>输入层</em>,<em class='similar'>隐藏层和输出层组成,</em><em class='similar'>其每一层的每个神经元都与上一层的每个神经元两两相连,</em>并且每个连接都有不同的权重。假设第𝑖个输入层和第𝑗个隐藏层之间的权重为𝑤𝑖𝑗,第𝑖个隐藏层和第𝑗个输出层之间的权重为𝑣𝑖𝑗,于是:⁞第𝑗个隐藏层的输入为:</p>
	                    <div class="textFrom">——华南理工大学硕士论文 叶泽慧-《基于深度学习的缺失多视图子空间聚类》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>织地连接在一起,形成多个层,每层有一个或者多个神经元,这样就组成了一个神经网络。以图2-2所示的一个基本三层神经网络结构为例,该网络包括一个<em class='similar'>输入层</em>,<em class='similar'>一个隐藏层和一个输出层,</em><em class='similar'>网络中每一层的神经元只与其相邻层的神经元相连,</em>同层或者跨层的神经元不相连,并且层与层之间的连接是单向的,网络间的信息向前传递,上一层的输出作为下一层的输入。在神经网络中,</p>
	                    <div class="textFrom">——西南大学硕士论文 杜珏-《基于人脸识别的在线学习辅助检测系统设计与实现》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>式中,表示当前层数;<em class='similar'>表示第层神经元的输出向量;</em><em class='similar'>表示第层到第层的权重矩阵;</em><em class='similar'>表示第层神经元的激活函数;</em><em class='similar'>表示第层的偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>也可以进一步理解反向传播算法的代码实现。⁞BP算法推导⁞(1)符号说明,⁞nl:表示网络的层数,仏为输入层,々为输出层。⁞5:<em class='similar'>表示第/层网络神经元的个数。</em>⁞/:<em class='similar'>表示神经元的激活函数。</em>⁞W(<em class='similar'>J表示第/层到第/+1层的权重矩阵,</em>其中w[wR表示从/层的第i个神经元到第7+1层第j个神经元之间的权重。⁞心:<em class='similar'>表示第/层的偏置向量,</em>其中叱)表示/层第,个神经元的偏置。⁞严:<em class='similar'>表示第/层的输入向量,</em>其中Z,为/层第,个神经元的输入。⁞。⑴:<em class='similar'>表示第/层的输出向量,</em>其中。,为/层第,个神经元的输出。⁞虽然上述符号定义有些琐碎,需要点时间去了解,但是对于后面的公式推导却起着很重要的作用。其中,/一般代表第/层神经网络,</p>
	                    <div class="textFrom">—— 陈仲铭，彭凌西著-《人民邮电  深度学习原理与实践》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>将⁞⁞7⁞⁞上一层的神经元激活值通过加权求和的方式结合起来,与偏置项相加,然后通过激活函数再进行计算。公式如下:()=(()∙()+)(2.1)其中()<em class='similar'>表示第层的输出向量,</em>()表示第−1层的输出向量。()<em class='similar'>表示第−1层神经元连接到第层神经元的权重矩阵,</em><em class='similar'>表示第层的偏置,</em>(∙)<em class='similar'>表示激活函数。</em>某一层的激活函数根据数据和任务的特征以及训练过程中的需要进行⁞选择,常见的激活函数如 ReLU 和 tanh。⁞当神经网络中网络的深度过深时,</p>
	                    <div class="textFrom">——华侨大学硕士论文 宋丹-《基于卷积神经网络的宫颈病变图像分类方法研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>并映射成两个低维的语义相关的特征向量。⁞最后根据余弦距离来计算用户与视频的相关性大小,以此作为推荐的评分依据。⁞此网络的具体描述如下:假设用表示输入向量,<em class='similar'>表示输出向量,</em><em class='similar'>表示神经⁞网络中的隐含层表示网络中第层的权重矩阵,</em><em class='similar'>表示第层⁞的偏置。</em>则有以下公式:⁞(3-4)⁞(3-5)⁞(3-6)⁞其中,<em class='similar'>表示激活函数,</em>在本文中用作为隐藏层和输出层的激活函数。</p>
	                    <div class="textFrom">——深圳大学硕士论文 高睿-《基于深度神经网络的视频个性化推荐系统研究》-2017 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>乃,yι),(亚,?2),.・・,(Im »» ZieR&quot;, yi ∈Rz,输入样本有d⁞个属性描述,输出/维实向量。其他各个符号的表示含义如下:⁞L:神经网络的层数;⁞nz:第2层神经元的个数;⁞/(•):,<em class='similar'>层神经元的激活函数;</em><em class='similar'>⁞W1i 2-1层到第Z层的权重矩阵;</em>⁞bl : L —1层到,层的偏置值;⁞zz:第Z层神经元的加权输入;<em class='similar'>⁞第/层神经元的输出。</em>⁞1)前向传播⁞前向传播简而言之就是从输入层开始,信号输入神经元,</p>
	                    <div class="textFrom">—— 刘玉芳，张玮责任编辑；（中国）尚荣华，焦李成，刘芳-《人工智能前沿技术丛书  计算智能导论》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>前向传播公式如式(4.5)所示:⁞第一层⁞第二层⁞第三层⁞图4.15前向传播过程⁞Fig.4.15 Forward dissemination process ⁞(4.5)<em class='similar'>⁞其中代表层数,</em><em class='similar'>代表第层神经元,</em><em class='similar'>代表第层</em>神经元,为偏置,为激活函数的输出。⁞反向传播是指通过输出与理想结果的差异从后逐渐反馈到前面,从而对权值更新的⁞一个过程。所图4.16所示为反向传播过程,公式如式(4.6)所示:⁞</p>
	                    <div class="textFrom">——大连理工大学硕士论文 黄云奎-《基于POCT的宫颈癌细胞图像识别研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_4" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">21.4%(255字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于早期烟雾图像多特征融合的火灾检测" target="_blank">基于早期烟雾图像多特征融合的火灾检测</a></span>
                      <p>周敏瑞 -
                        《武汉工程大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.1%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于卷积神经网络的机械故障诊断域自适应算法研究" target="_blank">基于卷积神经网络的机械故障诊断域自适应算法研究</a></span>
                      <p>朱智宇 -
                        《哈尔滨工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">3.9%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=加速MATLAB编程指南CUDA实现" target="_blank">加速MATLAB编程指南CUDA实现</a></span>
                      <p>赵地著 -
                        《
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Skip-LSTM的机场群延误预测方法研究" target="_blank">基于Skip-LSTM的机场群延误预测方法研究</a></span>
                      <p>渠星 -
                        《中国民航大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110670786_2.html" target="_blank">考虑秒级时间序列风速变化的海上风电功率滚动预测方法与流程_2</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=降质服务攻击及其防范方法" target="_blank">降质服务攻击及其防范方法</a></span>
                      <p>何炎祥，刘陶编著 -
                        《北京：机械工业出版社,2011.06
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202010092547.html" target="_blank">一种安全带检测方法、装置及电子设备与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络混合模型的心率预测方法" target="_blank">基于神经网络混合模型的心率预测方法</a></span>
                      <p>李清濠 -
                        《湖南师范大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于文本纠正及注意力机制的不规则自然场景文本识别" target="_blank">基于文本纠正及注意力机制的不规则自然场景文本识别</a></span>
                      <p>林庆祥 -
                        《华南理工大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于线积分卷积算法的并行实现方法" target="_blank">基于线积分卷积算法的并行实现方法</a></span>
                      <p>冯冲;颜廷华 -
                        《计算机技术与发展
                        》- 2008 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能餐具分类回收系统研究" target="_blank">智能餐具分类回收系统研究</a></span>
                      <p>彭锋勇;孙尚舒;凌童心 -
                        《科学与财富
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(38字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的用户个性化推荐方法的设计" target="_blank">基于深度学习的用户个性化推荐方法的设计</a></span>
                      <p>曹迪 -
                        《河北科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=情感分析的分类算法研究" target="_blank">情感分析的分类算法研究</a></span>
                      <p>李根 -
                        《中原工学院硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202111189317.html" target="_blank">一种电子元器件组装检测方法及系统与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的年龄估计" target="_blank">基于深度学习的年龄估计</a></span>
                      <p>孟晓东 -
                        《西安电子科技大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向危险化学品的知识图谱构建研究" target="_blank">面向危险化学品的知识图谱构建研究</a></span>
                      <p>程钊 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于集成学习和位置指纹的室内定位算法研究" target="_blank">基于集成学习和位置指纹的室内定位算法研究</a></span>
                      <p>许晓杰 -
                        《黑龙江大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">19.</strong> <span><a href="http://xueshu.baidu.com/s?wd=融合多头注意力机制的网络恶意流量检测" target="_blank">融合多头注意力机制的网络恶意流量检测</a></span>
                      <p>赵忠斌;蔡满春;芦天亮 -
                        《数据与计算发展前沿
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">20.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的彩色图像质量评价" target="_blank">基于深度学习的彩色图像质量评价</a></span>
                      <p>李志娟 -
                        《内蒙古工业大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">21.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于LSTM的风机发电量预测研究" target="_blank">基于LSTM的风机发电量预测研究</a></span>
                      <p>刘凯 -
                        《兰州理工大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">22.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于去相关化的低秩矩阵分解对口语能力的评估方法" target="_blank">基于去相关化的低秩矩阵分解对口语能力的评估方法</a></span>
                      <p>林思岑 -
                        《微型电脑应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">23.</strong> <span><a href="https://blog.csdn.net/smilejiasmile/article/details/80952438" target="_blank">基于 循环神经网络 (LSTM) 的情感评论文本分类 - smilejiasmile的博客 - CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">24.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110663923.html" target="_blank">一种基于GCN的汉语复句隐式关系分析方法及装置与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">25.</strong> <span><a href="http://xueshu.baidu.com/s?wd=RHS-CNN:一种基于正则化层次Softmax的CNN文本分类模型" target="_blank">RHS-CNN:一种基于正则化层次Softmax的CNN文本分类模型</a></span>
                      <p>王勇;何养明;陈荟西;黎春 -
                        《重庆理工大学学报(自然科学)
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">26.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于视觉的两栖无人航行器目标检测及区域分割研究" target="_blank">基于视觉的两栖无人航行器目标检测及区域分割研究</a></span>
                      <p>叶浩 -
                        《江苏科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">27.</strong> <span><a href="http://xueshu.baidu.com/s?wd=深度学习系列深度学习与TensorFlow实战" target="_blank">深度学习系列深度学习与TensorFlow实战</a></span>
                      <p>李建军，王希铭，潘勉 -
                        《北京：人民邮电出版社,2018.08
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_4" class="simMore"><a href="javascript:$ShowMore(4);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>然后使用链式法则从输出层往输入层方向</em><em class='similar'>(反向)</em><em class='similar'>逐层求取各参数梯度,</em><em class='similar'>最后将学习率</em>(百分比,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>。目前最为常见的参数更新算法是反向传播(Back Propagation, BP)算法[42]。BP算法根据网络输出结果与参考结果的偏差得到损失函数的值,<em class='similar'>再使用链式法则从输出层方向往输入层方向逐层求取各层参数的梯度,</em><em class='similar'>最后利用学习率与求得梯度的乘积去更新原来的参数。</em>目前,Pytorch、TensorFlow等主流的深度学习框架都包含了自动梯度计算的功能,研究人员只需考虑如何用代码实现相关的网络结构,梯度的计算将交由这些框架自动进</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>这些步骤可以反复循环迭代,<em class='similar'>直至网络输出的误差减少到可接受的程度或达到设定的最大训练次数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>层,用于修正各隐层中每个神经元的⁞权重和阈值。网络的训练过程就是利用训练样本在信号正向传播与误差反向传播过程⁞中调整各层神经元的参数,不断循环,<em class='similar'>直至网络输出的误差减少到可接受的程度或达⁞到预先设定的训练次数为止。</em>⁞设有 L 层的前馈网络,前 L-1层是隐层。输入向量为(7)(8)T⁞12,,,,,i nX(28)x x (43)x (43)x ,输⁞出向量为(7)(8)T⁞12,,,,,j mO(28)</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 孟晓东-《基于深度学习的年龄估计》-2017 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>节各层的权值以减小偏差。此过程反复循环,<em class='similar'>直至训练样本真实输出与神经网络输出的误差在设定的范围内或者达到最大训练次数。</em>⁞在本章的检测系统中应用BP网络的一个重要因素是其具有超强的自适应、自学习能力,这为RoQ攻击检测模型提供了很大的灵活性。训练后的BP网络通过对以前观察到的入侵行</p>
	                    <div class="textFrom">——北京：机械工业出版社,2011.06 何炎祥，刘陶编著-《降质服务攻击及其防范方法》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>卷积神经网络</em>[45]<em class='similar'>是一种包含卷积操作的 FNN,</em><em class='similar'>一般包含卷积层、</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>而将内层循环转换为parfor循环产生多个parfor循环。因此,将外层循环转换为parfor循环的延迟(OVerhead)大于将内层循环转换为parfor 循环。⁞例如,<em class='similar'>在卷积神经网络前向传播</em>(forward PrOPagatiOn)<em class='similar'>的卷积层包含有卷积操作。</em>在进行卷积操作以前,程序员需要将所有的卷积核旋转90°。因为MATLAB的 rot90()函数只能够运行在二维的维度,对于多个卷积核而言,</p>
	                    <div class="textFrom">—— 赵地著-《加速MATLAB编程指南CUDA实现》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>它能对提取的特征进行有效的降维,</em><em class='similar'>从而减少模型的计算量。</em><em class='similar'>卷积核</em><em class='similar'>(卷积滤波器)</em>是CNN的关键部件,<em class='similar'>它是一个可定义权值的函数,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>更泛化的特征信息。模型采用高度h为2、3、4的3组卷积核(滑动窗口分别覆盖2、3、4个词语),每组卷积核20个。池化层:池化操作是对卷积特征进行再次筛选,<em class='similar'>提取出主要的特征,</em><em class='similar'>对特征向量进行降维,</em><em class='similar'>减少模型的计算量,</em>并提升模型的畸变容忍能力。通过池化操作,最终得到维数为卷积核总数的文本特征向量。输出层:即RH-Softmax,为整个模型的核心,其原理如3.3小节所示,把文本特征向量映射为类别概率,</p>
	                    <div class="textFrom">——重庆理工大学学报(自然科学) 王勇；何养明；陈荟西；黎春-《RHS-CNN:一种基于正则化层次Softmax的CNN文本分类模型》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>网络层的感受野较小,能够提取出图像的细节特征,而卷积层数相对较多的支路,⁞可以获得图像深层次的抽象信息。在支路中加入11卷积核,<em class='similar'>对提取的特征进行降维,</em><em class='similar'>⁞以减少模型的计算量,</em>缓解参数过多的问题。⁞输入⁞5×5×641×1×643×3×321×1×64⁞3×3×645×5×643×3×32⁞5×5×643×3×64 VGG⁞3×3×64⁞5×5×64⁞3×3×32⁞5×5×32⁞3×3×4⁞全连接⁞输出⁞图3-7多尺度特征提取模型⁞</p>
	                    <div class="textFrom">——内蒙古工业大学硕士论文 李志娟-《基于深度学习的彩色图像质量评价》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>从改变网络结构出发,训练小型化网络以减少计算参数,实现模型轻量化[63]。⁞MobileNet 基于训练的一种小型化网络的分类模型,通过深度可分离卷积和点卷积,<em class='similar'>能够减少模型计算量。</em><em class='similar'>对比标准的卷积把卷积核作滤波器,</em>对映射的特征层作为输出通道数,一次性完成卷积操作与通道数调整操作。MobileNet 形成新的特征形式,采用输入为 F FD D M,卷积核 K 大小为 K KD D M </p>
	                    <div class="textFrom">——江苏科技大学硕士论文 叶浩-《基于视觉的两栖无人航行器目标检测及区域分割研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>大大提高了计算速度。1LIC算法描述LIC算法是由Cabral和Leedom[2]提出的。用卷积来表示矢量场的方向源于一种运动模糊的思想。卷积是图像处理常用的方法,给定输入图像,在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均,<em class='similar'>其中权值由一个函数定义,</em>这个函数称为卷积核。LIC使用一维低通滤波器函数k()作为卷积核沿流线卷积白噪声图像,合成纹理。输出纹理的每个像素值均通过积分卷积得</p>
	                    <div class="textFrom">——计算机技术与发展 冯冲；颜廷华-《基于线积分卷积算法的并行实现方法》-2008 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>主要作用是将输入图像上某个区域中的每一个像素进行加权平均并作为输出图像中的对应像素。</em>一个简单的卷积操作如图2-3所示。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>b6⁞图4-5卷积神经网络示例⁞1)图像数据通过输入层进入卷积神经网络。⁞2)在1卷积层对输入的图像进行卷积计算取得特征图,以卷积核为𝑤1,偏置为𝑏1。其中,<em class='similar'>卷积核是在输入的图像中的一个小区域中的像素进行加权平均后输出图中每个对应像素,</em>以提取特征。卷积核深度依据卷积通道数的数量而变。⁞图4-6平均池化⁞3)将经过1卷积层的图像输入第一个池化层,</p>
	                    <div class="textFrom">——武汉工程大学硕士论文 周敏瑞-《基于早期烟雾图像多特征融合的火灾检测》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>其中,预设的图像分割模型包括预设的第一卷积核以及预设的第二卷积核。第一卷积核以及第二卷积核均是预先训练好的卷积核。该第一卷积核以及第二卷积核均为转置卷积核。卷积核是图像处理时,给定输入图像,<em class='similar'>输入图像中一个小区域中像素加权平均后成为输出图像中的每个对应的像素。</em>用于对目标区域图像中的像素加权平均后成为输出图像中的每个对应像素。对应的,第一卷积核是以目标区域图像为输入图像,并对目标区域图像中每个小区域中像素加权</p>
	                    <div class="textFrom">——网页 -《一种安全带检测方法、装置及电子设备与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>获得第一图像清晰度,则应获得图像信息的饱和度对其进行判断。所述卷积核特征提取是用来对图像进行处理的一种手段,在进行图像处理时,给定输入图像,<em class='similar'>输入图像中一个小区域中,</em><em class='similar'>像素加权平均后成为输出图像中的每个对应像素,</em>其中权值由一个函数定义,即卷积核。所述主体卷积特征是图像采集后对元件、连接件进行标记,对主体的图像进行处理,比如对其边缘进行强化等,</p>
	                    <div class="textFrom">——网页 -《一种电子元器件组装检测方法及系统与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>大大提高了计算速度。1LIC算法描述LIC算法是由Cabral和Leedom[2]提出的。用卷积来表示矢量场的方向源于一种运动模糊的思想。卷积是图像处理常用的方法,给定输入图像,<em class='similar'>在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均,</em>其中权值由一个函数定义,这个函数称为卷积核。LIC使用一维低通滤波器函数k()作为卷积核沿流线卷积白噪声图像,合成纹理。输出纹理的每个像素值均通过积分卷积得</p>
	                    <div class="textFrom">——计算机技术与发展 冯冲；颜廷华-《基于线积分卷积算法的并行实现方法》-2008 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>结构包括以下三种:⁞2.1.1卷积层⁞在卷积神经网络中,图片被表示成一个宽×高×通道的三维矩阵。卷积层由卷积核和图像映射组成。卷积核可以理解为处理图像时,给定输入图像,<em class='similar'>输入图像中一个小区域中像素加权平均后成为输出图像中的对应像素,</em>其中权值由卷积核定义,因此卷积核具有局部性。图像映射是一组与⁞特定图片相关的坐标。⁞卷积的目的是从输入图片中提取特征,因此保留着像素之间在空间上的关系。</p>
	                    <div class="textFrom">——科学与财富 彭锋勇；孙尚舒；凌童心-《智能餐具分类回收系统研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong>首先CNN通过将卷积核在输入图像(三通道)<em class='similar'>上按特定顺序移动,</em><em class='similar'>扫描视野范围内的像素信息来提取特征,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>现局部不变特征的提取。卷积神经网络中,卷积层中一个简单的卷积操作如图2.3所示。卷积滤波器又称为卷积核,它是一组可学习权值的集合,可视为参数量较少的一组全连接网络。<em class='similar'>卷积核通过在图片上按照特定的顺序移动,</em><em class='similar'>扫描视野范围内的图片信息进而提取特征。</em>每个卷积核提取得到的特征是尺寸更小的单通道图片,该图片也被称为特征图(Feature Map, FM)。再使用非线性激活函数对每张特征图进行处理,并对得到激活特征图按照顺序进行通道上的堆叠,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>将所有特征图转化为激活特征图;<em class='similar'>最后对激活特征图在通道维度上按顺序进行堆叠,</em><em class='similar'>从而得到卷积操作的输出结果。</em><em class='similar'>通过对卷积核数、</em><em class='similar'>尺寸等超参数进行合适的设置,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>扫描视野范围内的图片信息进而提取特征。每个卷积核提取得到的特征是尺寸更小的单通道图片,该图片也被称为特征图(Feature Map, FM)。再使用非线性激活函数对每张特征图进行处理,<em class='similar'>并对得到激活特征图按照顺序进行通道上的堆叠,</em><em class='similar'>即可得到卷积操作的输出结果。</em>在卷积神经网络中,在进行卷积操作后,通常还会使用池化操作对特征图进行裁剪,进一步压缩特征图的大小。<em class='similar'>通过对卷积核数、</em><em class='similar'>卷积核尺寸等超参数进行合适的设置,</em>可实现语音信号频谱图时间步压缩以及频域信息的扩展与丰富。⁞2.2.3循环神经网络及其变种⁞循环神经网络RNN[43]是一类用于处理时序相关输入序列的递归神经网络,其网络拓扑结构</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>果作为下一层的输入特征。通常一个卷积层会有多个卷积核,但是每个卷积核会单⁞独对输入信号进行卷积。由于同一层的卷积核大小相同,因此输出特征的大小相同。<em class='similar'>⁞不同卷积核的卷积结果在通道</em>(Channels)<em class='similar'>维度上进行堆叠得到特征图</em>(Feature⁞Maps)。每当通过一个卷积层,特征图尺寸变换计算公式如下:⁞1in⁞out⁞L K⁞L⁞S⁞?=+(2-1)⁞式中 inL ——输入尺寸。⁞outL ——输出尺寸。⁞K ——卷积核大小(Kernel Size)。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 朱智宇-《基于卷积神经网络的机械故障诊断域自适应算法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>循环神经网络[46]<em class='similar'>是一种擅于处理时间序列数据的人工神经网络,</em>其网络拓扑</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>+e(t)ꢀꢀꢀꢀꢀꢀꢀꢀ(6)式中:δp(t)为t时刻与t‑θ时刻海上风电功率的变化值;f2为海上风电功率差分序列的时间相关性函数;e(t)为t时刻的最小预测误差;步骤s22)建立滚动lstm神经网络模型:<em class='similar'>循环神经网络是人工神经网络的一种,</em><em class='similar'>循环神经网络善于处理时间序列数据,</em>可以在时间轴上描述数据前后关系,lstm是由hochreiter和schmidhuber作为循环神经网络的衍生而提出,lstm在循环神经网络隐藏层中添加多个特殊的计算节点,改善反向传播时梯度传递方式,</p>
	                    <div class="textFrom">——网页 -《考虑秒级时间序列风速变化的海上风电功率滚动预测方法与流程_2》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>准确率与合格率也也是两个重要评价指标,本课题的研⁞究结果将采用RMSE评价指标。基于 LSTM 的风机发电量预测研究⁞26⁞4.4 LSTM 网络原理与建模⁞4.4.1<em class='similar'> RNN 与 LSTM 网络⁞循环神经网络是人工神经网络的一种。</em><em class='similar'>RNN 善于处理时间序列数据,</em>可以在时间⁞轴上描述数据前后关系。Tensor Flow 所提供的 RNN 结构如图4.4所示。</p>
	                    <div class="textFrom">——兰州理工大学硕士论文 刘凯-《基于LSTM的风机发电量预测研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>刻的数据输入和前一时刻的隐藏状态两部分组成,</em><em class='similar'>产生当前时刻的隐藏状态和输出,</em>计算过</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>RNN只有一个隐藏状态ht,而LSTM隐藏层中除ht外,还具有单元状态Ct,用于控制心率序列数据长期信息的保存。LSTM具有三个输入,<em class='similar'>分别为上一时刻的隐藏状态ht-1、</em><em class='similar'>单元状态Ct-⁞1和当前时刻的心率数据输入xt,</em><em class='similar'>输出为当前时刻的单元状态Ct和隐藏状态ht。</em>LSTM拥有三个决定心率信息积累速度的&quot;门&quot;:遗忘门ft如式(2-7)所示,控制上一时刻单元状态Ct-1丢弃心率的无效信息,保留心率的关键信息;输入门it如式(2-8)所示,</p>
	                    <div class="textFrom">——湖南师范大学硕士论文 李清濠-《基于神经网络混合模型的心率预测方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>上式中,</em><em class='similar'>、和均为权重矩阵;</em><em class='similar'>和均为非线性激活函数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>过激活函数仍口拟合用户的短期兴趣即用户特征巴⁞和长期兴趣z得到输出值计&quot;,表示在t时刻用户&quot;与项目f产生交互行为的可能⁞性,计算公式如式(4.14)所示。⁞y c=仍口(Ⅳ’嘲+6,)⁞其中,b和6’表示偏置项,<em class='similar'>矽和W’为权重矩阵,</em><em class='similar'>尺口和仍Q为非线性激活函数。</em>⁞全连接网络模块如图4-4所示。⁞鬻———~⁞Z2.⁞溆誊》⁞震⁞;^1.⁞i谨⁞喾—//⁞输出⁞(4-14)⁞图4-4全连接网络图⁞得到全练连接层的输出之后,再对输出值分析得到预测每个项目的概率值p,</p>
	                    <div class="textFrom">——河北科技大学硕士论文 曹迪-《基于深度学习的用户个性化推荐方法的设计》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>)hdh x ∈R 表征。⁞定义3.1(隐藏层表征)输入数据xdx∈R ,隐藏层表征()hdh x ∈R 定义如下:⁞()()f hh =f x =s Wx +b (3-6)<em class='similar'>⁞式中fs 为非线性激活函数,</em><em class='similar'>d dh xWR×∈为权重矩阵,</em>hdRhb ∈为偏置向量,常见⁞36第3章基于收缩自编码器的 AP 特征约简算法⁞的激活函数如下:⁞()⁞()⁞()⁞()()⁞1sigmoid⁞1⁞tanh⁞Re LU max 0,</p>
	                    <div class="textFrom">——黑龙江大学硕士论文 许晓杰-《基于集成学习和位置指纹的室内定位算法研究》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>每个隐藏层通过应用仿射变换和非线性映射将其输入向量从下一层转换到⁞上一层,如式(1)一式(3)。⁞20=z (1)v‘‘+1’一矸 z(2’(2)z 一盯(v )(3)<em class='similar'>⁞式中,</em>w&quot;’表示￡层的权重矩阵;口()<em class='similar'>表示非线性激活函数。</em>在最后一层中,softmax用于获得输入特征向量而的第i&quot;类⁞5。的概率,如式(4)。⁞p(s。I z。一softmax(&lt;硼}¨,z‘L-1’&gt;)(4)⁞式中,L表示隐藏层的数量,以及&lt;耐&quot;,</p>
	                    <div class="textFrom">——微型电脑应用 林思岑-《基于去相关化的低秩矩阵分解对口语能力的评估方法》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>RNN 因其网络拓扑结构在处理时序信息方面具有天然的优势,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>RNN 在提取文本特这时,各有优缺点,那么,将其结合一下合并成一个网络,既结合了两者的优点,也屏蔽了两者的缺点。但是,如果要将其结合时,需要考虑先用 RNN 还是 CNN。<em class='similar'>因为,</em><em class='similar'>RNN 在处理时序信息时有天然的优势,</em>而语言(文本)本身就具有天然的时序特征,如果我们先用 CNN 卷积的话,则时序特征可能就无法完全的保留。基于这一点,</p>
	                    <div class="textFrom">——网页 -《基于 循环神经网络 (LSTM) 的情感评论文本分类 - smilejiasmile的博客 - CSDN博客》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>与简单的前向神经网络的区别是循环神经网络的内部是一种循环的网络结构,因此 RNN中的输入序列的计算步骤也是循环而行,<em class='similar'>这使得 RNN在处理连续性的时序信息时具有天然的优势。</em>这里的循环的网络结构标示 RNN对连续序列的每个时间步的信息都执行相似的计算步骤,每一个时间步的输入会关联到之前所有时间步计算所得到的输出,这就使得循环神经网络的每次计算都⁞应&quot;记忆&quot;过往时序的信息。</p>
	                    <div class="textFrom">——中原工学院硕士论文 李根-《情感分析的分类算法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>LSTM 引入了门控机制,</em><em class='similar'>包括遗忘门、</em><em class='similar'>输入门和输出门,</em><em class='similar'>这些门控单元能够有效地缓解梯度爆炸和梯度消失问题。</em><em class='similar'>下面结合LSMT 的前向计算过程,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>3.2 BiLSTM 层⁞RNN 包括输入层、隐藏层和输入层,但是随着输入序列长度的增加,传统的 RNN会出现梯度爆炸和梯度消失问题[91]。LSTM 在 RNN 的基础上进行改进,通过增加<em class='similar'>遗忘门</em>、<em class='similar'>输入门和输出门三个门控单元,</em><em class='similar'>很好地解决了梯度消失和梯度爆炸的问题,</em>加快了模型的收敛速度。LSTM 结构如图4-9所示。⁞LSTM 单元结构的遗忘门、输入门、输出门的具体公式如下:⁞𝑓𝑡=𝜎(𝑊𝑓[ℎ𝑡−1,𝑥𝑡]+𝑏𝑓)(4-4)⁞𝑖𝑡=𝜎(</p>
	                    <div class="textFrom">——常州大学硕士论文 程钊-《面向危险化学品的知识图谱构建研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>8-26)和式(8-28)。⁞它基于〃一1、x,、s,决定隐层输出九,见图8-16。⁞图8T6输出门⁞这样就可以比较清楚地了解LSTM单元的结构了。⁞8.2.2 LSTM单元如何缓解梯度弥散⁞那么,<em class='similar'>LSTM单元是如何缓解梯度消失和梯度爆炸问题的呢?</em>⁞如图8-17所示,可以将LSTM单元看成一个尝试将信息存储较久的记忆单元。这个记忆单元被3个激活门<em class='similar'>(遗忘门、</em><em class='similar'>输入门、</em><em class='similar'>输出门)</em>所保护,</p>
	                    <div class="textFrom">——北京：人民邮电出版社,2018.08 李建军，王希铭，潘勉-《深度学习系列深度学习与TensorFlow实战》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>引入了记忆模块的概念,使用门控机制对信息的输入、遗忘和输出进行控制。从而,有效的解决rnn中梯度消失的问题。[0044]双向长短时记忆网络<em class='similar'>(bi‑lstm)</em><em class='similar'>主要引入了门控机制包括输入门,</em><em class='similar'>遗忘门和输出门,</em>其概念实则是一个全连接层,它的输入是上一时刻的隐藏层状态,输出是其细胞状态的每一个单元的信息乘数因子,该因子的大小控制输入信息流的再输入、输出和需要遗忘的选择项。</p>
	                    <div class="textFrom">——网页 -《一种基于GCN的汉语复句隐式关系分析方法及装置与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>遗忘门用来控制需要保留多少上一时刻细胞状态的信息到当前细胞状态中。通⁞第二章自然场景文本识别相关理论及基础知识⁞过引入&quot;门机制&quot;可以有效约束梯度值的大小,<em class='similar'>从而缓解梯度消失或者梯度爆炸的问题。</em><em class='similar'>⁞LSTM 记忆单元的前向计算过程如下:</em>⁞𝑓𝑡=𝜎(𝑊𝑓𝑥𝑥𝑡+𝑊𝑓ℎℎ𝑡−1+𝑏𝑓)⁞𝑖𝑡=𝜎(𝑊𝑖𝑥𝑥𝑡+𝑊𝑖ℎℎ𝑡−1+𝑏𝑖)⁞𝑐𝑡⁞~=𝑡𝑎𝑛ℎ(</p>
	                    <div class="textFrom">——华南理工大学硕士论文 林庆祥-《基于文本纠正及注意力机制的不规则自然场景文本识别》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>搭建了基于 LSTM 的机场群延误⁞预测模型。相较于传统的 CNN 网络,LSTM 能学习到数据之间的时间相关性,相较于⁞传统的 RNN 网络,LSTM 增加了输入门,<em class='similar'>输出门和遗忘门三个门控单元,</em><em class='similar'>能有效地避⁞免梯度消失和爆炸,</em>学习到更长的时间序列。本文基于中美机场群的数据集对 LSTM 预⁞测模型进行了训练以及优化,对模型的超参数对实验结果的影响进行了讨论,模型在中⁞美数据集上的表现进行了对比。</p>
	                    <div class="textFrom">——中国民航大学硕士论文 渠星-《基于Skip-LSTM的机场群延误预测方法研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong> diagram⁞线线线⁞⁞赵忠斌等:融合多头注意力机制的网络恶意流量检测数据与计算发展前沿,2022,4(5)⁞长短期记忆网络(LSTM)[12]通过门控机制来解决传统 RNN 的缺陷。<em class='similar'>LSTM 引入了包括输入门、</em><em class='similar'>输出门和遗忘门,</em>以及记忆元这些门控机制,通过门控单元来决定数据的重要程度,或保留或丢弃,从而保障关键信息可以传递下去。图2展示了 LSTM的结构。⁞其中,各个门控单元的计算规则如下:⁞</p>
	                    <div class="textFrom">——数据与计算发展前沿 赵忠斌；蔡满春；芦天亮-《融合多头注意力机制的网络恶意流量检测》-2022 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_5" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">23.6%(219字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自注意力机制和BiGRU相结合的文本分类研究" target="_blank">自注意力机制和BiGRU相结合的文本分类研究</a></span>
                      <p>石磊;王明宇;宋哲理;陶永才;卫琳;高宇飞;范雨欣 -
                        《小型微型计算机系统
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">5%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=低资源语言神经机器翻译关键技术研究" target="_blank">低资源语言神经机器翻译关键技术研究</a></span>
                      <p>赖文 -
                        《中央民族大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Transformer的蒙汉神经机器翻译研究" target="_blank">基于Transformer的蒙汉神经机器翻译研究</a></span>
                      <p>高芬;苏依拉;牛向华;赵亚平;范婷婷;仁庆道尔吉 -
                        《计算机应用与软件
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.6%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=公路隧道施工期智能实时监测及预警系统" target="_blank">公路隧道施工期智能实时监测及预警系统</a></span>
                      <p>刘洁 -
                        《长安大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的心电脉搏特征识别与应用" target="_blank">基于深度学习的心电脉搏特征识别与应用</a></span>
                      <p>胡文锐 -
                        《北方民族大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=机器翻译" target="_blank">机器翻译</a></span>
                      <p>李沐，刘树杰，张冬冬，周明 -
                        《
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=多人对话机器人语音分离系统研究" target="_blank">多人对话机器人语音分离系统研究</a></span>
                      <p>蔡景祥 -
                        《西南科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://www.doc88.com/p%2D1923903073921.html" target="_blank">改进的神经语言模型及在代码提示中的应用 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.doc88.com/p%2D51499045297626.html" target="_blank">基于层次注意力机制的多任务疾病进展模型_潘祖江 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多模态注意力机制的视觉问答研究" target="_blank">基于多模态注意力机制的视觉问答研究</a></span>
                      <p>张浩田 -
                        《内蒙古大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=人工智能前沿技术丛书  计算智能导论" target="_blank">人工智能前沿技术丛书  计算智能导论</a></span>
                      <p>刘玉芳，张玮责任编辑;（中国）尚荣华，焦李成，刘芳 -
                        《
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_5" class="simMore"><a href="javascript:$ShowMore(5);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>图2-5长短时记忆神经网络基本结构</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>控制门用来确定上一个隐藏层状态的信息中哪些是重要的,输入控制⁞门用来确定当前状态的哪些信息是重要的,输出控制门用来确定下一个隐藏层状态。<em class='similar'>⁞⁞图4.5长短时记忆神经网络结构图⁞长短时记忆神经网络的基本结构,</em>如图4.6所示。在 t 时刻时,长短时记忆神经网⁞络中的输入有三个:当前时刻网络的输入值、上一时刻 LSTM 的输出值、以及上⁞一时刻的单元状态;输出有两个:当前时刻的 LSTM 输出值和单元状态。</p>
	                    <div class="textFrom">——长安大学硕士论文 刘洁-《公路隧道施工期智能实时监测及预警系统》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>-8-2.2脉搏信号的理论基础.-9-⁞2.2.1脉搏信号的产生原理.-9-2.2.2脉搏信号的波形特征与物理意义.-10-2.3深度学习的理论基础.-11-⁞2.3.1卷积神经网络基本结构.-11-2.3.2<em class='similar'>双向长短时记忆神经网络基本结构.</em>-14-2.4本章小结.-16-⁞第三章心电脉搏信号的采集与预处理.-17-⁞3.1心电脉搏信号同步采集.-17-3.2改进 EEMD 算法对心电脉搏信号的去噪研究.-19-⁞3.2.</p>
	                    <div class="textFrom">——北方民族大学硕士论文 胡文锐-《基于深度学习的心电脉搏特征识别与应用》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>减少细胞状态G的累积量。这便是长短时记忆神经网络相较于传统循环神经网络更稳定的原因。下面将详细介绍长短时记忆神经网络的门控原理。⁞计算智能导论⁞2)<em class='similar'>长短时记忆神经网络的数学分析⁞基于图4-37,</em>长短时记忆神经网络的核心是设计细胞状态C,用以控制信息的变化。注意,图4-37中£时刻的输入包括当前时刻的输入不、前一时刻的细胞状态CLI以及前一时刻的隐</p>
	                    <div class="textFrom">—— 刘玉芳，张玮责任编辑；（中国）尚荣华，焦李成，刘芳-《人工智能前沿技术丛书  计算智能导论》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>输入门产生当前时刻的输入映射,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>和当前时间步的实际输入拼接,作为输入。再通过非线性激活函数将输出限制在0到1之间。输出越接近1说明遗忘门越倾向于保留该输出,反之亦然。遗忘门输出的计算过程如式(2.7)所示。⁞(2.7)⁞2.<em class='similar'>输入门:</em><em class='similar'>用于产生输入的映射,</em><em class='similar'>计算过程如式</em>(2.8)所示。⁞(2.8)⁞3.状态更新:将当前输入更新到网络的状态中。<em class='similar'>计算过程如式</em>(2.9)-(2.10)所示。⁞(2.9)⁞(2.10)⁞4.输出门:通过输出门得到输出,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>上式中,表示 Sigmoid 函数;<em class='similar'>和分别表示权重矩阵和偏置向量;</em><em class='similar'>表示按元素相乘。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>()()1/1xx e �8�2−=+和()()tanh /x xx e e −=−()x xe e −+为激活函数;<em class='similar'> W 和 b 分别表示权重矩阵和偏置向量;</em><em class='similar'>表示按元素相乘,</em>即 Hadamard 积;t t ti , f ,o 分别表示输入门、遗忘门和输出门操作;,,t t tx c h 分别表示网络输入、记忆单元状态和隐含层状态; t 表示展开时间。</p>
	                    <div class="textFrom">——网页 -《改进的神经语言模型及在代码提示中的应用 - 道客巴巴》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>𝑡)⊙ℎ(𝑡−1)+(1−𝑢(𝑡))⊙ℎ̃(𝑡)(2.18)⁞其中𝑢(𝑡)、𝑟(𝑡)分别代表更新门和重置门的输出,ℎ̃(𝑡)为候选隐含状态特征,ℎ(𝑡)是当前时刻的隐含状态,<em class='similar'>𝑊和𝑏表示权重矩阵和偏置向量,</em><em class='similar'>⊙表示对应元素相乘。</em>通过上述过程可以发现,在 GRU 中首先获取到重置门和更新门的门控信号,接着使用重置信号对上一时间步的隐含特征进行重置且将得到的结果与当前时刻输入进行拼接存入候选隐含状态中</p>
	                    <div class="textFrom">——内蒙古大学硕士论文 张浩田-《基于多模态注意力机制的视觉问答研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>编—解码器结构包含<em class='similar'>编码器</em>、<em class='similar'>注意力网络和解码器三部分,</em><em class='similar'>如图2-6所示。</em><em class='similar'>其中,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>2语音分离模型构建⁞本文提出的基于自适应注意力网络(TAANet)的时域语音分离方法由三个部分组成:<em class='similar'>编码器</em>、<em class='similar'>自适应注意力网络和解码器,</em><em class='similar'>如图4-6所示。</em><em class='similar'>其中,</em>自适应注意力网络包含 N 个结构相同的局部-全局注意力块,每个注意力块中包括局部注意力网络与全局注意力网络,它们共同对语音信号进行建模。同时,模型能够自适应地调整多个层次中的局部-全局注意力比重,</p>
	                    <div class="textFrom">——西南科技大学硕士论文 蔡景祥-《多人对话机器人语音分离系统研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>注意力机制则通过计算输入帧和的匹配分数来完成输入序列和输出序列的对齐,</em><em class='similar'>匹配分数的高低代表这个输入帧和的相关程度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并传递给解码器(Decoder),解码器将根据接收的隐状态预测输出序列。在大多数情况下,预测特定所需的信息依赖于少数输入帧。因此在解码时不需要考虑每一个输入语音帧。<em class='similar'>注意力机制通过为每一对输入帧和分配相应的匹配得分来进行输入序列和输出序列的对齐。</em><em class='similar'>匹配得分的高低表示特定输入帧与的相关程度,</em>解码器通过决定对每个输入帧的关注程度进而预测输出序列。⁞加性注意力机制使用RNN解码器上一个时间步的状态和编码器网络编码得到的某一时刻</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>以使用加性注意力机制的注意力网络为例,</em><em class='similar'>首先计算解码器前一时刻的状态和编码器某一时刻的状态之间的相关程度,</em><em class='similar'>即注意力得分,</em>过程如下:</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>行输入序列和输出序列的对齐。匹配得分的高低表示特定输入帧与的相关程度,解码器通过决定对每个输入帧的关注程度进而预测输出序列。<em class='similar'>⁞加性注意力机制使用RNN解码器上一个时间步的状态和编码器网络编码得到的某一时刻的隐状态产生注意力得分:</em>⁞(2.29)⁞式(2.29)中,、——可学习的权值向量、偏置向量⁞、——可学习的权值矩阵⁞——双曲正切激活函数⁞再使用softmax函数进行归一化:⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>S-)是比较编码器状态儿和解码器状态J的一个匹配函数另外需要注意,解码器的初始隐含状态Sl)是基于反向编码器第一个时刻隐含状态 Zl计算得到的。<em class='similar'>⁞注意力网络首先使用匹配函数计算任意一个编码器隐含状态儿和前一时刻解码器隐含状态Si的匹配得分,</em>,然后使用SOftmax函数将该得分标准化成一个编码器隐含状态序列上的概率询。概率%,</p>
	                    <div class="textFrom">—— 李沐，刘树杰，张冬冬，周明-《机器翻译》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>对于原序列中的每一个词??,?1,长短期记忆网络(Long short-term Memory Network, LSTM)生成隐状态?,?1,,?来表示句子中的单词。对于目标语言中的第?个词,计算各个编码器隐藏层状态?~?<em class='similar'>与解码器状态?</em><em class='similar'>?之间的相关程度,</em>并进行SoftMax 归一化得到每个隐藏层向量的权重??,然后计算上下文向量??=????,并用它来预测目标语言中的第?个单词。在 RETAIN 中,它通过以相反的时间顺序查看 </p>
	                    <div class="textFrom">——网页 -《基于层次注意力机制的多任务疾病进展模型_潘祖江 - 道客巴巴》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>然后使用 Softmax 函数进行归一化,</em><em class='similar'>并进行加权求和得到向量,</em>计算过程</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>输入的查询Q和键K的维度为4,值V的维度为4,则注意力的计算过程可以分为三个步骤:首先,计算查询Q和键K的点乘,并除以依;<em class='similar'>然后,</em><em class='similar'>通过SoftmaX函数计算权重进行归一化;</em><em class='similar'>最后,</em><em class='similar'>乘以值V进行加权求和得到最终的注意力向量。</em>具体公式为:⁞OK 7⁞Attention(Q, K, P)= soft max(-¾=)F⁞多路注意力机制对现有的缩放点积注意力进行横向扩展,具体思路为:假设输入三元组为(Q,K,V),首先,</p>
	                    <div class="textFrom">——中央民族大学硕士论文 赖文-《低资源语言神经机器翻译关键技术研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现更加合理的自然语言建模.注意力机制其本质为一个查询(Query)到一系列键值对(Key-Value)的映射,其将Query和每个Key进行相似度计算得到权重,<em class='similar'>然后使用Softmax函数进行归一化,</em>最后将权重和相应的键值Value进行加权求和得到最终的Attention值[18].在文本分类任务中,注意力机制通过学习一系列的注意力分配系数,即权重系数,对RNN的每个单元输出向量赋予权重,</p>
	                    <div class="textFrom">——小型微型计算机系统 石磊；王明宇；宋哲理；陶永才；卫琳；高宇飞；范雨欣-《自注意力机制和BiGRU相结合的文本分类研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>筛选出少量重要信息并聚焦到这些重要信息上。其核心内容是为输入向量的每个单词学习一个权重。在计算注意力的时候主要分为三步:首先将query和key进行相似度计算权重,<em class='similar'>然后使用softmax函数进行归一化,</em>最后将权重和对应的键值对value进行加权求和。一般key=value。计算公式表示为:⁞Attention(Q,K,V)=softmax(sim(Q,K))V (1)⁞放缩点积注意力结构如图2所示,放缩点积注意力就是使用点积进行相似度计算,</p>
	                    <div class="textFrom">——计算机应用与软件 高芬；苏依拉；牛向华；赵亚平；范婷婷；仁庆道尔吉-《基于Transformer的蒙汉神经机器翻译研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 2 章 对话系统基础理论</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_6" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">13.3%(154字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于子词嵌入和相对注意力的材料实体识别" target="_blank">基于子词嵌入和相对注意力的材料实体识别</a></span>
                      <p>韩玉民;郝晓燕 -
                        《计算机应用
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110291278.html" target="_blank">一种基于独立指针网络的敏捷成像卫星任务规划方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.9%(45字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的人物交互检测算法研究与实现" target="_blank">基于深度学习的人物交互检测算法研究与实现</a></span>
                      <p>余雪源 -
                        《西南交通大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=深度学习语音识别系统中的若干建模问题研究" target="_blank">深度学习语音识别系统中的若干建模问题研究</a></span>
                      <p>唐健 -
                        《中国科学技术大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(41字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=回复信息生成模型的训练方法、回复信息生成方法及装置" target="_blank">回复信息生成模型的训练方法、回复信息生成方法及装置</a></span>
                      <p>蒋宏飞;王萌萌;李健铨;崔培君;晋耀红;杨凯程 -
                        《11363 北京弘权知识产权代理事务所(普通合伙)
                        》- 2018.06.12 
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向仪器领域的任务型对话系统研究" target="_blank">面向仪器领域的任务型对话系统研究</a></span>
                      <p>陈婷婷 -
                        《西安电子科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Transformer的对话系统研究" target="_blank">基于Transformer的对话系统研究</a></span>
                      <p>许明权 -
                        《湖南大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=以开放式网络应用服务模型为基础的Web服务资源管理研究" target="_blank">以开放式网络应用服务模型为基础的Web服务资源管理研究</a></span>
                      <p>陈曦 -
                        《西南交通大学博士论文
                        》- 2013 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.doc88.com/p%2D9009957298762.html" target="_blank">基于CSI的人体动作识别方法研究 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_6" class="simMore"><a href="javascript:$ShowMore(6);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>最后解码器根据、</em><em class='similar'>前一时刻的输出向量和状态向量计算得到当前时刻的状态向量和输出向量,</em>再经过 Softmax函数之后得到输出序列,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>逐个计算后最终输出完整的输入序列编码上下文的向量表示,<em class='similar'>在后续的解码阶段将编码器输出的上下文向量和前一时刻解码隐藏状态向量进行计算得到当前时刻解码隐藏状态向量,</em>将解码模块的输出向量经过Softmax函数计算得到目标词置信度。序列到序列模型也存在一些缺陷,首先这种模型对于输入序列有顺序要求,不能实现并行处理,因此训练速度很慢。当输入语言序列较⁞</p>
	                    <div class="textFrom">——西南交通大学硕士论文 余雪源-《基于深度学习的人物交互检测算法研究与实现》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>,以当前轮次输入信息的结束符的字向量为解码器输入层的输入值,计算得到第一⁞个时刻的解码隐状态向量;<em class='similar'>以第一个时刻的解码隐状态向量计算得到第一个时刻的输出向⁞量。</em>再以第一个时刻的解码隐状态向量为解码器隐藏层的输入值,以当前轮次回复信息的⁞第一个字的字向量为解码器输入层的输入值,计算得到第二个时刻的解码隐状态向量;以⁞第二个时刻的解码隐状态向量计算得到第二</p>
	                    <div class="textFrom">——11363 北京弘权知识产权代理事务所(普通合伙) 蒋宏飞；王萌萌；李健铨；崔培君；晋耀红；杨凯程-《回复信息生成模型的训练方法、回复信息生成方法及装置》-2018.06.12 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>对应f -1时刻子字的字符子序列为&quot;0 U R&quot;。⁞字符子序列中的第h个字符的预测输出过程如下,首先,与传统解码⁞器结构相同,<em class='similar'>模型进行字符解码器状态更新和注意力向量计算。</em><em class='similar'>状态向量⁞根据前一字符时刻的输出</em>(mm更新字符解码器的隐层状态。上述计算过程^⁞公式(5.12)所示。字符解码器-层状态&lt;_1&gt;u与aJLyq作为反馈信息加载到字符⁞注意力模块中,</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 唐健-《深度学习语音识别系统中的若干建模问题研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>将其对应的静态元素经el映射后得到的向量作为编码器的输入。l∈[1,l]为解码器在解码时间步骤t时第l层的隐含层状态。[0018]在步骤(3)中,在每个解码时间步骤t时,根据编码器的输出向量i∈[1,m]、<em class='similar'>解码器最后一层的隐含层状态和mask向量计算得到指向输入序列各个节点的softmax概率分布,</em>选择概率最大的节点yt+1作为下一解码时间步骤t+1时的输出。根据所选择的输出节点yt+1,依次对输入序列中的动态元素i∈[1,</p>
	                    <div class="textFrom">——网页 -《一种基于独立指针网络的敏捷成像卫星任务规划方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>用不同<em class='similar'>的注意力机制</em>,<em class='similar'>目前使用较广泛的注意力机制还有缩放点积注意力机制</em>[49]、</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对加权求和得到加性注意力输出向量:⁞(2.31)⁞RNN解码器网络根据、上一个解码时间步的输出向量以及状态向量产生当前时间步的状态向量以及输出向量:⁞(2.32)⁞(2.33)⁞除了加性<em class='similar'>注意力机制外</em>,<em class='similar'>目前使用较为广泛的注意力机制有缩放点积注意力机制</em>(Scale Dot Product Attention, SDPA)[45]、多头注意力机制(Multi-Head Attention, MHA)以及局部注意力机制(Local Attention, LA)[46]。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>多头注意力</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'>MHA)</em>机制[17]<em class='similar'>和局部注意力机制</em>[50]等。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>量产生当前时间步的状态向量以及输出向量:⁞(2.32)⁞(2.33)⁞除了加性注意力机制外,目前使用较为广泛的注意力机制有缩放点积注意力机制(Scale Dot Product Attention, SDPA)[45]<em class='similar'>、多头注意力机制</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'> MHA)</em><em class='similar'>以及局部注意力机制</em>(Local Attention, LA)[46]。在编码器-解码器结构中通常使用不同的注意力机制以从不同的角度获取各种层次的信息。目前,出现了各种基于不同注意力机制的编解码网络,如LAS模型、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>式和噪声输入确实有助于提高模型的鲁棒性。⁞统一使用ULM词嵌入作为输入,在 BiLSTM-CRF模型基础上加入命名实体识别常用的卷积神经网络、<em class='similar'>自注意力机制</em>(Self-Attention,SA)、<em class='similar'>多头注意力机制</em><em class='similar'>(Multi-Head Attention,</em><em class='similar'>⁞MHA)</em>和相对多头注意力机制(RMHA),用以验证相对多头注意力机制对于模型的提升效用,实验结果见表7。可以看出,相对于其他特征编码模型,相对多头注意力机制能更有效地提升模型对于实体与实体、</p>
	                    <div class="textFrom">——计算机应用 韩玉民；郝晓燕-《基于子词嵌入和相对注意力的材料实体识别》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>受到了广泛关注[52]。<em class='similar'>论文第三章将对Transformer模型进行详细探讨,</em><em class='similar'>并在此基础上进行改进。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>出现了各种基于不同注意力机制的编解码网络,如LAS模型、Transformer模型等。其中,Transformer模型以其极高的识别准确度和简便的建模流程而受到广泛关注。<em class='similar'>本文第三章和第四章将详细探讨Transformer模型,</em><em class='similar'>并在此基础上进行改进。</em>⁞2.5本章小结⁞本章主要分为两部分。第一部分主要介绍了语音识别的基本理论和处理流程。第二部分主要介绍了深度学习方法在端到端语音识别中的主要应用,这部分首先介绍端</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>在自然语言理解领域,</em><em class='similar'>考虑到意图检测和槽位填充两个子任务之间的密切相关性,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>如双向长短期记⁞西安电子科技大学硕士学位论文⁞忆网络与条件随机场相结合,不仅能够利用过去和未来的信息,还可进行句子级别的标注。⁞3)<em class='similar'>联合训练⁞在自然语言理解任务中,</em><em class='similar'>领域识别、</em><em class='similar'>意图识别和槽位填充之间存在一定的相关性,</em>因此将这三个任务进行联合训练是研究的一个重要方向。2016年,微软Hakkani-Tür[22]⁞等人提出了采用 RNN 和 LSTM 结构的联合模型完成联合任务,取得了比单个模型更⁞</p>
	                    <div class="textFrom">——西安电子科技大学硕士论文 陈婷婷-《面向仪器领域的任务型对话系统研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>主要包含三部分。</em><em class='similar'>第一部分主要介绍了对话系统的基本组成结构,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>即第一步上下文向量 ctxc聚集了来自第一步解码序列 ŷ的全局信息。⁞2.8小结⁞本章节介绍本文所涉及的相关基础理论与技术,<em class='similar'>主要包括三大部分。</em><em class='similar'>第一部分介绍了任务型对话系统的四个组成模块,</em>包括NLU、 DST、DPL 和 NLG;第二部分介绍了聊天型对话系统的几种生成方法,包括规则、检索和生成;第三部分介绍Seq2seq文本生成模型,</p>
	                    <div class="textFrom">——湖南大学硕士论文 许明权-《基于Transformer的对话系统研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>这一章节为后续第3章、</em><em class='similar'>第4章的内容做下铺垫。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并对基于传感器、视觉、红外和CSI的人体动作识别方法的研究现状进行阐述和总结,对比分析后得出基于CSI的人体动作识别方法的优越性。最后总结了现有的基于CSI的人体动作识别方法存在的问题,<em class='similar'>为后续第3章和第4章的研究内容做铺垫。</em>万方数据⁞哈尔滨工程大学硕士学位论文12万方数据⁞第3章基于CSI的固定路径人体动作识别方法研究第3章基于CSI的固定路径人体动作识别方法研究3.1引言通过对基于CSI的人体动作识别的研究现</p>
	                    <div class="textFrom">——网页 -《基于CSI的人体动作识别方法研究 - 道客巴巴》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>b服务进行了分类,并通过各类Web⁞服务的比较,阐述了Web服务的异构性问题及其对OSI/RM体系结构层次划分带来的⁞挑战,指出了ONAS模型提出应用支撑层和网络应用服务接口NASI的必要性。第2⁞章内容对后续章节,<em class='similar'>特别是第3章和第4章的展开做了铺垫。</em>⁞西南交通大学博士研究生学位论文第页⁞论文第3章和第4章介绍了Web服务的统一建模、存储和查询平台ServUnity。其⁞中第3章重点介绍了USGM模型、服务图转化算法、服务声誉计算算法等。</p>
	                    <div class="textFrom">——西南交通大学博士论文 陈曦-《以开放式网络应用服务模型为基础的Web服务资源管理研究》-2013 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第3章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_7" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">42.8%(547字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202010577720.html" target="_blank">基于交互式解码的双语情感对话生成系统的制作方法</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6%(77字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110617100.html" target="_blank">基于BERT的自适应分层输出的中文分词方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.3%(55字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=利用依存句法分析辅助增强AMR解析方法研究" target="_blank">利用依存句法分析辅助增强AMR解析方法研究</a></span>
                      <p>吴泰中 -
                        《南京师范大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">4.2%(53字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=端到端维吾尔语语音识别研究" target="_blank">端到端维吾尔语语音识别研究</a></span>
                      <p>丁枫林;郭武;孙健 -
                        《小型微型计算机系统
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.7%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图卷积网络的在线用户评论情感分析研究" target="_blank">基于图卷积网络的在线用户评论情感分析研究</a></span>
                      <p>佘久洲 -
                        《常州大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.6%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110748160.html" target="_blank">面向大型关系型数据库的对话式数据模糊检索方法及装置与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.4%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://www.doc88.com/p%2D48773127649498.html" target="_blank">系统学习NLP（二十六）--BERT详解.docx</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202011284266.html" target="_blank">一种结合指针生成式与自注意力机制的短文本自动摘要方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于时空特性的社交网络突发话题查询、预测与可视化" target="_blank">基于时空特性的社交网络突发话题查询、预测与可视化</a></span>
                      <p>周立岩 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_7" class="simMore"><a href="javascript:$ShowMore(7);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>受到了广泛的关注。需要注意的是,<em class='similar'>Transformer 模型的性能通常与编码器块和解码器块的深度呈正相关。</em><em class='similar'>此外,</em><em class='similar'>更大的模型维度也会带来更高的模型性能和更强的泛化能力。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Transformer模型自被提出以来,其在端到端语音识别任务中展现了强大的能力。随着对Transformer模型研究的深入,逐渐衍生出了各种各样的变种模型。但是,<em class='similar'>Transformer模型的表现往往与编码器块和解码器块的深度呈正相关。</em><em class='similar'>此外,</em><em class='similar'>模型维度越大,</em><em class='similar'>模型的表达能力越强,</em><em class='similar'>识别的准确率和泛化能力越高,</em>但是会增加模型中各权值矩阵的维度,进而导致模型参数量和计算量的剧烈升高。比如,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>个含有24个编码器块的Transformer 模型,</em><em class='similar'>在模型维度为1024的情况下参数量达到了270M</em>[55]。<em class='similar'>为了降低Transformer 模型的参数量和计算复杂度,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>模型维度越大,模型的表达能力越强,识别的准确率和泛化能力越高,但是会增加模型中各权值矩阵的维度,<em class='similar'>进而导致模型参数量和计算量的剧烈升高。</em>比如,G. Synnaeve等人提出的改进Transformer模型[56]使用了24个编码器网络块,<em class='similar'>在模型维度为1024的情况下,</em><em class='similar'>得到的模型参数量为270M;</em>N. Q.<em class='similar'> Pham等人构建了一个含有48个编码器网络块和48个解码器网络块的Transformer模型</em>[57],其参数量达到了252M。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>Transformer 模型是一个典型的编—解码器结构,</em><em class='similar'>如图3-1所示。</em><em class='similar'>左侧为编码器,</em><em class='similar'>由若干个块堆叠而成,</em><em class='similar'>每个块中包含两个子层,</em><em class='similar'>分别为多头注意力</em><em class='similar'>(Multi-head Attention,</em>MHA)<em class='similar'>层和前馈网络层</em>(Feedforward Network Layer,FNL);<em class='similar'>右侧为解码器,</em><em class='similar'>其结构与编码器类似。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>数据集上实验表明&quot;局部—全局&quot;级联结构的融合注意力机制识别效果最好。⁞3.2自注意力机制与Transformer模型⁞Transformer模型的网络结构图如图3.1所示。⁞⁞图3.1 Transformer模型网络结构图⁞由图3.1可知,<em class='similar'>其是一个典型的编码器-解码器结构,</em>且内部不存在循环神经网络或卷积神经网络。图3.1左边是一个块(block)<em class='similar'>,通常编码器由若干个块堆叠而成。</em><em class='similar'>每个块中存在有两个子层,</em><em class='similar'>分别是多头注意力层和前馈网络层</em>(Position-wise Feed-forward Network, PFN)。<em class='similar'>解码器网络的结构和编码器类似,</em>也由数个块堆叠而成。相较于编码器块,解码器块将多头注意力替换为了掩膜多头注意力,并在掩膜多头注意力之后级联了一个多头注意力用于捕获预测字符与语音特征间的关联。每个子层之间都使用残差连接进行耦合,并在残差连接之后使用层归一化(Layer Normalization, LN)</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>务文档。<em class='similar'>⁞Bert 模型⁞Transformer 模型⁞TransfbrmerRi]</em><em class='similar'>遵循编解码结构,</em>编码器和解码器分别使用堆叠的自注意层和对应的的全连接层,<em class='similar'>如图2-1所示,</em><em class='similar'>左侧为编码器,</em><em class='similar'>右侧为解码器。</em>编码器部分由N个相同的层堆叠而成,每一层由多头自注意力机制和全连接前馈网络构成,之间均残差进行连接,并进行层归一化。解码器部分也由N个相同的层堆叠而成。每层在编码器层的基础上添加了一层多头注意</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 周立岩-《基于时空特性的社交网络突发话题查询、预测与可视化》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>10%单词不变。如图2所述为注意力机制结构图、如图3为bert模型采用的transformer模型结构图,<em class='similar'>transformer是一个encoder‑decoder的结构,</em><em class='similar'>由若干个编码器和解码器堆叠形成,</em><em class='similar'>图3中左侧部分为编码器,</em>由多维注意力机制<em class='similar'>(multi‑head attention)</em>和一个全连接组成,用于将输入语料转化成特征向量。<em class='similar'>右侧部分是解码器,</em>其输入为编码器的输出以及已经预测的结果,</p>
	                    <div class="textFrom">——网页 -《面向大型关系型数据库的对话式数据模糊检索方法及装置与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>,本文在Transformer结构的基础上,去除其中的解码器部分,将编码器与链接时序分类(CTC)相结合,作为本文所采用的端到端模型,<em class='similar'>模型结构如图1所示.</em><em class='similar'>整个模型的主体由若干个相同的编码层堆叠而成,</em>每个编码层分为两大部分:<em class='similar'>&quot;多头&quot;注意力</em><em class='similar'>(Multi-head attention)</em><em class='similar'>和前馈网络</em>(Feed-For-w ard Netw ork).每一部分后面都添加一个残差(residual)连接,然后进行层归一化(layer nomalization)</p>
	                    <div class="textFrom">——小型微型计算机系统 丁枫林；郭武；孙健-《端到端维吾尔语语音识别研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>并且作者已经发布在TensorFlow 的 tensor2tensor 库中。 Transformer 的网络架构如图1所示,<em class='similar'>Transformer 是一个 encoder-decoder 的结构,</em><em class='similar'>由若干个编码器和解码器堆叠形成。</em><em class='similar'>图1的左侧部分为编码器,</em>由 Multi-Head Attention 和一个全连接组成,用于将输入语料转化成特征向量。<em class='similar'>右侧部分是解码器,</em>其输入为编码器的输出以及已经预测的结果,由 Masked </p>
	                    <div class="textFrom">——网页 -《系统学习NLP（二十六）--BERT详解.docx》- （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>器使用堆叠式自注意力和逐点全连接层实现。编码器包括6个相同的网络块,参考图1,图1示出了一个网络块的具体结构,图1中&quot;n×&quot;表示n个相同的网络块,示例地,n为6。<em class='similar'>如图1所示,</em><em class='similar'>每个网络块由2个子层组成,</em>分别是multi-headattention层<em class='similar'>(多头注意力层)</em><em class='similar'>和feedforward层</em><em class='similar'>(前馈层)</em>,每个网络块的内部结构和transformer相同。编码器的输出同时传递给两个解码器。两个解码器分别为中文解码器和英文解码器,两个解码器的结构相同,每个解码器包括6个相同的网络块。</p>
	                    <div class="textFrom">——网页 -《基于交互式解码的双语情感对话生成系统的制作方法》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>不同之处在于,<em class='similar'>解码器将多头注意力层替换为掩膜多头注意力层,</em><em class='similar'>并在之后额外级联了一个多头注意力层以计算预测字符与语音特征间的相关性。</em><em class='similar'>所有子层之间都使用残差连接进行耦合,</em><em class='similar'>并在各子层之后使用归一化对该层输出进行调整。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>数据集上实验表明&quot;局部—全局&quot;级联结构的融合注意力机制识别效果最好。⁞3.2自注意力机制与Transformer模型⁞Transformer模型的网络结构图如图3.1所示。⁞⁞图3.1 Transformer模型网络结构图⁞由图3.1可知,其是一个典型的编码器-解码器结构,且内部不存在循环神经网络或卷积神经网络。图3.1左边是一个块(block),通常编码器由若干个块堆叠而成。每个块中存在有两个子层,分别是多头注意力层和前馈网络层(Position-wise Feed-forward Network, PFN)。解码器网络的结构和编码器类似,也由数个块堆叠而成。相较于编码器块,<em class='similar'>解码器块将多头注意力替换为了掩膜多头注意力,</em><em class='similar'>并在掩膜多头注意力之后级联了一个多头注意力用于捕获预测字符与语音特征间的关联。</em><em class='similar'>每个子层之间都使用残差连接进行耦合,</em><em class='similar'>并在残差连接之后使用层归一化</em>(Layer Normalization, LN)</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>为了使残差连接更加方便计算,所有子层以及嵌入层输出的维度大小dmodel都为512。[0020](5)解码模块由6层解码器组成,解码器由自注意力层和全连接前馈神经网络层以及带掩码注意力层三个子层组成,<em class='similar'>子层之间采用残差连接并进行归一化,</em>所有子层以及嵌入层输出的维度大小dmodel都为512。[0021]图1是本发明的一种基于指针生成式与自注意力机制的短文本自动摘要模型示意图,如图1所示,该发明包括:[0022](1)分词以及词向量构建模块,</p>
	                    <div class="textFrom">——网页 -《一种结合指针生成式与自注意力机制的短文本自动摘要方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>3.2.1自注意力模型⁞采用的句子编码器由多层基于自注意力的编码器构成,其单层结构如图3.2⁞所示。该单层的结构主要可以分为两个子层:多头注意力层(Multi-Head Attention⁞Layer)和前馈层(FeedForward Layer )<em class='similar'>。多头注意力层有多个自注意力模型构成,</em>⁞用于获取句子在不同层面上的特征表示,并且进行组合;前馈层将通过多头注意⁞力层所获取的句子表示进行非线性激活,</p>
	                    <div class="textFrom">——南京师范大学硕士论文 吴泰中-《利用依存句法分析辅助增强AMR解析方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>简介。<em class='similar'>值得注意的是,</em><em class='similar'>在较新的文献中,</em><em class='similar'>常用&quot;线性层&quot;指代&quot;全连接层&quot;</em>[59]。<em class='similar'>因此,</em><em class='similar'>后续对这两种说法不加区分。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>构建基于分层分组线性变换的扩张缩放单元用于增强模型的表达能力,同时给出了其数学定义和拓扑描述。<em class='similar'>值得注意的是,</em><em class='similar'>在较新的文献中,</em><em class='similar'>常常用线性变换来指代全连接层。</em><em class='similar'>因此,</em><em class='similar'>本文对两种说法不加以区分。</em>⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。与普通全连接层使用的线性变换不同,分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>Transformer 模型频繁地使用自注意力</em><em class='similar'>(Self Attention,</em>SA)<em class='similar'>机制,</em><em class='similar'>从不同的表示子空间中获取丰富的信息。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>每个子层之间都使用残差连接进行耦合,并在残差连接之后使用层归一化(Layer Normalization, LN)对输出进行调整。⁞3.2.1<em class='similar'>自注意力机制⁞Transformer中的编码器网络和解码器网络中频繁使用自注意力机制以从不同表示子空间获取大量的丰富信息。</em>自注意力机制使用点积运算来计算序列中任意位置元素间的关联性。⁞考虑将一个长度为、向量维度(也称为模型维度)为的序列作为自注意力在一个表示子空间</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong><em class='similar'>attention)</em><em class='similar'>机制;</em>前者可以充分捕捉序列内部的结构和依赖关系,比如常见代词指代的事物,<em class='similar'>后者则可以让模型关注到不同位置的不同表示子空间中的信息。</em><em class='similar'>transformer模型也是第一个完全使用注意力</em><em class='similar'>(attention)</em>机制搭建的模型,摆脱了传统的编码器‑解码器结构必须含有cnn或rnn的固定模式,既可以解决长期依赖问题,也可以很好地实现并行化计算。</p>
	                    <div class="textFrom">——网页 -《基于BERT的自适应分层输出的中文分词方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>multi-head attention)算法,如图2-11所示。通过将任意位置的两个单词的相对距离转换成常量,有效的解决了 NLP 中棘手的长依赖和并行化计算困难的问题。⁞多头注意力<em class='similar'>使用自注意力机制</em><em class='similar'>(self-attention)</em><em class='similar'>的模型捕获不同表示子空间的信⁞息。</em>与传统注意力算法不同的是,self-attention 通过引入一个 k 维调节器⁞kd 可以让⁞训练过程更加稳定,此时式(2-51)变为如式(2-53)表现形式。⁞(,)⁞softmax()</p>
	                    <div class="textFrom">——常州大学硕士论文 佘久洲-《基于图卷积网络的在线用户评论情感分析研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>在 Transformer 模型中,</em><em class='similar'>模型维度通常指各模块输出向量的维度,</em>取值通常为128、</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>3.2.2 Transformer其余网络组件⁞在Transformer模型中,除了自注意力机制外,还有其它组件,它们对网络的性能表现也具有重要的作用。下面对这些组件进行简要介绍。⁞1.前馈网络层⁞在Transformer中,<em class='similar'>模型的维度通常指的是模型中各模块输出向量的维度,</em>常取256、512、1024等2的整数次幂。前馈网络层实际上是两层全连接网络,它首先将扩张到更大的维度,再通过第二个全连接层进行维度还原。前馈网络主要用于增强模型的拟合能力。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_8" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">34.1%(378字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于障碍物图像感知的油气管道机器人路径规划策略研究" target="_blank">基于障碍物图像感知的油气管道机器人路径规划策略研究</a></span>
                      <p>戴耀南 -
                        《武汉工程大学博士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">5.9%(65字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向多类型消息的网络谣言传播机制研究" target="_blank">面向多类型消息的网络谣言传播机制研究</a></span>
                      <p>戴天骥 -
                        《重庆邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的中文文本情绪分类方法研究" target="_blank">基于深度学习的中文文本情绪分类方法研究</a></span>
                      <p>高凯龙 -
                        《北京建筑大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向科技文献的学术知识图谱构建研究与应用" target="_blank">面向科技文献的学术知识图谱构建研究与应用</a></span>
                      <p>陈曦 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识图谱的推荐算法研究与实现" target="_blank">基于知识图谱的推荐算法研究与实现</a></span>
                      <p>贾帅琪 -
                        《电子科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.9%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110471865.html" target="_blank">一种基于时频跨域特征选择的语音分离方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于改进卷积神经网络的航空发动机RUL预测方法研究" target="_blank">基于改进卷积神经网络的航空发动机RUL预测方法研究</a></span>
                      <p>孙行行 -
                        《河南大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Spark的并行条件随机场模型设计与实现" target="_blank">基于Spark的并行条件随机场模型设计与实现</a></span>
                      <p>龚哲戎 -
                        《湖南大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_8" class="simMore"><a href="javascript:$ShowMore(8);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>式中,</em><em class='similar'>,分别表示查询</em><em class='similar'>(Query)</em><em class='similar'>向量序列、</em><em class='similar'>键(</em><em class='similar'>Key)</em><em class='similar'>向量序列和值</em><em class='similar'>( Value )</em><em class='similar'>向量序列;</em>,分别为对应的权重矩阵。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>假设输入部分表示为𝑋=[𝑥1,𝑥2,.𝑥𝑛],输出部分表示为𝑌=[𝑦1,𝑦2,.𝑦𝑛],那么可以通过输入向量 X 乘以不同的系数 W,得到的Q、K、<em class='similar'>V 分别表示查询向量序列 query、</em><em class='similar'>键向量序列 key、</em><em class='similar'>和值向量序列 value,</em>公式表⁞示如下:⁞𝑄=𝑊𝑞𝑋(3-1)𝐾=𝑊𝐾𝑋(3-2)𝑉=𝑊𝑉𝑋(3-3)𝑊𝑞、𝑊𝑘、𝑊𝑣分别是参数矩阵。⁞由此可以得出输出矩阵 Y,</p>
	                    <div class="textFrom">——北京建筑大学硕士论文 高凯龙-《基于深度学习的中文文本情绪分类方法研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>⁞(,,) max()⁞T⁞k⁞K QAttention Q K V soft V⁞d⁞(4-1)⁞(,,)(1,,) oMultiHead Q K V Concat head headh W(4-2)<em class='similar'>⁞式中Q,</em>K,V分别是查询向量序列,<em class='similar'>键向量序列和值向量序列</em><em class='similar'>(Query,</em><em class='similar'>Key,⁞Value)</em>。(,,)Q K V⁞i i i ihead Attention QW KW VW。 kd 对内积进行缩放,避免softmax的结果非0即1。⁞为了扩大全局注意力的影响,降低 self-Attention 的运算复杂度,</p>
	                    <div class="textFrom">——武汉工程大学博士论文 戴耀南-《基于障碍物图像感知的油气管道机器人路径规划策略研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>进而得到二者之间的注意力权重矩阵,</em><em class='similar'>最后将该矩阵作用于即可得到的输出结果,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong> X K , X ,其中 X  X⁞V Q  XK  XV 。⁞初始化参数矩阵WQ ,WK ,WV ,计算Q, K 之间的相似度,即为图中QKT ,然后经 softmax⁞激活函数并归一化,<em class='similar'>最后将得到的注意力权重矩阵与V 相乘,</em><em class='similar'>便得到了最终的输出结果⁞Y 。</em>⁞上述过程又被称为单头注意力,多头注意力是在单头注意力的基础上多次重复其操⁞作并将其结果叠加后进行线性变换得到最终结果,多头注意力的操作过程描述如下,</p>
	                    <div class="textFrom">——河南大学硕士论文 孙行行-《基于改进卷积神经网络的航空发动机RUL预测方法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>本质上它包含两层全连接网络,</em><em class='similar'>第一层将扩张到更大的维度,</em><em class='similar'>第二层再将维度进行还原,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>前馈网络层⁞在Transformer中,模型的维度通常指的是模型中各模块输出向量的维度,常取256、512、1024等2的整数次幂。<em class='similar'>前馈网络层实际上是两层全连接网络,</em><em class='similar'>它首先将扩张到更大的维度,</em><em class='similar'>再通过第二个全连接层进行维度还原。</em>前馈网络主要用于增强模型的拟合能力。式(3.6)描述了前馈网络的前向传播过程。⁞(3.6)⁞式(3.6)中,——线性整流激活函数⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>式中,<em class='similar'>表示激活函数;</em><em class='similar'>,分别表示两个全连接网络的权重矩阵;</em><em class='similar'>,分别表示两个全连接网络的偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>一个全连接网络2压缩全局特征描述子得到压缩特征描述子m为压缩后的特征维度,该压缩特征描述子是用来引导特征选择的,其计算过程如下,<em class='similar'>n代表全连接网络2的操作,</em><em class='similar'>δ代表sigmoid激活函数,</em><em class='similar'>w表示该全连接网络2的权重矩阵,</em>g表示全局特征描述子:z=δ(n(wg))再使用两个全连接层(全连接网络3和全连接网络4)将压缩特征描述子进行特征维度还原,分别得到时域特征描述子与时频域特征描述子aj表</p>
	                    <div class="textFrom">——网页 -《一种基于时频跨域特征选择的语音分离方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>[,,,,])fc t t t t t fcV W v f cc c ot b(4.6)⁞ˆ()u fc fcV W V b(4.7)⁞其中,V 表示第一层全连接输出的中间向量,<em class='similar'>表示 sigmoid 激活函数,</em>和⁞2fcW 表⁞示全连接网络的权重矩阵,<em class='similar'>⁞1fcb 和⁞2fcb 表示全连接网络的偏置矩阵,</em> ûV 表示第二层全连接输出的用户融合特征向量。⁞重庆邮电大学硕士学位论文第4章基于用户认知与多类型消息的转发态势预测模型⁞</p>
	                    <div class="textFrom">——重庆邮电大学硕士论文 戴天骥-《面向多类型消息的网络谣言传播机制研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>𝛼𝑒⁞𝑖𝑇⁞∙𝛼𝑜⁞𝑗⁞)⊘(∥𝛼𝑒⁞𝑖∥∥𝛼𝑜⁞𝑗⁞∥).(3.7)⁞其中,𝐴𝑡𝑡𝑛𝑖,𝑗表示第 j 个本体标签对第 i 个单词的注意力,⊘表示按元素相⁞除,<em class='similar'>∥∥表示向量的 L2范数。</em><em class='similar'>将权重矩阵经过一层全连接网络和激活函数,</em>得到每个单词关于本体标签的权重向量𝛽,如公式3.7-公式3.8所示。⁞𝜇𝑖=𝑚𝑎𝑥(𝑅𝑒𝐿𝑈(𝑊𝑎∙𝐴𝑡𝑡𝑛[𝑖−𝑠:𝑖+𝑠]+𝑏𝑎)).(3.8)</p>
	                    <div class="textFrom">——吉林大学硕士论文 陈曦-《面向科技文献的学术知识图谱构建研究与应用》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>由于 Transformer 模型内部没有循环结构,</em><em class='similar'>无法像 RNN 一样利用天然包含的时序位置信息,</em><em class='similar'>注意力机制会在不同的上下文环境中输出相同的状态序列,</em><em class='similar'>导致位置信息完全丢失。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>语音输入序列以及字符序列都是时间关联的序列,具有特定的排列顺序。排列顺序富含了上下文语义信息,因此在模型中引入位置信息有助于强化对序列内部关系进行表征的能力。<em class='similar'>Transformer内部不存在RNN中的循环结构,</em><em class='similar'>无法利用天然包含在循环结构中的时序位置信息。</em>如果不加以处理,<em class='similar'>注意力机制在不同上下文环境中会输出相同状态序列,</em><em class='similar'>进而导致位置信息的完全丢失。</em>由此可见,在序列中附上各个向量的位置信息帮助模型进行学习是非常有必要的。Transformer模型引入了位置编码(Positional Encoding, PE)来表征序列内部向量间的位置信息。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>入的语音序列和输出的字符序列都属于时间序列数据,</em><em class='similar'>具有特定的排列顺序且富含上下文语义信息,</em><em class='similar'>所以在序列中加入位置信息有助于增强模型表示序列内部关系的能力,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>⁞(3.6)⁞式(3.6)中,——线性整流激活函数⁞、——两个全连接层的权值矩阵,,⁞、——两个全连接层的偏置向量,,⁞2.<em class='similar'>位置编码⁞语音输入序列以及字符序列都是时间关联的序列,</em><em class='similar'>具有特定的排列顺序。</em><em class='similar'>排列顺序富含了上下文语义信息,</em><em class='similar'>因此在模型中引入位置信息有助于强化对序列内部关系进行表征的能力。</em>Transformer内部不存在RNN中的循环结构,无法利用天然包含在循环结构中的时序位置信息。如果不加以处理,注意力机制在不同上下文环境中会输出相同状</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>将 PE 与输入语音序列进行加性组合,</em><em class='similar'>使得序列中附带关于序列内部的位</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>由此可见,在序列中附上各个向量的位置信息帮助模型进行学习是非常有必要的。Transformer模型引入了位置编码(Positional Encoding, PE)来表征序列内部向量间的位置信息。<em class='similar'>Transformer通过将PE与输入序列进行加性组合,</em><em class='similar'>使得输入序列被动地附有序列内部的位置信息,</em>进而使模型自身具备学习位置信息的能力。下面介绍PE的生成过程。⁞给定序列长度,表示PE编码过程生成的第个位置(时间步)、维度为(能被2整除)的位置编码向量。向量中每个元素由式(3.7)和式(3.8)</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>向量,</em><em class='similar'>其中每个元素的计算方式如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>出现的经验特征向量万尸‘=1￡7/,五#,,五},向量的长度与总特征数K等⁞长。因为向量中大部分的值是为〇的,所以此向量以SparseVector稀疏向量的形式⁞存储,这样不但能够节约内存空间,而且能节省计算时间。<em class='similar'>向量中元素计算方式⁞如下:</em>⁞W =:￡,》,&lt;)(3-3)⁞t=l⁞另一个是根据特征字典将数据转为相应的特征因子,包括条件特征因子和非⁞条件特征因子。⁞表3.2 SCRFs的并行训练数据转换和中间数据缓存算法伪代码⁞算法3.2 </p>
	                    <div class="textFrom">——湖南大学硕士论文 龚哲戎-《基于Spark的并行条件随机场模型设计与实现》-2017 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>线性加上对应的 PE 向量即可得到含有位置信息的向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>72]和相对位置编⁞码[73]。这里我们采用训练式的绝对位置编码。如公式(3-4)和(3-5)所示,我们直接为每个嵌入向量分配一个可训练的位置向量(Position Embedding,PE),<em class='similar'>再将对应的嵌入向量与 PE相加,</em><em class='similar'>得到包含位置信息的嵌入向量 x。</em>⁞xt = eit + pt ∀t =1,2,..., T (3-4)⁞xu = eu + pT+1(3-5)⁞其中,pt为第 t个位置的物品的位置向量,pT+1为用户的位置向量。</p>
	                    <div class="textFrom">——电子科技大学硕士论文 贾帅琪-《基于知识图谱的推荐算法研究与实现》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong>方式,<em class='similar'>它是将后一层中的部分神经元与前一层中的部分神经元全连接,</em>如图</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>常常用线性变换来指代全连接层。因此,本文对两种说法不加以区分。⁞4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。与普通全连接层使用的线性变换不同,<em class='similar'>分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接。</em>在不同的网络层,通过设定神经元被划分的组数,可以控制整个网络的参数量。对于一个层全连接网络,与分别为第层的输入和输出,为层神经元所分的组数。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong>具体地,<em class='similar'>通过在不同的网络层中设定神经元被划分的组数,</em><em class='similar'>可以控制整个网络模型的参数量。</em>例如,<em class='similar'>对于一个层全连接网络,</em>假设与分别表示第</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>4.2.1分层分组线性变换⁞图4.1是分层分组线性变换的示意图。与普通全连接层使用的线性变换不同,分层分组线性变换允许下层网络中的一部分神经元与上一层网络的部分神经元全连接。<em class='similar'>在不同的网络层,</em><em class='similar'>通过设定神经元被划分的组数,</em><em class='similar'>可以控制整个网络的参数量。</em><em class='similar'>对于一个层全连接网络,</em>与分别为第层的输入和输出,为层神经元所分的组数。对于普通全连接网络,其参数量为,若采用分层分组线性变换,其参数量为。可见,在网络层数和每层神经元个数相同的情况下,分层分组线性变换的参数量是对应全连接</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_9" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">31.5%(393字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110367779_2.html" target="_blank">基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程_2</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.3%(79字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110367779.html" target="_blank">基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.3%(79字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=加强特征的时空图卷积轨道交通线网客流预测" target="_blank">加强特征的时空图卷积轨道交通线网客流预测</a></span>
                      <p>许晗 -
                        《北京建筑大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于概念交互图的长文本匹配研究" target="_blank">基于概念交互图的长文本匹配研究</a></span>
                      <p>郭苏州 -
                        《中原工学院硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>假设输入向量和输出向量分别为和,</em><em class='similar'>GLT 首先根据维度和构建个维度逐渐增加的中间层,</em><em class='similar'>若需要进行变换的向量维度</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>性变换能够以相对较少的参数量进行有效学习。第层中的各个神经元,都能够通过多种路径到达输入向量的某个输入神经元,以降低信息在流动过程中的损失。<em class='similar'>令与分别代表输入向量和输入向量。</em><em class='similar'>分层分组线性变换首先根据维度和构建个维度逐渐增加的中间层。</em>因此,层的输出向量比层的输出向量拥有更大的维度。<em class='similar'>若进行变换的向量维度能够被规定的最大组数整除,</em>某一层的输出向量可以通过式(4.1)得到。⁞(4.1)⁞式(4.1)中,——层所分组数,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>式中,表示分组线性变换操作;<em class='similar'>表示第层的可训练的权重矩阵;</em>表示第层的划分组数,值为。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>炸或者梯度消失问题的出现,为了避免此问题,对算子进行进一步优化,令,,进而将优化后算子扩展至拥有 Q 个通⁞道的图信号输入中,得到神经网络第层输出为⁞(3-13)<em class='similar'>其中是在特定层中的可训练权重矩阵,</em><em class='similar'>表示激活函数,</em><em class='similar'>表示第层的特征矩阵。</em>至此,可以得到 GCN 图卷积神经网络的信息传播过程。⁞3.2 BiLSTM 神经网络结构⁞3.2.1 LSTM 神经网络⁞长短时记忆网络 LSTM 是一种可以处理时间序列数据的神经网络模型,</p>
	                    <div class="textFrom">——北京建筑大学硕士论文 许晗-《加强特征的时空图卷积轨道交通线网客流预测》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现子域空间的交互,使用大池化方法得到终线性表示。图神⁞经网络的公式如下:⁞()=()()(3-5)⁞其中=+,图的邻接矩阵;是单位矩阵,表示的度矩阵,即:=∑;⁞是激活函数;()<em class='similar'>表示第层的可训练的权重矩阵;</em>()=,为输入的图顶点特征。⁞为充分利用文本信息,本文将利用传统的文本相似度计算方法,抽取出全局特征信息,将其与以上方法获得两个全局特征向量,拼接为一个向量表征,然后将该向量传入到分类器中,</p>
	                    <div class="textFrom">——中原工学院硕士论文 郭苏州-《基于概念交互图的长文本匹配研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>ansformation,RGLT),<em class='similar'>在此基础上可以构建包含维度扩张和维度收缩两个阶段的&quot;钻石&quot;型缩放单元,</em>如图3-3(b)所示。<em class='similar'>缩放单元由5个配置参数决定:</em><em class='similar'>深度</em><em class='similar'>(层数)</em><em class='similar'>、宽度因子、</em><em class='similar'>输入维度、</em><em class='similar'>输出维度和分组线性变换的最大组数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>基于分组线性变换,可以形成网络更深、<em class='similar'>包含扩张和收缩两个阶段的&quot;缩放单元&quot;。</em>在扩张阶段,分组组数随着网络深度的加深而变多,神经元数量也会变多,反之亦然。<em class='similar'>在&quot;缩放单元&quot;中配置5个配置参数:</em><em class='similar'>深度n、</em><em class='similar'>宽度因子mw、</em><em class='similar'>输入维度dm、</em><em class='similar'>输出维度do、</em><em class='similar'>最大组数gmax。</em>在扩张阶段,该单元将维度为dm的输入序列映射到更高维度(限制最高维度dmax=mwdm),同时各层层数将会线性地增加到层。</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>然后使用混合器将分组的输入和输出混合,<em class='similar'>形成扩张和收缩两个阶段的&quot;缩放单元&quot;;</em>在扩张阶段,分组组数随着网络深度的加深而变多,神经元数量也会变多,反之亦然;在收缩阶段,<em class='similar'>&quot;缩放单元&quot;中配置5个配置参数:</em><em class='similar'>深度n、</em><em class='similar'>宽度因子mw、</em><em class='similar'>输入维度dm、</em><em class='similar'>输出维度do、</em><em class='similar'>最大组数gmax;</em>在扩张阶段,该单元将维度为dm的输入序列映射到更高维度,限制最高维度dmax=mwdm,</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程_2》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>取值为⁞——层所使用的线性变换⁞——层所学习的权重⁞4.2.2扩张缩放单元⁞在分层分组线性变换的基础上,<em class='similar'>可以构建含有维度扩张和维度收缩两个主要阶段的扩张缩放单元。</em>该单元首先将输入向量变换到更高维度,使网络具有比较强大的学习能力,再将维度进行收缩以匹配模型维度,进而减少整个模型的参数量。<em class='similar'>扩张缩放单元由5个参数进行描述:</em>(1)<em class='similar'>深度</em><em class='similar'>(层数)</em>;</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>表示切分混合函数。<em class='similar'>以第2层为例,</em><em class='similar'>首先将上一层的输出和原始输入根据该层组数分别按相同规律切分,</em>得到、、和</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>2(a)简要描述了扩张缩放单元的一个基本计算步骤。由图4.2(b)可知,该计算步骤两个主要的操作,分别为函数的分组切分、混合器混合以及的分层分组线性变换。<em class='similar'>以第二层为例,</em>首先将上一层(Layer-1)<em class='similar'>的输出和原始输入根据该层组数,</em><em class='similar'>分别按照相同的切分规律进行切分得到4个中间向量,</em>其中前两个向量、拆分自,后两个向量、拆分自。然后按照顺序将、进行合并,、进行合并,得到的两个向量即为的输出结果。最后将的输出结果送入进行处理便得到最终输出。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>等4个向量;<em class='similar'>然后按特定顺序合并和、</em>和,<em class='similar'>组合得到的两个向量即为的输出;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>分层分组线性变换。以第二层为例,首先将上一层(Layer-1)的输出和原始输入根据该层组数,分别按照相同的切分规律进行切分得到4个中间向量,其中前两个向量、拆分自,后两个向量、拆分自。<em class='similar'>然后按照顺序将、</em><em class='similar'>进行合并,</em>、进行合并,<em class='similar'>得到的两个向量即为的输出结果。</em>最后将的输出结果送入进行处理便得到最终输出。式(4.2)-(4.3)描述了第层输出的计算过程。⁞(4.2)⁞(4.3)⁞式(4.2)-(4.3)中,——分层分组线性变换,输入为序列或中间层输出结果⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>将维度为的输入向量经过前层映射到最高维度为的向量,</em>使网络模型具有比较强大的学习能力;<em class='similar'>在收缩阶段,</em><em class='similar'>将最高维度向量经过剩下的层变换为输出维度,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>(a)扩张缩放单元基本计算步骤(b)扩张缩放单元示意图(c)逐块缩放策略⁞图4.2扩张缩放单元和逐块缩放策略示意图⁞扩张缩放单元的示意图见图4.2(b)。在扩张阶段,<em class='similar'>维度为的输入向量将在前层中被逐层映射到维度为的最高维度向量。</em><em class='similar'>在收缩阶段,</em><em class='similar'>使用剩余的层将最高维度变换到输出维度。</em>分层分组线性变换的输入为原始输入序列或中间层的输出结果,其中,为切分混合函数,图4.2(a)简要描述了扩张缩放单元的一个基本计算步骤。由图4.2(b)可知,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>对于某些层数较深的网络,</em>可以基于逐块缩放策略(如图3-3<em class='similar'>(c)</em>所示)<em class='similar'>在其组件中嵌入缩放单元,</em><em class='similar'>以适应其训练过程中向量维度的变化。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>式(4.2)-(4.3)描述了第层输出的计算过程。⁞(4.2)⁞(4.3)⁞式(4.2)-(4.3)中,——分层分组线性变换,输入为序列或中间层输出结果⁞、<em class='similar'>——当前层的权值矩阵和偏置向量⁞对于某些复杂且较深的网络,</em><em class='similar'>可以在网络各子组件中嵌入逐块缩放的扩张缩放单元,</em><em class='similar'>以适应计算过程中向量维度和深度的变化。</em>图4.2<em class='similar'>(c)</em>为逐块缩放策略的示意图。图4.2<em class='similar'>(c)</em>中,每一个六边形为一个扩张缩放单元,对于一个位置为的扩张缩放单元,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong>上式中,和均<em class='similar'>为超参数</em>,<em class='similar'>分别表示最小深度和最大深度;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>还考虑构筑块之间的堆叠所造成的影响;在各个构筑块间引入不同的深度和宽度因子约束:其中,nb和为第b块&quot;缩放单元&quot;的深度和宽度因子,b表示总块数,nmin与nmax<em class='similar'>为超参数</em>,<em class='similar'>为设定的最小深度和最大深度;</em>每个块中,在&quot;缩放单元&quot;之后级联自注意力机制、互注意力机制和前馈网络,形成解码网络。本发明的有益效果在于:从模型算法角度出发,为解决语音识别在边缘计算设备上的轻量化部署难题提供一种新的方法,通过基于自适</p>
	                    <div class="textFrom">——网页 -《基于自适应掩膜和分组线性变换的轻量级语音识别方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_10" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">30.3%(337字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>中的 ReLU 函数,</em><em class='similar'>它所求得的梯度更加平滑,</em><em class='similar'>更有利于模型进行训练。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>轻量级前馈网络层的参数量将是前者的。⁞⁞(a)普通前馈网络层(b)轻量级前馈网络层⁞图4.4两种前馈网络层示意图⁞在激活函数方面,轻量级前馈网络层选择了最近提出的MISH激活函数[61]。<em class='similar'>MISH激活函数求得的梯度相较于ReLU更加平滑,</em><em class='similar'>更有利于模型进行学习。</em>其表达式见式(4.6)。⁞(4.6)⁞4.3.3改进Transformer模型的结构⁞在第三章改进Transformer模型的基础上,采用本章所介绍的内容对解码器网络进行优化,进而得到如图4.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>在每个轻量级解码器块中,</em><em class='similar'>首先使用缩放单元完成输入序列的深度和宽度缩放,</em><em class='similar'>而深度因子和宽度因子将逐块增加,</em>所以缩放单元的深度和宽度会随着其靠近输出端的程度而增加;<em class='similar'>此外其中的注意力机制与普通解码器中的注意力机制有所不同,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并将普通的前馈网络层替换为改进的轻量级前馈网络层(Lightweight Position-wise Feedforward Network, LPFN),便形成了如图4.3所示的轻量级解码器块。在每一个块中,<em class='similar'>首先通过一个扩张缩放单元完成输入序列的深度缩放和宽度缩放,</em><em class='similar'>扩张缩放单元配置参数中的深度和宽度因子将逐块增加。</em>越靠近输出端,扩张缩放单元内部结构将变得更宽、更深。<em class='similar'>其次,</em><em class='similar'>解码器端自注意力机制和普通自注意力机制有所不同,</em>普通自注意力机制使用的三个权值矩阵通常用于将输入序列维度减小以减小计算量。<em class='similar'>而在轻量级解码器块中,</em>由于扩张缩放单元的输出向量维度较低,因此前面的解码器掩膜自注意力的权值矩阵不</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>普通注意力机制使用三个权重矩阵来减小输入序列的维度,</em><em class='similar'>而在轻量级解码器块中,</em><em class='similar'>由于缩放单元的输出向量维度较低,</em><em class='similar'>所以其注意力机制不需要再次减小输入序列的维度,</em><em class='similar'>只需通过线性层将序列维度映射至模型维度,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>扩张缩放单元配置参数中的深度和宽度因子将逐块增加。越靠近输出端,扩张缩放单元内部结构将变得更宽、更深。其次,解码器端自注意力机制和普通自注意力机制有所不同,<em class='similar'>普通自注意力机制使用的三个权值矩阵通常用于将输入序列维度减小以减小计算量。</em><em class='similar'>而在轻量级解码器块中,</em><em class='similar'>由于扩张缩放单元的输出向量维度较低,</em>因此前面的解码器掩膜自注意力的权值矩阵不必减小输入序列的维度,<em class='similar'>只需将计算得到的序列通过输出线性层映射到模型的维度。</em>在此之后使用的编码器-解码器自注意力也是如此。最后使用轻量级前馈网络层代替普通前馈网络层进一步减少参数量。⁞4.3.2轻量级前馈网络层⁞类似于普通的前馈网络层,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>在原始 Transformer 模型的基础上,</em><em class='similar'>采用上述内容对解码器部分进行优化,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>61]。MISH激活函数求得的梯度相较于ReLU更加平滑,更有利于模型进行学习。其表达式见式(4.6)。⁞(4.6)⁞4.3.3改进Transformer模型的结构⁞在第三章改进Transformer模型的基础上,<em class='similar'>采用本章所介绍的内容对解码器网络进行优化,</em>进而得到如图4.5所示的改进的轻量化Transformer模型。其中,编码器采用&quot;ALDSA-自注意力&quot;级联形式的融合注意力机制以完成语音特征的高效提取。解码器网络由基于分</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong> LSRA),并使用专门的表示子空间以提取不同范围的特征。LSRA利用卷积操作对序列间的依赖关系进行建模,以准确率小幅降低作为代价,换来了推理速度的极大提高。<em class='similar'>⁞本章工作在第三章改进Transformer模型的基础上,</em><em class='similar'>侧重于对解码器部分进行优化。</em>具体来讲,通过将机器翻译领域提出的DExTra模块[59,60]迁移并应用到语音识别领域的Transformer模型上,实现了解码器的轻量化。⁞4.2基于分层分组线性变换的扩张缩放单元⁞</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_11" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">23.1%(392字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于RNN-Transducer的端到端长时语音识别模型研究及系统实现" target="_blank">基于RNN-Transducer的端到端长时语音识别模型研究及系统实现</a></span>
                      <p>李泽瑞 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">6%(102字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=融合语言模型的端到端语音识别算法研究" target="_blank">融合语言模型的端到端语音识别算法研究</a></span>
                      <p>吕坤儒 -
                        《吉林大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(54字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="https://blog.csdn.net/colleges/article/details/122144163" target="_blank">3-Python数据划分代码-小记_骑着蜗牛环游深度学习世界的博客-CSDN博客_划分数据集python代码</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>实验环境包含硬件和软件两部分。<em class='similar'>在硬件方面,</em><em class='similar'>主要使用一台高性能服务器来完成所有模型的训练;</em>在软件方面,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>该词汇表共含有503个建模单位。⁞3.5实验配置⁞本节首先给出实验的软硬件环境,然后从网络模型的超参数配置、模型评价指标等方面描述模型的详细训练信息。⁞3.5.1<em class='similar'>实验环境⁞在硬件方面,</em><em class='similar'>本文使用了一台高性能服务器来完成所有模型的训练。</em>其主要配置为:处理器CPU/2×Intel(R) Xeon(R) CPU E5-2680 v4@2.40GHz;内存Memory/8×ECC Registered DDR4@32GB;显卡GPU/4×NVIDIA Tesla P100@16GB。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>来自于400个来自中国不同口音区域的发言人,<em class='similar'>内容涉及智能家居、</em><em class='similar'>无人驾驶和工业生产等11个领域;</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>3.2.3实验数据⁞本实验使用中文语音数据集 AISHELL[53]和 Thchs30,其中 AISHELL 数据集⁞由北京希尔贝壳公司开源,其录音文本涉及金融、房产、<em class='similar'>智能家居、</em><em class='similar'>工业生产等⁞11个领域,</em>由来自中国不同口音地区的发言人在安静室内环境中使用高保真麦⁞克风参与录制并采样降至16 KHZ,经过专业语音校对人员转写注释并通过严格⁞质量检验,此数据集约160小时的语音数据,</p>
	                    <div class="textFrom">——吉林大学硕士论文 吕坤儒-《融合语言模型的端到端语音识别算法研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>LIUM2都按照一定的比例被划分为训练集</em><em class='similar'>(Train)</em><em class='similar'>、验证集</em>(Val)<em class='similar'>和测试集</em><em class='similar'>(Test)</em>三个子集,<em class='similar'>前者的划分比例参照文献</em>[63],</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>是相对路径。output_dir：训练集、<em class='similar'>测试集、</em>验证集文件所在的目录，是相对路径。split_prop：划分比例的列表。<em class='similar'>这里参照了文献的划分比例，</em>即[训练集:<em class='similar'>验证集:</em><em class='similar'>测试集]</em>=[3:1:2]。该列表共三个元素，例如[3,1,2]，表示[训练集:<em class='similar'>验证集:</em><em class='similar'>测试集]</em>=[3:1:2]。⁞3划分过程⁞3.1读取待划分数据⁞这里使用了numpy.</p>
	                    <div class="textFrom">——网页 -《3-Python数据划分代码-小记_骑着蜗牛环游深度学习世界的博客-CSDN博客_划分数据集python代码》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>语音采样频率为16kHz,其语音数据组成结构如表2-3所示。共包括来自中国不同地区的600个说话人参与语音录制,录音全部在室内的安静环境中完成,文本标注序列正确率在98%以上。aidatatang_200zh数据集按照7:<em class='similar'>1:2的比例划分为训练集</em><em class='similar'>(Train)</em><em class='similar'>、验证集</em>(Dev)<em class='similar'>和测试集</em><em class='similar'>(Test)。</em>其中训练集包括420名说话人录制的165k条语句,验证集包括60名说话人录制的24k条语句,测试集包括120名说话人录制的48k条语句。⁞表2-3.</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 李泽瑞-《基于RNN-Transducer的端到端长时语音识别模型研究及系统实现》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>指标为词错误率</em><em class='similar'>(Word Error Rate,</em><em class='similar'>WER)。</em><em class='similar'>CER 和 WER 的计算方式如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对于AISHELL-1数据集,其以汉字单字符为建模单位,本文使用字错误率(Character Error Rate, CER)来描述其准确度;对于TED-LUM2,其以一元模型为基本建模单位,<em class='similar'>对应指标为单词错误率</em><em class='similar'>(Word Error Rate,</em><em class='similar'> WER)。</em><em class='similar'>CER和WER计算方式见式</em>(3.17)。⁞(3.17)⁞式(3.17)中,——相较于参考文本替换的字符(单词)数⁞——相较于参考文本增加的字符(单词)数⁞——相较于参考文本删除的字符(单词)数⁞——参考文本的字符(单词)数⁞3.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>增加和删除<em class='similar'>的字符</em><em class='similar'>(单词)</em><em class='similar'>数;</em><em class='similar'>表示正确文本的总字符</em><em class='similar'>(单词)</em>数。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>对应指标为单词错误率(Word Error Rate, WER)。CER和WER计算方式见式(3.17)。⁞(3.17)⁞式(3.17)中,——相较于参考文本替换<em class='similar'>的字符</em><em class='similar'>(单词)</em>数⁞——相较于参考文本增加的字符<em class='similar'>(单词)</em>数⁞——相较于参考文本删除的字符<em class='similar'>(单词)</em><em class='similar'>数⁞——参考文本的字符</em><em class='similar'>(单词)</em>数⁞3.6实验结果及分析⁞本小结首先探索自注意力机制和ALDSA在拓扑结构上的结合方式,通过消融实验得到最优的融合注意力机制。在此基础上,继续给出基于ALDSA的Transfomer模型、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_12" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">40.4%(606字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多任务学习的坐姿检测系统研究与实现" target="_blank">基于多任务学习的坐姿检测系统研究与实现</a></span>
                      <p>胡昊杰 -
                        《华南理工大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4.1%(62字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多分支聚合网络的短语音说话人确认方法研究" target="_blank">基于多分支聚合网络的短语音说话人确认方法研究</a></span>
                      <p>杨宇奇 -
                        《哈尔滨工业大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4%(60字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于交通流量预测的边缘智能部署优化" target="_blank">基于交通流量预测的边缘智能部署优化</a></span>
                      <p>郭嘉宸 -
                        《青岛科技大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.8%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络" target="_blank">GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络</a></span>
                      <p>倪伟健;秦会斌 -
                        《电子技术应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/201911189228.html" target="_blank">文本图像处理方法、文本及卡证图像质量评价方法和装置与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://www.xjishu.com/zhuanli/52/201310692957.html" target="_blank">红外传感器输出信号的滤波方法、装置及红外气体分析仪的制作方法</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://www.xsqkfb.com/lglw/21572.html" target="_blank">人脸识别与活体检测在嵌入式上的优化-学术期刊发表网</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.1%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://www.xjishu.com/zhuanli/62/202110121731.html" target="_blank">联合超分辨率和视频编码的目标跟踪方法、装置、设备及介质与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://www.doc88.com/p%2D9909660946819.html" target="_blank">基于多深度模型集成的音频场景分类方法研究 - 道客巴巴</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.7%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于MG训练准则的说话人表征研究" target="_blank">基于MG训练准则的说话人表征研究</a></span>
                      <p>韩姣 -
                        《西北民族大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.7%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_12" class="simMore"><a href="javascript:$ShowMore(12);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>Operations,<em class='similar'>FLOPs)</em>的。<em class='similar'>对于将输入维度映射为输出维度的单层</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong> MACs)[62]来反映网络实际的计算量。在相同的条件下,对于同一个网络,MACs约是另一个反映网络复杂度的指标——浮点运算数(Floating Point Operations,<em class='similar'> FLOPs)</em>的0.5倍。<em class='similar'>⁞对于一层将输入维度映射为输出维度的全连接网络,</em>MACs的计算方式见式(4.7)。⁞(4.7)⁞对于较为复杂的卷积操作,MACs的计算方式如下:⁞(4.8)⁞式4.8中,、——卷积核的高度、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>对于较为复杂的卷积操作,</em><em class='similar'>MACs 值的计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>Cs约是另一个反映网络复杂度的指标——浮点运算数(Floating Point Operations, FLOPs)的0.5倍。⁞对于一层将输入维度映射为输出维度的全连接网络,MACs的计算方式见式(4.7)。⁞(4.7)<em class='similar'>⁞对于较为复杂的卷积操作,</em><em class='similar'>MACs的计算方式如下:</em>⁞(4.8)⁞式4.8中,、——卷积核的高度、宽度⁞、——输入通道数、输出通道数⁞、——输出图像的高度和宽度⁞4.5实验结果及分析⁞本节首先通过对比实验验证改进模型的相关性能,特别是参数量、</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>式中,<em class='similar'>和分别表示卷积核的高度和宽度;</em><em class='similar'>和分别表示输入和输出的通道数;</em><em class='similar'>和分别表示输出图像的高度和宽度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>深度可分离通道卷积⁞标准卷积层中,输入为Df×Df×m的特征图,输出为为Dg×Dg×n的特征图。其中Df为输入特征图<em class='similar'>的宽度和高度</em>,<em class='similar'>Dg为输出特征图的宽度和高度,</em><em class='similar'>m和n分别为输入和输出的通道数。</em>一个卷积层的参数量取决于卷积核的参数量,而卷积核的参数量又与m×n的大小密切相关。共享且密集的通道卷积层的输入输出特征图与标准卷积层的输入输出特征图相同,但是卷积核只</p>
	                    <div class="textFrom">——网页 -《人脸识别与活体检测在嵌入式上的优化-学术期刊发表网》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>所以标准的卷积层的卷积核的大小为Dw DH m,一共有n个,其中.Dw和DH(一般相等)是卷积核的宽度和高度。因此,标准卷积层⁞的参数量数量为:⁞Dw‘DH m‘凡(1)⁞其中,<em class='similar'>%和Dn分别是卷积核的宽度和高度,</em><em class='similar'>m和n分⁞别是输入和输出特征图的通道数。</em>⁞从上述分析中,标准卷积层参数的大小取决于输入特征通道数m和输出特征通道数厅的乘积m 凡的大小。为了能够减少卷积层的参数,</p>
	                    <div class="textFrom">——电子技术应用 倪伟健；秦会斌-《GSDCPeleeNet:基于PeleeNet的高效轻量化卷积神经网络》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>然后通过1×1的逐点卷积对得到的特征图进行维度扩张。从表3-1可以看到,使用深度可分离卷积后,卷积操作的参数量和计算量均下降至⁞原来的⁞𝐷KW×𝐷KH左右。其中𝐷KW、<em class='similar'>𝐷KH分别为卷积核的宽高,</em>𝐶in、𝐶out分别表示输入和输出特征图的通道数,<em class='similar'>𝐷W、𝐷H分别表示输出特征图的宽、</em>高。⁞图3-4标准卷积操作⁞图3-5深度可分离卷积操作⁞表3-1使用深度可分离卷积前后卷积操作参数量和计算量比较⁞参数量计算量⁞</p>
	                    <div class="textFrom">——华南理工大学硕士论文 胡昊杰-《基于多任务学习的坐姿检测系统研究与实现》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>论文使用应用较为广泛的频域 FBank 特征作为语音信号的声学特征</em>[66]。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>增加语音增强对照组,在训练之前,对语音数据进行了加混响(MUSAN数据集)和噪声(RIRS_NOISES)。⁞关于语音长度问题,该实验从每个音频中随机抽取3秒的语音片段,<em class='similar'>使用40维的Fbank特征作为语音信号的声学特征。</em>⁞具体数据如下表3.4所示。⁞表3.4相关数据集设置⁞数据集 Vox1_training set Vox2_test set ⁞说话人个数(个)1251118⁞语音总时长(小时)35248⁞句子总数(条)</p>
	                    <div class="textFrom">——西北民族大学硕士论文 韩姣-《基于MG训练准则的说话人表征研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>然后对每一帧进行快速傅里叶变换将时域信号转变为频域信号并计算</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并且计算时间短。⁞[0007]为了实现上述目的,现提出的方案如下:⁞[0008]—种红外传感器输出信号的滤波方法,包括:⁞[0009]获取红外传感器输出信号,计算红外传感器输出信号的固定频率;⁞[0010]<em class='similar'>对所述输出信号进行快速傅里叶变换,</em><em class='similar'>将时域信号转变为频域信号;</em>⁞[0011]保留所述固定频率的幅值,将其它频率的幅值置为零。⁞[0012]优选的,在步骤获取红外传感器输出信号之前包括:对红外传感器输出信号进行信号放大。⁞</p>
	                    <div class="textFrom">——网页 -《红外传感器输出信号的滤波方法、装置及红外气体分析仪的制作方法》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>需要对音频信号进行预处理,包括用于补偿高频分量的预处理,将准稳态的音频信号转变为短时稳态信号处理的分帧和加窗。<em class='similar'>然后,</em><em class='similar'>对信号进行快速傅里叶变换,</em><em class='similar'>将时域信号转变为频域信号。</em>其次,计算每帧的能量频谱,并用 Mel 滤波器模拟耳膜进行滤波,最后将 Mel 滤波能量取对数后,再进行离散余弦变换(Discrete Consine Transform, DCT),</p>
	                    <div class="textFrom">——网页 -《基于多深度模型集成的音频场景分类方法研究 - 道客巴巴》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>论文设置25ms 帧长和10ms 帧移来提取 FBank 特征,</em>其维度为80;<em class='similar'>对于 TED-LIUM2,</em><em class='similar'>在80维 FBank 特征的基础上额外增加了3维 Pitch</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>区域人数比例(%)⁞北方33383⁞南方3810⁞粤贵闽184⁞其它113⁞合计400100⁞3.4.2语音信号数据处理⁞对于AISHELL-1数据集,本文使用窗口25ms、帧移为10ms的40维FBANK特征作为模型的输入。<em class='similar'>对于TED-LIUM2,</em><em class='similar'>在80维FBANK特征的基础上还额外增加了3维的pitch,</em>总共83维FBANK特征。本文还使用了近期提出的SpecAugment[52]语音增强方法对训练集进行增强。在上述原始特征的基础上,本文使用一个含有两层卷积层的卷积模块对原始特征进行进一步处理。其中,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>3.4实验结果与分析⁞3.4.1实验网络参数⁞实验数据集仍然采用基线系统中介绍过的 Voxceleb1数据集。数据处理方面也继续对测试数据进行每3s、2s、1s 的切割。提取的 MFCC 特征为23维,帧长25ms,<em class='similar'>帧移10ms。</em><em class='similar'>提取的 Fbank 特征为40维,</em><em class='similar'>帧长25ms,</em>帧移10ms。其中,MFCC 特征输入 TDNN 分支和 S_TDNN 分支,Fbank 特征输入 L_TDNN分支。多分支聚合网络的结构参数如表3-3所示。</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 杨宇奇-《基于多分支聚合网络的短语音说话人确认方法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong><em class='similar'>步长为2、</em><em class='similar'>输出通道数为256、</em><em class='similar'>激活函数为 ReLU。</em>在卷积模块的作用下,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>第七层:可分离卷积层,其卷积核为3*3,<em class='similar'>步长为2,</em>使用batchnorm,<em class='similar'>激活函数为relu,</em><em class='similar'>输出通道数为256,</em>其输出的featuremap为2*2*256。第八层:1*1卷积层,其卷积核为1*1,步长为1,使用batchnorm,<em class='similar'>激活函数为relu,</em><em class='similar'>输出通道数为256,</em>其输出的featuremap为2*2*256。该1*1卷积层也可以用于整合通道之间的关系。第九层:可分离卷积层,其卷积核为3*3,<em class='similar'>步长为2,</em></p>
	                    <div class="textFrom">——网页 -《文本图像处理方法、文本及卡证图像质量评价方法和装置与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>压缩效率极高。需要注意,并不限于avs3标准。57.将压缩后的码流进行视频重构,并将重构视频逐帧输入超分辨网络。58.进入网络后的图像先进行特征提取,以5x5大小的卷积核进行步长为1的卷积操作,<em class='similar'>输出通道数为56,</em><em class='similar'>激活函数为relu。</em>59.在得到的特征图上进行坍缩操作(shrinking),此处使用3x3的感受野,<em class='similar'>输出通道数为12,</em><em class='similar'>激活函数为relu。</em>60.再对坍缩后的卷积层进行映射(mapping)操作,使用卷积核大小为3x3,</p>
	                    <div class="textFrom">——网页 -《联合超分辨率和视频编码的目标跟踪方法、装置、设备及介质与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>两个一维卷积层、两个池化层以及一个输出层。卷积层卷积核个数为4、3、3,滤波器的个数为8、32、32,<em class='similar'>池化层步长为2,</em><em class='similar'>激活函数为 RELU 函数。</em>在 LSTM 网络中将卷积模块的输出作为LSTM 网络的输入,设置4层网络,分别为两层 LSTM 以及两层全连接层,激活函数为 tanh。⁞(2)LSTM。模型包含一个输入层、隐藏层以及一个输出层,</p>
	                    <div class="textFrom">——青岛科技大学硕士论文 郭嘉宸-《基于交通流量预测的边缘智能部署优化》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>对于 AISHELL-1,</em><em class='similar'>论文使用4336个不同的字符来构成词汇表</em><em class='similar'>(字典)</em><em class='similar'>,其中4333个字符来自于原始标注文本,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>的卷积模块对原始特征进行进一步处理。其中,两层卷积层的超参数为:卷积核、步长2、输出通道256以及ReLU激活函数。通过上述卷积模块,原始特征时间步将被压缩为原来的长度。⁞在标签处理方面,<em class='similar'>对于AISHELL-1数据集,</em><em class='similar'>本文共使用不同的4336个字符来构成词汇表</em><em class='similar'>(字典)</em><em class='similar'>。词汇表中4333个字符统计自于AISHELL-1标注文本。</em>除此之外,还增加了&quot;&lt;EOS/BOS&gt;&quot;、&quot;&lt;PAD&gt;&quot;以及&quot;&lt;UNK&gt;&quot;这3个额外的特殊字符用于辅助模型进行训练。其中 </p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>训练额外增加的特殊字符,</em>分别是、和。用于指示模型何时开始或停止输出字符序列;可以在训练阶段将一个批处理(Batch)<em class='similar'>大小的数据中不同长度的语音特征序列或字符序列填充到相同的长度;</em><em class='similar'>可在模型输出时替代某些在字典中未出现的字符,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>计自于AISHELL-1标注文本。除此之外,<em class='similar'>还增加了&quot;&lt;EOS/BOS&gt;&quot;、</em><em class='similar'>&quot;&lt;PAD&gt;&quot;以及&quot;&lt;UNK&gt;&quot;这3个额外的特殊字符用于辅助模型进行训练。</em><em class='similar'>其中 EOS/BOS&gt;&quot;字符用于指示模型开始或停止输出字符序列 PAD&gt;&quot;字符用于在训练阶段将一个批处理数据中不同长度的语音特征序列或字符序列填充到相同的长度 UNK&gt;&quot;字符用于代替那些在词汇表中没有出现的输出字符,</em>以避免训练出现意料之外的错误。而对于TED-LUM2数据集,本文使用SentencePiece工具生成建模单位为一元模型(Unigram)的词汇表。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_13" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(90字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/21/202110488262.html" target="_blank">一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.6%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=主题可控的多文档摘要生成方法研究" target="_blank">主题可控的多文档摘要生成方法研究</a></span>
                      <p>何思博 -
                        《华中科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的方面级情感分类研究" target="_blank">基于深度学习的方面级情感分类研究</a></span>
                      <p>王媛媛 -
                        《重庆大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">1.7%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=非独立同分布词语相关度计算方法研究" target="_blank">非独立同分布词语相关度计算方法研究</a></span>
                      <p>张玉腾 -
                        《齐鲁工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_13" class="simMore"><a href="javascript:$ShowMore(13);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>改进的轻量级 Transformer 模型由12个编码器块和6个解码器块堆叠而成,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>未知符号&quot;&lt;unk 句子起始与结尾符号&quot;&lt;eos 填充符号&quot;&lt;pad&gt;&quot;和空格符号&quot;&lt;space&gt;&quot;)组成的词汇集。2、网络结构:如图1所示,本发明提出的resgsa-transformer是一种改进的speech-transformer,它由卷积前端、<em class='similar'>12个编码器子块、</em><em class='similar'>6个解码器子块和一个嵌入层的堆叠组成。</em>卷积前端采用两个2-d卷积层,卷积核大小为3*3,步长为2,通道数为256,激活函数为relu;编码器子块包含一个resgsa层和一个位置前馈模块;</p>
	                    <div class="textFrom">——网页 -《一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>⁞(,21) cos(/100002)modeli d⁞pos iPE pos(4.12)② Transformer 编码层:Transformer 编码层是在 ELMo 模型的基础上改进的。<em class='similar'>由6个编码器和6个解码器堆叠而成的 Transformer 代替了 ELMo 中的 LSTM。</em>其⁞输入⁞重庆大学硕士学位论文4基于 BERT 词嵌入的 SCBMA-BERT ⁞结构如图4.7所示。</p>
	                    <div class="textFrom">——重庆大学硕士论文 王媛媛-《基于深度学习的方面级情感分类研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>述基于高斯残差自注意力的resgsa-transformer模型是在speech-transformer基础上将其中的自注意力模块替换为高斯残差自注意力模块构成;所述基于高斯残差自注意力的resgsa-transformer模型由卷积前端、<em class='similar'>12个编码器子块、</em><em class='similar'>6个解码器子块和一个嵌入层堆叠组成;</em>所述卷积前端采用两个2-d卷积层,卷积核大小为3*3,步长为2,通道数为256,激活函数为relu;每个编码器子块包含一个高斯残差自注意力模块和一个位置前馈模块,</p>
	                    <div class="textFrom">——网页 -《一种基于残差高斯自注意力的Transformer端到端语音识别方法与流程》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>论文使用Kullback-Leibler散度作为模型训练的损失函数,</em>标签平滑度(Label</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>𝛽1值为0.9,𝛽2值为⁞华中科技大学硕士学位论文⁞0.998,学习率的权重衰减因子为0.01,学习率的变化方式为线性增长和下降,其中线性增长的步数占训练总步数的10%。<em class='similar'>⁞模型训练时使用的损失函数为 Kullback-Leibler 散度</em>(KL divergence),衡量了模型分布𝑄近似真实分布𝑃时的信息损失,KL 散度越大,模型分布的表达越差,计算公式如(4.1)所示。⁞𝐷𝐾𝐿(𝑃||𝑄)=∑𝑃(𝑥) log (𝑃(</p>
	                    <div class="textFrom">——华中科技大学硕士论文 何思博-《主题可控的多文档摘要生成方法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>论文使用了近期提出的 SpecAugment</em>[76]<em class='similar'>对训练集数据进行必要的增强。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>本文使用窗口25ms、帧移为10ms的40维FBANK特征作为模型的输入。对于TED-LIUM2,在80维FBANK特征的基础上还额外增加了3维的pitch,总共83维FBANK特征。<em class='similar'>本文还使用了近期提出的SpecAugment</em>[52]<em class='similar'>语音增强方法对训练集进行增强。</em>在上述原始特征的基础上,本文使用一个含有两层卷积层的卷积模块对原始特征进行进一步处理。其中,两层卷积层的超参数为:卷积核、步长2、输出通道256以及ReLU激活函数。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>LM)。<em class='similar'>在推理阶段,</em><em class='similar'>将原始声学模型和语言模型的预测结果以浅融合</em>[77]的方式</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>05.0⁞表示子空间个数44⁞FFN维度10241024⁞⁞2535⁞⁞22⁞遵从大多数语音识别系统的配置,本文除了声学模型外,还构建了与之配套的外部语言模型。<em class='similar'>在推理解码阶段,</em><em class='similar'>将声学模型的预测结果和语言模型的预测结果以浅融合</em>(Shallow Fusion, SF)的方式进行综合,能进一步提升识别准确率。对于AISHELL-1数据集,本文利用标注文本训练了一个2层LSTM网络,其模型维度为1024。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong>"↓"表示该项指标越低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>即低层次的显式共现⁞耦合,低层次的显式超链接耦合和高层次的隐式概念耦合。由于 CCE 具有全面捕⁞捉概念耦合的强大功能,因此在所有对比方法中获得了最佳结果。⁞(1)<em class='similar'>加粗表示最优结果,</em><em class='similar'>下划线表示次优结果,</em>*表示 CCE 比次优结果提升的百分比。齐鲁工业大学硕士学位论文⁞21⁞表3.2所有数据集上的平均斯皮尔曼秩相关性系数。。⁞Families  Methods </p>
	                    <div class="textFrom">——齐鲁工业大学硕士论文 张玉腾-《非独立同分布词语相关度计算方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_14" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">7.6%(127字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>在提出的轻量级 Transformer 模型的基础上,</em><em class='similar'>分别将轻量级解码器替换为普通解码器、</em><em class='similar'>将轻量级解码器的注意力表示子空间个数从4降低为1,</em>从而得到两个变种模型,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>整个模型表现的贡献程度。具体来讲,消融实验围绕ALDSA编码器、轻量级解码器以及注意力表示子空间个数这三个方面来进行。<em class='similar'>本文在本章所提出的改进Transformer模型的基础上,</em><em class='similar'>分别将ALDSA编码器替换为普通Transformer编码器、</em><em class='similar'>轻量级解码器网络替换为普通Transformer解码器网络以及将解码器的注意力表示子空间个数从4降低为1,</em>观察这些改动得到的变种模型在AISHELL-1和TED-LIUM2数据集上的相关指标,并将相关结果记录到了表4.4。表4.4中,BASE表示本章提出的改进模型,ND表示普通解码器网络,NE表示普通编码器网络,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 3 章 基于残差分组线性变换解码器的自动语音识别</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_15" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.2%(105字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=叶尖定时测量误差的高精度实验分析与修正" target="_blank">叶尖定时测量误差的高精度实验分析与修正</a></span>
                      <p>蒙一鸣;肖志成;欧阳华 -
                        《航空动力学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>ND 在验证集和测试集上的 CER 分别下降了0.18%和0.20%,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>mer的模型。本文提出的模型在没有语言模型辅助的情况下可以达到5.85%的CER,当使用语言模型时,甚至可以达到5.65%的CER。和对比方法中准确率表现最好的HA-Transformer模型相比,<em class='similar'>在验证集和测试集上的CER分别相对下降了7.4%和8.6%。</em>⁞表3.7 AISHELL-1数据集上的对比实验表⁞模型 CER(%)⁞ Eval Test⁞TDNN-Chain[53]⁞-7.45⁞LAS[30]⁞-10.56⁞SSAN[54]⁞-6.</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>若使用含有单个注意力表示子空间的轻量级解码器</em><em class='similar'>(SH),</em>相较于 Base 模型,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>观察这些改动得到的变种模型在AISHELL-1和TED-LIUM2数据集上的相关指标,并将相关结果记录到了表4.4。表4.4中,BASE表示本章提出的改进模型,ND表示普通解码器网络,NE表示普通编码器网络,<em class='similar'>SH表示轻量级解码器只使用一个注意力表示子空间,</em>所有的实验均在语言模型被移除的情况下进行的。⁞从表4.4可知,第三章提出的基于ALDSA的模型在识别准确率方面表现最好,但参数量和计算量都是最多的;仅使用轻量化解码器能大幅降低模型的参数量和计算量</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>其他三项分别作为横轴绘制散点图,</em><em class='similar'>如图3-9所示。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>t 时刻增量式编码器的输出线⁞数, sumn 为编码器旋转一圈的总输出线数。式(20)⁞所定义的轴位置误差本质上即为 t 时刻转速波动引起的误差。接下来分析轴位置误差与测量总误差之间的关系,<em class='similar'>以两者分别为横轴和纵轴绘制散点图,</em><em class='similar'>如图9所示。</em>对比数据点与 sp totale e的虚线参考线,可看出两者明显呈正比关系。其具体相关系数值见表2,不同传感器的相关系数值均处于0.98与0.995之间,可以确定该实验中转速波动是 </p>
	                    <div class="textFrom">——航空动力学报 蒙一鸣；肖志成；欧阳华-《叶尖定时测量误差的高精度实验分析与修正》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>需要考虑对于其中注意力表示子空间的个数选取,</em><em class='similar'>因为这在很大程度上会影响到模型的识别性能。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>器能大幅降低模型的参数量和计算量,但是会一定程度降低识别的准确率。综合两种特点的BASE模型在识别准确率、参数量以及计算量上都达到了一个较好的折中。此外,从消融实验可知,<em class='similar'>注意力机制中表示子空间的个数很大程度上影响到模型的识别准确率,</em>采用单一的表示子空间表现较差。⁞为了更加直观地说明提出方法的有效性,本文根据各变种模型在两个数据集上的CER/WER以及参数量绘制了图4.9。从图4.9可知,</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第4章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_16" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用泛函分析" target="_blank">应用泛函分析</a></span>
                      <p>腾岩梅，贾超华，冯伟杰等编著 -
                        《北京：北京航空航天大学出版社,2012.09
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=量子隐形传态线路的设计与分析" target="_blank">量子隐形传态线路的设计与分析</a></span>
                      <p>张国帅 -
                        《贵州大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=泛函分析与最优化理论" target="_blank">泛函分析与最优化理论</a></span>
                      <p>王日爽编著 -
                        《北京：北京航空航天大学出版社
                        》- 2003 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>述为:假设表示 Hilbert 空间、<em class='similar'>表示的一个子空间,</em><em class='similar'>对于一个给定向量,</em><em class='similar'>需要找到一个离最近的向量,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>首先有SUS」,,应用命题4,即有S」」,US\其次,仍⁞由命题3,又有&quot;U (1最后,结合起来,即有⁞SL±±=Slo投影定理⁞我们现在要讨论的最优化问题是,在内积空间或Hilbert空间中,<em class='similar'>给定一个向量x与一个子空间要求找出一个向量⁞它是M中距离x最近的向量。</em>这也就是说,要找出一个向量使得min || x — m ||=|| x —m0||。当然,当xGM时,答案是明显的,只需取%=x。然而,在一般情形下,要解决这个问题,</p>
	                    <div class="textFrom">——北京：北京航空航天大学出版社 王日爽编著-《泛函分析与最优化理论》-2003 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>9z=zi o⁞2.射影定理的应用⁞(1)最佳逼近问题⁞利用射影定理,可以解决在随机过程理论、逼近论、最优化理论以及其他学科中经常要碰到的最佳逼近问题。⁞设X是Hilbert空间,<em class='similar'>给定一个向量①C X和一个子空间M,</em>经常需要讨论是否唯一存在 yCM,使得||z—y∣∣=d(z,M)= inf ||n—z∣∣。这就是Hilbert空间中的最佳逼近问题。⁞z∈M⁞由射影定理及其证明过程可以看出,</p>
	                    <div class="textFrom">——北京：北京航空航天大学出版社,2012.09 腾岩梅，贾超华，冯伟杰等编著-《应用泛函分析》- （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>{,.,})m mspan ??(28)span ??。将1,.,m??生成一个H 的子空间⁞W ,其维数为 m ,通过对1,.,m??正交化和范化后可以得到W 的一组规范⁞正交基。设 H 为一个 Hilbert 空间,<em class='similar'>X 为 H 的一个子空间,</em><em class='similar'>一个向量?</em>与 X 正⁞交(记为??X )是指:?与X 中任意向量正交。由与 X 正交的所有向量张⁞成的子空间称为 X 的正交补空间。记为 X ?。X 与 X ?公共元只有零向量0。H⁞可以分解为直和: </p>
	                    <div class="textFrom">——贵州大学硕士论文 张国帅-《量子隐形传态线路的设计与分析》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_17" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于图神经网络的半监督文本分类算法研究" target="_blank">基于图神经网络的半监督文本分类算法研究</a></span>
                      <p>王钢坤 -
                        《北京邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">10.7%(97字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=时变转速下基于改进图注意力网络的轴承半监督故障诊断" target="_blank">时变转速下基于改进图注意力网络的轴承半监督故障诊断</a></span>
                      <p>邵海东;颜深;肖一鸣;刘翊 -
                        《电子与信息学报
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">8.5%(77字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://m.toutiao.com/i6955020864236667404" target="_blank">一文了解图注意力网络GAT</a></span>
                      <p>交大包老师 -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.4%(58字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110721336_2.html" target="_blank">一种基于堆叠LSTM的腰载式航向角计算方法与流程_2</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.2%(56字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://www.xjishu.com/zhuanli/05/202110219069.html" target="_blank">一种基于语义图网络的医疗预测方法及系统与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.2%(56字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="https://wenku.baidu.com/view/761d09c69cc3d5bbfd0a79563c1ec5da50e2d648" target="_blank">GAT模型的实际应用案例分析</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">6.1%(55字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=智能电网中虚假数据注入攻击的检测与防御研究" target="_blank">智能电网中虚假数据注入攻击的检测与防御研究</a></span>
                      <p>王媛媛 -
                        《华北电力大学(北京)博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">5.5%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的流程感知业务流程预测方法研究" target="_blank">基于深度学习的流程感知业务流程预测方法研究</a></span>
                      <p>宫子优 -
                        《安徽理工大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">5.3%(48字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="https://blog.csdn.net/jing_jing95/article/details/88836707" target="_blank">神经网络</a></span>
                      <p>csdn -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.3%(48字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=依存约束的图网络实体关系联合抽取" target="_blank">依存约束的图网络实体关系联合抽取</a></span>
                      <p>任鹏程;于强;侯召祥 -
                        《计算机系统应用
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">5.2%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://m.toutiao.com/i6915224100109615619/" target="_blank">全球首款商用图神经网络加速IP核正式发布</a></span>
                      <p>电脑商情报 -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.2%(47字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于多注意力机制的用户在线评论情感分析研究" target="_blank">基于多注意力机制的用户在线评论情感分析研究</a></span>
                      <p>周婷 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="https://www.doc88.com/p-58339018467068.html" target="_blank">基于图卷积和语义关系的人</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">5.1%(46字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于知识图谱和图注意力的众包任务推荐算法" target="_blank">基于知识图谱和图注意力的众包任务推荐算法</a></span>
                      <p>沈旭;王淑营;田媛梦;郑庆 -
                        《计算机应用研究
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(43字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202110853794.html" target="_blank">一种基于最短路径的图注意力神经网络方法与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.7%(42字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">16.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络的机器阅读理解综述" target="_blank">基于神经网络的机器阅读理解综述</a></span>
                      <p>顾迎捷;桂小林;李德福;沈毅;廖东 -
                        《软件学报
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.5%(32字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">17.</strong> <span><a href="http://xueshu.baidu.com/s?wd=视频群体行为分析与识别关键技术研究" target="_blank">视频群体行为分析与识别关键技术研究</a></span>
                      <p>徐得中 -
                        《北京工业大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(30字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">18.</strong> <span><a href="http://xueshu.baidu.com/s?wd=多模态数据的图表示学习" target="_blank">多模态数据的图表示学习</a></span>
                      <p>杨旭 -
                        《西安电子科技大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.1%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_17" class="simMore"><a href="javascript:$ShowMore(17);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'>GAT)[80]</em><em class='similar'>是一种图神经网络的变体,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>既实现了连接关系的利用,又通过嵌入的思想实现了实体和关系的低维空间向量表示。现有基于传播的方法主要通过将图神经网络融入知识图谱中,挖掘节点间的高阶连通关系。<em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'> GAT)</em><em class='similar'>是图神经网络的一种,</em>在 KGAT 中主要用于学习邻居权重并在传播时控制信息聚合的多少。KGAT 可选的聚合器有 GCN、GraphSage 和 Bi-Interaction,其中 Bi-Interaction 性能最好,</p>
	                    <div class="textFrom">——计算机应用研究 沈旭；王淑营；田媛梦；郑庆-《基于知识图谱和图注意力的众包任务推荐算法》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>但是通过模型进行联合抽取依旧面临挑战.⁞语句的依存分析是 NLP中处理文本的关键技术之一,其目标是确定句子的句法结构和各单词间的依存关系.图神经网络是图结构数据建模的有效模型,<em class='similar'>图注意力网络</em><em class='similar'>(Graph Attention Network,</em> GAT)[1]<em class='similar'>是一种空域图神经网络,</em>适用于动态图的处理,有利于将顶点特征之间的关联性更好得融合进模型.⁞为优化传统 Pipline方式并实现高效的实体关系联合抽取模型,本文综合依存分析和图注意力网络特性</p>
	                    <div class="textFrom">——计算机系统应用 任鹏程；于强；侯召祥-《依存约束的图网络实体关系联合抽取》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>大训练数据需求由于小归纳偏差;四、难以解释自我注意机制学习和输入的贡献令牌对预测。因此,已经有许多研究者提出了基于 Transformer 的改进方法[68][69]。⁞2.3.3<em class='similar'>图注意力网络⁞图注意力网络</em><em class='similar'>(Graph Attention Network,</em><em class='similar'>GAT)</em><em class='similar'>是对图神经网络</em>(Graph Neural ⁞Network)的一种改进,由 Velickovic 等人于2017年提出。该模型将注意力机制引入图神经网络中,与同样以 GNN 为基础的图卷积神经网络(</p>
	                    <div class="textFrom">——常州大学硕士论文 周婷-《基于多注意力机制的用户在线评论情感分析研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>与传统的图卷积神经网络</em><em class='similar'>(Graph Convolutional Network,</em><em class='similar'>GCN)</em>不同,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>步骤4:不断调整网络参数,根据准确率和损失函数获得最优训练模型;步骤5:将本发明模型结果与其他主流深度学习模型如卷积神经网络(convolutional neural networks, cnn)、<em class='similar'>图卷积神经网络</em><em class='similar'>(graph convolutional network,</em><em class='similar'> gcn)</em>以及不同传感器组合做对比,验证模型可行性;步骤6:实时行人移动时,调用最优训练模型,将实时传感器数据传入模型中,输出判断结果;步骤7:根据步骤6中的航向判断结果对方向传感器获得的航向角进行修正,从而得到最</p>
	                    <div class="textFrom">——网页 -《一种基于堆叠LSTM的腰载式航向角计算方法与流程_2》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>但目前图神经网络加速芯片在国际上还是一片&quot;无人区&quot;。2020年初,严明玉博士在国际计算机体系结构顶会 HPCA 上发表了国际第一个图神经网络的加速结构设计&quot;HyGCN&quot;。严明玉称,<em class='similar'>GCN即图卷积神经网络</em><em class='similar'>(Graph Convolutional Network,</em> GCN为其缩写),作为图神经网络最重要的一个分支,GCN将深度学习算法和图计算算法相融合,对搜索、推荐、风险控制在内的等诸多重要领域有着更优的认知与问题处理等能力;HyGCN寓意向图神经</p>
	                    <div class="textFrom">——网页 电脑商情报-《全球首款商用图神经网络加速IP核正式发布》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong><em class='similar'>GAT 接收节点特征作为输入,</em><em class='similar'>其中,</em><em class='similar'>表示节点个数,</em><em class='similar'>表示每个节点的特征个数;</em><em class='similar'>输出一组新的节点特征,</em><em class='similar'>其中</em><em class='similar'>(可能具有不同的基数)</em>。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>GAT结构—图注意力层在图注意力网络中,最重要的部分就是图注意力层(Graph Attention Layer),整个GAT结构就是该层的一个堆叠。在该层中,<em class='similar'>输入为一组节点的特征集合,</em><em class='similar'>其中N为节点个数,</em>F为节点特征数:<em class='similar'>输出为一组新的节点特征集合,</em><em class='similar'>其中N为节点个数,</em><em class='similar'>F&#39;为节点新的特征数:</em>因此该层可以看作是,对于N个节点,根据输入的F个特征,预测新的F&#39;个特征。图注意力机制所要做的就是将输入处理成所需要的输出,因此至少需要经过一次线性变</p>
	                    <div class="textFrom">——网页 交大包老师-《一文了解图注意力网络GAT》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(3-47)⁞Hkejfi exp(LeakyReLU(ar[Whi\\Whk])&#39;)⁞其中%是节点j到节点i的注意系数,队代表图中节点i的邻域。<em class='similar'>该层的节⁞点特征的输入集是其中N是节点数,</em><em class='similar'>F是每个节点的特⁞征数,</em><em class='similar'>该层产生一组新的节点特征</em><em class='similar'>(可能具有不同的基数F’)</em>,/i&#39;=⁞K,hr2eir&#39;作为其输出。we 是应用于每个节点的共享线性变换⁞的权重矩阵(the weight matrix)。aeK2F&#39;是单层前馈神经网络的权重向量。</p>
	                    <div class="textFrom">——华北电力大学(北京)博士论文 王媛媛-《智能电网中虚假数据注入攻击的检测与防御研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过叠加该层构造任意图注意网络。层通过计算节点对(i,j)注意机制中的系数:aij是节点j对i的注意系数,Ni表示图中节点i的邻域,<em class='similar'>该层的节点特征的输入集为,</em>hi∈,N是节点数量,<em class='similar'>F是每个节点的特征数,</em><em class='similar'>该层生成一组新的节点特性</em><em class='similar'>(可能具有不同的基数F&#39;)</em>,,作为输出。是应用于每个节点的共享线性变换的权矩阵,是单层前馈神经网络的权向量。它由一个SoftMax函数进行归一化,并应用了非线性LeakyReLU(负输入斜率=0:2)。</p>
	                    <div class="textFrom">——网页 csdn-《神经网络》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>能对新的节点实现实时学习与分类。⁞模型的输入层是一组节点特征表示,h =危工2,,E 6 rf,其中n<em class='similar'>是节点数</em>,<em class='similar'>F是每个节点的特征数。</em><em class='similar'>该层生成一组新的节点特征,</em><em class='similar'>这些节点特征可能具有不同的基数尸,</em>九,={丸&amp;,,牖}(言6产,)作为其输出。为了获得足够的表达能力将输入特征转换为更高层次的特征,至少需要一个可学习的线性变换。为此,作为初始步骤,</p>
	                    <div class="textFrom">——北京邮电大学硕士论文 王钢坤-《基于图神经网络的半监督文本分类算法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>此处所描述的具体实施例仅仅用以解释本发明,并不用于限定本发明。12.图注意力层该层的输入为一组节点特征,其中n<em class='similar'>为节点数</em>,<em class='similar'>f为每个节点的特征数。</em><em class='similar'>该层输出也为一组节点特征,</em><em class='similar'>其中特征基数f&#39;可能与输入f不相同。</em>为了得到输入输出的变换,至少要进行一次可学习的线性变换,所以需要对所有节点训练一个权值矩阵,这个矩阵就是f个输入特征与f&#39;个输出特征之间的关系。之后再对每一个节点施加一个</p>
	                    <div class="textFrom">——网页 -《一种基于最短路径的图注意力神经网络方法与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>6.</strong>样是一种归纳式学习,不需要知道整个图的信息,可以应用到动态图。⁞图注意力网络的基本结构注意力层的输入是一组节点特征 h {h1,h ,⁞2,,hN}⁞h F ,<em class='similar'>其中为节点个数,</em>为节点特征数量。<em class='similar'>输出是一组新的节点特征⁞i  N F⁞h⁞⁞</em>{h1,h,,h},h F ,F为新的节点特征数量。首先通过一个共享的注意⁞2 N i⁞力机制 a :</p>
	                    <div class="textFrom">——安徽理工大学硕士论文 宫子优-《基于深度学习的流程感知业务流程预测方法研究》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong><em class='similar'>为了将输入特征转化为更高层次的特征,</em><em class='similar'>首先将由权重矩阵参数化的共享线性变换应用于每个节点;</em><em class='similar'>然后在节点上使用自注意力机制计算系数</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>帧的数量为 n)。产生新的一组节点特征输出&#39;h ,&#39;&#39;&#39;&#39;⁞12{,}nh h h h=。<em class='similar'>为了获得足够的表达能力将输入特征转换为高级特征,</em>需要一种可学习的线性转换。<em class='similar'>首先将由权重矩阵 W 参数化的共享线性变换应用于每个节点,</em><em class='similar'>然后,</em><em class='similar'>在节⁞点上执行一种共享的注意力机制 a ,</em><em class='similar'>计算注意力系数 ije ⁞</em>(,)ij⁞i je a Wh Wh=(5-14)⁞之后,我们通过掩模(masked)注意力将结构信息注入模型。</p>
	                    <div class="textFrom">——北京工业大学博士论文 徐得中-《视频群体行为分析与识别关键技术研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>障诊断。⁞H ′⁞W ∈⁞Rd′×d⁞F⃗⁞以下描述节点级图注意力层的具体构造,输入为一组节点特征H,图注意力层能输出一组新的节点特征。为了获得足够的表达能力,<em class='similar'>需要进行线性变换将输入特征转化为更高层次的特征。</em><em class='similar'>为⁞此,</em>作为初始步骤,<em class='similar'>对每个节点应用权值矩阵参数化的共享线性变换,</em><em class='similar'>然后在节点上执行⁞一种共享的注意机制计算注意力系数。</em></p>
	                    <div class="textFrom">——电子与信息学报 邵海东；颜深；肖一鸣；刘翊-《时变转速下基于改进图注意力网络的轴承半监督故障诊断》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>n|},通过图注意力层将产生一个新的节点表示集合作为输出h={h′1,h′2 h′|n|},f′表示输出特征的维度。<em class='similar'>为了将输入转化为更高层次的输出特征,</em><em class='similar'>图注意力层将在每一个节点采用权重矩阵参数化共享的线性转换,</em><em class='similar'>并采用共享的注意力机制计算注意力系数,</em>如公式(7)所示:[0065][0066]其中,表示句子中由实体对vi和vj构成的图φ在领域本体中有关系r,er表示r的关系向量,</p>
	                    <div class="textFrom">——网页 -《一种基于语义图网络的医疗预测方法及系统与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>认为输入的多域样本之间的关系矩阵中可能存在错误,从而导致结果偏离最优解。因此图注意力网络采用了注意力机制,该机制优化了多个域样本的相似关系。图注意力网络由两个图注意力层构成。第一步,<em class='similar'>利用权重矩阵Θ参数化的共享线性变换来变换每个节点。</em><em class='similar'>然后,</em><em class='similar'>我们在节点上执行自我注意力权重计算,</em><em class='similar'>并采用共享注意力机制 a来计算注意力系数。</em>⁞eij = a(Θhi,Θhj),(6­8)⁞其中 eii =1表示自相关权重,主要用于自我注意力机制的训练。</p>
	                    <div class="textFrom">——西安电子科技大学博士论文 杨旭-《多模态数据的图表示学习》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>一个图神经层的结构如图所示我们至少要有一个可学习的线性变换来实现拥有充足的表达能力来将输入特征转换为我们需要的更高层的特征。因此,<em class='similar'>我们首先对每个节点应用由权重矩阵WRF&#39;F参数化的共享线性变换。</em><em class='similar'>然后</em>,图注意层首先根据输入的节点特征向量集,进行self-attention处理:eijaWhi,WhjF&#39;F&#39;F&#39;F其中,a是一个RRR的映射,WR是一个权值矩阵(被所有hi所共享)。</p>
	                    <div class="textFrom">——网页 -《GAT模型的实际应用案例分析》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>接着使用 Softmax 函数对进行归一化处理得到,</em><em class='similar'>计算过程如下:</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>{fsem))(4-5)其中勾e?n表示语义分支预测的动作得分,/sem表示初始语义特征向量。模型将视觉分支、空间分支和语义分支分别预测的动作得分进行融合,得到该人-物对总体的动作得分,<em class='similar'>最后使用Softmax函数对结果进行归一化处理。</em><em class='similar'>其计算过程如式</em>(4-6)所示Sa=Sv;?S:?Ss;m(4-6其中Sa表示人-物对总体的动作得分。完成人-物对的人体动作预测之后,模型对人-物对的交互得分进行预测,该得分是综合视觉、空间语义三个方面的特征得到的,</p>
	                    <div class="textFrom">——网页 -《基于图卷积和语义关系的人》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>(,)(,)(,)tanh()Tdot j ij iTjibilinear j ij iTCQMLP j i jif C Q C QSfC Q C WQf C Q VW C W Q (19)(2)<em class='similar'>使用Softmax函数对权重进行归一化处理,</em><em class='similar'>得到?</em>j1,,?ji,,?jn:1exp()softmax()exp()jijijinjiiSSS (20)(3)将归一化后的权重和相应的问题Q中的单词Qi进行加权求和,得到序列C?</p>
	                    <div class="textFrom">——软件学报 顾迎捷；桂小林；李德福；沈毅；廖东-《基于神经网络的机器阅读理解综述》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_18" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向对话文本的关系抽取研究" target="_blank">面向对话文本的关系抽取研究</a></span>
                      <p>周孟佳 -
                        《武汉大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(31字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>式中,<em class='similar'>和分别表示槽位节点和意图节点的集合;</em><em class='similar'>表示可训练的权重矩阵。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>푒퐿푈￿￿￿⁞1⁞|푁￿⁞￿|푊￿⁞(￿)ℎ￿⁞(￿)+⁞￿∈￿￿⁞￿￿∈￿⁞푊￿⁞(￿)ℎ￿⁞(￿)￿(5.3)⁞其中,푅表示异构图中边的关系集合,即5.2.2小节提到的八种边的类型。<em class='similar'>푁￿⁞￿表示⁞与节点 hv 相邻的节点集合,</em><em class='similar'>푊￿⁞(￿)⁞表示可训练的权重矩阵,</em>l 为关系图卷积网络的层数,⁞其取值见5.3小节实验设置。푅푒퐿푈表示激活函数。⁞5.3实验设置⁞本章模型采用的数据集、预处理方式及评价指标同3.4小节,</p>
	                    <div class="textFrom">——武汉大学硕士论文 周孟佳-《面向对话文本的关系抽取研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_19" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=旋转机械早期故障诊断关键技术研究" target="_blank">旋转机械早期故障诊断关键技术研究</a></span>
                      <p>杨静 -
                        《西安理工大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">4%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://www.xjishu.com/zhuanli/55/202011413754.html" target="_blank">信息服务提供方法、装置、电子设备和存储介质与流程</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3.3%(40字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于扩张卷积的注意力机制视频描述模型" target="_blank">基于扩张卷积的注意力机制视频描述模型</a></span>
                      <p>王金金;曾上游;李文惠;张介滨 -
                        《电子测量技术
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>式中,</em><em class='similar'>表示 Sigmoid 函数;</em><em class='similar'>和表示可训练的权重矩阵和偏置向量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>[0057]其中it,ft,ot,ct分别代表t时刻输入门,遗忘门,输出门和细胞状态的输出,xt表示t时刻输入模型的向量,ht表示t时刻区块中隐藏层中的向量,<em class='similar'>σ表示sigmoid激活函数,</em><em class='similar'>w和b分别表示不同门内待训练的权重矩阵和偏置向量。</em>三个具有筛选功能的门结构,其主要功能如下:1)输入门:用当前的信息以及上一个隐藏层传过来的信息作为输入,用来决定流向当前区块的信息,</p>
	                    <div class="textFrom">——网页 -《信息服务提供方法、装置、电子设备和存储介质与流程》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>Wxgxt+Wagat-1+bg)(6)⁞ct =ft☉ct-1+it☉gt (7)⁞at =ot☉Ø(ct)(8)⁞其中,it、ft、ot 分别表示输入门、遗忘门和输出门,⁞Wxj、<em class='similar'>bj 均是可训练的权重矩阵和偏置向量,</em><em class='similar'>σ表示sigmoid函数,</em>Ø表示tanh函数,☉是哈达玛积运算,即向量的点乘。⁞2.5 AMSGrad优化器⁞ Adam⁞是在深度学习中用来替代随机梯度下降的优化⁞算法,结合了⁞AdaGrad⁞和⁞RMSProp⁞</p>
	                    <div class="textFrom">——电子测量技术 王金金；曾上游；李文惠；张介滨-《基于扩张卷积的注意力机制视频描述模型》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>其中1⁞i⁞x 表示第 i 个样本,n样本尺寸,是样本容⁞量。定义编码映射函数为 ef ,则隐层特征 id 可由下式(4.3)计算出:⁞i e i e i ef Sd x W x b (4.3)<em class='similar'>⁞其中S 代表 sigmoid 函数,</em><em class='similar'> eW 和 eb 分别表示编码层的权重矩阵和偏置向量。</em>⁞⁞⁞⁞⁞⁞⁞⁞⁞解码⁞⁞编码⁞ix⁞⁞⁞2⁞ix⁞⁞𝑥2⁞3⁞ix ⁞⁞⁞⁞11⁞ix ⁞⁞输入 ix ⁞特征 id 重构ˆ⁞ix ˆ⁞ix⁞⁞⁞2ˆ⁞ix⁞⁞⁞3ˆ⁞ix ⁞⁞1ˆ⁞ix ⁞⁞⁞M⁞id⁞⁞⁞2⁞id⁞⁞⁞1⁞id ⁞⁞⁞1⁞⁞⁞西安理工大学博士学位论文⁞</p>
	                    <div class="textFrom">——西安理工大学博士论文 杨静-《旋转机械早期故障诊断关键技术研究》-2020 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_20" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=总619期第9期" target="_blank">总619期第9期</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">7%(109字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://www.doc88.com/p%2D3147368960566.html" target="_blank">一种基于卷积神经网络的肝脏CT图像病灶检测问题研究</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">4.8%(74字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于Cascade R-CNN的钢轨表面伤损检测算法研究" target="_blank">基于Cascade R-CNN的钢轨表面伤损检测算法研究</a></span>
                      <p>李健 -
                        《华东交通大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">4.5%(70字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=社会媒体中产品评论的可信度预测方法与应用" target="_blank">社会媒体中产品评论的可信度预测方法与应用</a></span>
                      <p>黄龙超 -
                        《哈尔滨工业大学硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">3.8%(59字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=探讨生物信息学筛选的miR216/124靶向CADM2对小鼠再灌注脑损伤细胞凋亡的作用" target="_blank">探讨生物信息学筛选的miR216/124靶向CADM2对小鼠再灌注脑损伤细胞凋亡的作用</a></span>
                      <p>胡玲 -
                        《武汉科技大学博士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(49字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>式中,<em class='similar'>TP(</em><em class='similar'>True Positive)</em><em class='similar'>和 TN</em><em class='similar'>(True Negative)</em><em class='similar'>分别表示预测正样本和负样本正确的个数;</em><em class='similar'>FP(</em><em class='similar'>False Positive)</em><em class='similar'>和 FN</em><em class='similar'>(False Negative)</em><em class='similar'>分别表示预测正样本和负样本错误的个数。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>IoU 阈值的样本边框;预测标签的正负:<em class='similar'>分别表示预测结果的正确与错误;</em><em class='similar'>TP(</em><em class='similar'>True Positive)</em><em class='similar'>,TN(</em><em class='similar'>True Negative)</em>:针对预测正确的情况而言,<em class='similar'>分别表示将正、</em><em class='similar'>负样本预测正确的个数;</em><em class='similar'>FN(</em><em class='similar'>False Negative)</em><em class='similar'>,FP(</em><em class='similar'>False Positive)</em>:针对预测错误的情况而言,<em class='similar'>分别表示将正、</em><em class='similar'>负样本预测错误的个数;</em>P(Positive),N(Negativ):分别表示正、负样本总数;P’,N’:分别表示预测为正、负样本总数。精确率定义:<em class='similar'>FP </em></p>
	                    <div class="textFrom">——网页 -《一种基于卷积神经网络的肝脏CT图像病灶检测问题研究》- （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>在计算准确率和召回率时将用到表2-2中的混淆矩阵。⁞表2-2混淆矩阵⁞混淆矩阵⁞预测结果⁞正样本负样本⁞真实标签⁞正样本 TP<em class='similar'>(True Positive)</em><em class='similar'> FN(</em><em class='similar'>False Negative)</em>负样本 FP<em class='similar'>(False Positive)</em><em class='similar'> TN(</em><em class='similar'>True Negative)</em>⁞其中,TP表示预测边框被正确划分为正样本的数量,<em class='similar'>FP表示预测边框被错误划分为正样本的数量,</em><em class='similar'>FN表示预测边框被错误划分为负样本的数量,</em><em class='similar'>TN表示预测边框被正确划分为负样本的数量。</em>⁞准确率用来衡量预测为正样本且预测正确</p>
	                    <div class="textFrom">——华东交通大学硕士论文 李健-《基于Cascade R-CNN的钢轨表面伤损检测算法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>计算公式为:Sen=TPTP+FN′×100%(14)Spec=TNTN+FP′×100%(15)ACC=TP+TN(TP+FP+TN+FN)′×100%(16)其中,真阳性TP<em class='similar'>(true positive)</em><em class='similar'>表示正样本预测正确的个数;</em><em class='similar'>FN(</em><em class='similar'>false negative)</em><em class='similar'>表示被错分为负样本的正样本个数;</em><em class='similar'>FP(</em><em class='similar'>false positive)</em>定义为被分错到正样本的负样本个数;<em class='similar'>TN(</em><em class='similar'>true negative)</em>为被正确预测的负样本的个数。敏感度、特异性和准确率结果如表1所示。表1 CCM在不同延迟下的性能比较特征CCM(1)CCM(2)CCM(3)CCM(4)CCM(5)敏感度/%80.3785.2686.9888.2288.</p>
	                    <div class="textFrom">——网页 -《总619期第9期》- （是否引证：否）</div>
						<p class="paragraph"><strong>4.</strong>对预测结果进行评估,如灵敏度,特异度等。其中,真阳性<em class='similar'>(True Positive,</em><em class='similar'>TP)</em><em class='similar'>表示被正确预测的正样本的个数,</em>假阴性<em class='similar'>(False Negative,</em><em class='similar'>FN)</em>表示正样本中没有被正确预测出的正样本的个数,真阴性<em class='similar'>(True Negative,</em><em class='similar'>TN)</em>表示被正确识别出的负样本的个数,假阳性<em class='similar'>(False Positive,</em><em class='similar'>FP)</em>表示负样本中没有被正确识别出的负样本的个数。ROC 曲线是以 TP 为纵坐标、FP 为横坐标所绘制的一条曲线,</p>
	                    <div class="textFrom">——武汉科技大学博士论文 胡玲-《探讨生物信息学筛选的miR216/124靶向CADM2对小鼠再灌注脑损伤细胞凋亡的作用》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>5.</strong>如表2-1所示。⁞表2-1二分类问题的混淆矩阵⁞被判定为正样本被判定为负样本⁞正样本 True Positive <em class='similar'>(TP)</em><em class='similar'> False Negative </em>(FN)⁞负样本 False Positive <em class='similar'>(FP)</em><em class='similar'> True Negative </em>(TN)⁞其中 TP 表示正样本被模型预测为正样本的个数;<em class='similar'>FN 表示正样本被预测为⁞负样本的个数;</em>FP 表示负样本被判定为正样本的数量;TN 表示负样本被预测⁞为负样本的数量。针对分类任务时,查全率 R 和查准率 P 以及 F 值的定义如公⁞</p>
	                    <div class="textFrom">——哈尔滨工业大学硕士论文 黄龙超-《社会媒体中产品评论的可信度预测方法与应用》-2017 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_21" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=数据科学入门" target="_blank">数据科学入门</a></span>
                      <p>（美）JOELGRUS著;高蓉，韩波译 -
                        《
                        》- 2016 
                      </p>
                    </div></td>
                  <td><span class="green">2%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=知识图谱分布式表示学习方法及应用研究" target="_blank">知识图谱分布式表示学习方法及应用研究</a></span>
                      <p>张金斗 -
                        《中国科学技术大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>论文选择在验证集上表现最佳的模型作为训练好的模型,</em>然后在测试集上对其进行测试以进行公平比较。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>有持续的好表现。)⁞在这种情况下,你应该把数据划分为三部分:一个用来建立模型的训练集,<em class='similar'>一个为在训练好的模型上进行选择的验证集,</em>一个用来判断最终的模型的测试集。正确性⁞当我不做数据科学的时候,我会涉猎医疗研究。在业余时间,我做了一个低成本、无害的新生儿测试——准确性高达98%——测试新生儿是否会得白血病。我的律师确信我是有专利权的。</p>
	                    <div class="textFrom">—— （美）JOELGRUS著；高蓉，韩波译-《数据科学入门》-2016 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>"↑"/"↓"分别表示该项指标越高/低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14], DSST[16], SAMF_CA[17], MOSSE_CA[17]和 CT[23]⁞等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>⁞表1部分跟踪算法的速度对比结果帧/s ⁞视频 LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA 本文整体20.2017.5027.80210.105.1264.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>8710.7910.7970.7250.9810.9380.9370.861⁞(+3.4%)(+2.9%)(+5.8%)(+7.7%)(+0.4%)(+0.9%)(+6.7%)(+7.4%)⁞注:黑体数字表示最优结果,<em class='similar'>下划线数字表示次优结果,</em>括分里面的数值表示⁞FKAPR与次优的结果相比提升的百分比⁞表5.3和图5.3分别给出了所有方法在四个数据集上CTR预测的AUC、F1值⁞和Top-K推荐的Recall@K指标值。</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 张金斗-《知识图谱分布式表示学习方法及应用研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
            	<h3 style="line-height:40px;">全文对照</h3>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 4 章 基于标签感知图交互的自然语言理解</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_23" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://mp.weixin.qq.com/s?src=11&timestamp=1621424192&ver=3078&signature=jcHyNOoq23FSbGF5zLFBCq6YbjMzq8hRMLq7wQ7dipYyzxuLNNBT0ZJ4PC3V9GR7v6vwXjg2Rq4Vh0JdhmlZA7-KMinGIXXpVkwefQS2j56eRoBROAihxqWFaCSSlDRt&new=1" target="_blank">喜讯 | 香港中文大学（深圳）数据科学学院宋彦教授团队十二篇论文分别被各大学术会议及期刊收录</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">3%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>从而提升模型性能。</em><em class='similar'>在MixATIS和MixSnips数据集上的实验结果论证了本章所提方法的有效性。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>并把其引入模型。相比于普通的GCN模型(即不区分词与上下文信息的相对位置关系,并用对所有上下文信息同等对待的模型),D-GCN可以有效地区分不同上下文信息的贡献,并据此更好地利用这些信息,<em class='similar'>进而提升模型性能。</em><em class='similar'>本研究在三个标准数据集上的实验结果表明了该方法的有效性;</em>该方法超越了其它图结构模型达到了目前最好的成绩。图10:基于方向建模的图神经网络模型架构图Paper10MeetChangeswithConstancy:</p>
	                    <div class="textFrom">——网页 -《喜讯 | 香港中文大学（深圳）数据科学学院宋彦教授团队十二篇论文分别被各大学术会议及期刊收录》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第5章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_24" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="https://blog.csdn.net/bluewhalerobot/article/details/81587039" target="_blank">TX2刷机和使用常见问题 - bluewhalerobot的博客 - CSDN博客</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于端到端学习的自动驾驶决策算法研究" target="_blank">基于端到端学习的自动驾驶决策算法研究</a></span>
                      <p>王奎霖 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.6%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向危险化学品的知识图谱构建研究" target="_blank">面向危险化学品的知识图谱构建研究</a></span>
                      <p>程钊 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用残差稠密网络的无监督单幅图像深度估计" target="_blank">应用残差稠密网络的无监督单幅图像深度估计</a></span>
                      <p> -
                        《小型微型计算机系统
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>接着将论文第3章、<em class='similar'>第4章提出的模型分别在驾驶数据集上进行训练,</em>最后集成、移植网络模型至 TX2并围绕搭建全套硬件平台,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>与对应化学品有&quot;避免接触条件&quot;关系⁞图5-4甲醛溶液的相关特性⁞5.1.2应用模型进行风险信息补全⁞为构建更加全面的含有风险信息的危险化学品知识图谱,<em class='similar'>利用第4章提出的模型,</em><em class='similar'>在第3章建立的数据集上进行训练,</em>并提取出语料中的风险信息语句补全知识图谱。⁞值得注意的是,对于识别出的实体,需要对其进行关系拼接,以&quot;甲醛溶液&quot;的风险信息&quot;其蒸汽与空气可形成爆炸性混合物,遇明火、</p>
	                    <div class="textFrom">——常州大学硕士论文 程钊-《面向危险化学品的知识图谱构建研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现神经网络的无监督训练.通过将预测图像输入网络模型得到对应的视差图,再根据视差图与深度图之间的几何关系,得到图像的深度图.<em class='similar'>本文所提出的网络模型在 KITTI 驾驶数据集上进行训练,</em>在测试集上得到了优于现存的大部分方法的误差值和准确率,以及更为清晰的物体边缘轮廓信息,从而验证了本文所提出方法在单幅图像深度估计中的有效性和优异性.⁞关键词:深度估计;</p>
	                    <div class="textFrom">——小型微型计算机系统 -《应用残差稠密网络的无监督单幅图像深度估计》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过注意力机制(AttentionMechanism)对卷积网络提取的高维特征信息进行加权,通过两组长短期记忆神经网络和全连接网络分别对车辆下一时刻速度和方向盘转角进行预测。<em class='similar'>本文中所提出的模型使用 Comma.</em><em class='similar'>ai驾驶数据集进行训练,</em>训练结果表明基于深度神经网络的端到端驾驶决策模型对车速、方向盘转角可以取得较好的预测效果,并能够有效降低模型预测的平均绝对误差(Mean Absolute Error,MAE)。⁞(2)</p>
	                    <div class="textFrom">——吉林大学硕士论文 王奎霖-《基于端到端学习的自动驾驶决策算法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong>CUDA(Compute Unified Device Architecture)<em class='similar'>架构升级为 Pascal,</em><em class='similar'>每瓦性能提高一倍。</em>同时,由于支持 PyTorch、TensorFlow 和 Caffe 等深度学习框架,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>性能强大(1 TFLOPS),外形小巧,节能高效(7.5W),非常适合机器人、无人机、智能摄像机和便携医疗设备等智能终端设备。 Jatson TX2与 TX1相比,内存和 eMMC 提高了一倍,<em class='similar'>CUDA 架构升级为 Pascal,</em><em class='similar'>每瓦性能提高一倍,</em>支持 Jetson TX1模块的所有功能,支持更大、更深、更复杂的深度神经网络。2. TX2刷机系统要求要给TX2刷机,需要一台装有Ubuntu 16.04系统的主机1.</p>
	                    <div class="textFrom">——网页 -《TX2刷机和使用常见问题 - bluewhalerobot的博客 - CSDN博客》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_25" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于小波变换的汽车语音特征指令逼近与端点检测方法" target="_blank">基于小波变换的汽车语音特征指令逼近与端点检测方法</a></span>
                      <p>石海燕 -
                        《浙江工业大学硕士论文
                        》- 2009 
                      </p>
                    </div></td>
                  <td><span class="green">2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="https://www.docin.com/p%2D1784871189.html" target="_blank">2013年上海大众帕萨特NMS电器培训教材</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">2%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>字信号处理器(Digital Signal Processor,DSP)用于降低车辆噪音,<em class='similar'>如发动机噪音、</em>传输噪音、<em class='similar'>轮胎噪音和空气动力噪音等。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>高速行驶中汽车轮胎在地面上的滚动、车身与空气的作用,是产生汽车⁞噪音的根本原因。汽车噪音一般可以分为发动机噪音、排气系统噪音、风扇噪音、<em class='similar'>⁞传动系统噪音、</em><em class='similar'>轮胎噪音、</em><em class='similar'>制动噪音、</em><em class='similar'>气动噪音等。</em><em class='similar'>发动机噪音,</em>除了发动机机⁞体发出的机械声外,还包括进气系统噪音和排气系统噪音。高速气体经空气滤清⁞器、进气管、气门进入气缸,在流动过程中,会产生一种很强的气动噪音。</p>
	                    <div class="textFrom">——浙江工业大学硕士论文 石海燕-《基于小波变换的汽车语音特征指令逼近与端点检测方法》-2009 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>功率放大器信息娱乐系统售后服务培训中心页数:70功率放大器另一种执行DSP功能的方法是根据车速连续地改变频率特性(加重低于200Hz的频率),即:部分降低汽车行驶时产生的物理噪音<em class='similar'>(空气动力噪音、</em><em class='similar'>来自轮胎的噪音、</em><em class='similar'>发动机噪音)</em>.信息娱乐系统售后服务培训中心页数:71双低音喇叭箱(2Ω装在后座衣帽架下面信息娱乐系统售后服务培训中心页数:72功率放大器安装位置在驾驶员座椅下方诊断地址:47信息娱乐</p>
	                    <div class="textFrom">——网页 -《2013年上海大众帕萨特NMS电器培训教材》- （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_26" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=非独立同分布词语相关度计算方法研究" target="_blank">非独立同分布词语相关度计算方法研究</a></span>
                      <p>张玉腾 -
                        《齐鲁工业大学硕士论文
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>"↓"表示该项指标越低越好,<em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>即低层次的显式共现⁞耦合,低层次的显式超链接耦合和高层次的隐式概念耦合。由于 CCE 具有全面捕⁞捉概念耦合的强大功能,因此在所有对比方法中获得了最佳结果。⁞(1)<em class='similar'>加粗表示最优结果,</em><em class='similar'>下划线表示次优结果,</em>*表示 CCE 比次优结果提升的百分比。齐鲁工业大学硕士学位论文⁞21⁞表3.2所有数据集上的平均斯皮尔曼秩相关性系数。。⁞Families  Methods </p>
	                    <div class="textFrom">——齐鲁工业大学硕士论文 张玉腾-《非独立同分布词语相关度计算方法研究》-2019 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_27" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的在线字临摹分析系统设计" target="_blank">基于深度学习的在线字临摹分析系统设计</a></span>
                      <p>张承强;张永爱;顾兴权 -
                        《信息技术与网络安全
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(37字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于神经网络分类器链算法的肺癌证型分类研究" target="_blank">基于神经网络分类器链算法的肺癌证型分类研究</a></span>
                      <p>刘梦玲 -
                        《江西中医药大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.3%(34字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=视听觉信息特征提取与融合方法研究" target="_blank">视听觉信息特征提取与融合方法研究</a></span>
                      <p>江彦桥 -
                        《电子科技大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.9%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=知识图谱分布式表示学习方法及应用研究" target="_blank">知识图谱分布式表示学习方法及应用研究</a></span>
                      <p>张金斗 -
                        《中国科学技术大学博士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.8%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自适应特征融合的多尺度相关滤波目标跟踪算法" target="_blank">自适应特征融合的多尺度相关滤波目标跟踪算法</a></span>
                      <p>陈智;柳培忠;骆炎民;汪鸿翔;杜永兆 -
                        《计算机辅助设计与图形学学报
                        》- 2018 
                      </p>
                    </div></td>
                  <td><span class="green">1.6%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong><em class='similar'>和分别设置为0.9和0.1。</em><em class='similar'>训练过程中各个模型在验证集上的损失</em><em class='similar'>(Loss)</em><em class='similar'>曲线如图5-4所示</em>(从第10次迭代开始)。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>随训练轮次的变化。⁞在验证集上,使用基于多层 CNN 的视觉特征提取模型并分类测试,准确率 acc⁞性达到88.8%,但模型的收敛较慢。<em class='similar'>⁞⁞图4-4多层 CNN 模型训练过程的准确率 acc 和损失 loss 曲线⁞在验证集上,</em>对多层 CNN 提取的视觉特征采用 T-SNE 方法进行二维可视化⁞后,效果如图4-5。</p>
	                    <div class="textFrom">——电子科技大学硕士论文 江彦桥-《视听觉信息特征提取与融合方法研究》-2021 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>设置batch_size、学习率和网络输入的大小,指定模型保存路径,损失函数选择sigmoid交叉熵,优化器选择Adam,并设置其他相关参数[11]。设置完所有的参数后,对模型进行训练,<em class='similar'>如图3和图4所示,</em><em class='similar'>分别是模型训练过程中的精度曲线和损失值</em><em class='similar'>(loss)</em>曲线。图3迭代次数与准确率的关系图图4迭代次数与损失值的关系图3字相似度算法本文的字相似度算法比现有的传统字相似度算法简单,且符合直观感受,</p>
	                    <div class="textFrom">——信息技术与网络安全 张承强；张永爱；顾兴权-《基于深度学习的在线字临摹分析系统设计》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>表中&quot;↑&quot;/&quot;↓&quot;分别表示该项指标越高/低越好,</em><em class='similar'>粗体数字表示最优结果,</em><em class='similar'>下划线数字表示次优结果。</em>从表中可以看出,第4章所提模型在 CQUPT-DS 上除了 Latency 值外,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>11], Staple[13], DeepSRDCF[14],DSST[16], SAMF_CA[17], MOSSE_CA[17]和CT[23]等经典算法,得到的实验结果如表1和图1所示,<em class='similar'>表中加粗的数字表示最优结果,</em><em class='similar'>下划线表示次优结果.</em>表1部分跟踪算法的速度对比结果帧/s视频LCT SAMF DSST KCF SRDCF CSK Staple SAMF_CA本文整体20.2017.5027.80210.105.1264.3038.</p>
	                    <div class="textFrom">——计算机辅助设计与图形学学报 陈智；柳培忠；骆炎民；汪鸿翔；杜永兆-《自适应特征融合的多尺度相关滤波目标跟踪算法》-2018 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>四种不同基分类器下的二元相关分类模型下验证特征集合的性能,性能比较结果见表3-8,字母F 表示特征全集,字母 S 表示最优特征子集,<em class='similar'>加粗的数字表示各个指标中的最优结果,</em><em class='similar'>&quot;↓&quot;表示评价指标的值越小越好,</em><em class='similar'>&quot;↑&quot;表示评价指标的值越大越好。</em></p>
	                    <div class="textFrom">——江西中医药大学硕士论文 刘梦玲-《基于神经网络分类器链算法的肺癌证型分类研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>8710.7910.7970.7250.9810.9380.9370.861⁞(+3.4%)(+2.9%)(+5.8%)(+7.7%)(+0.4%)(+0.9%)(+6.7%)(+7.4%)⁞注:黑体数字表示最优结果,<em class='similar'>下划线数字表示次优结果,</em>括分里面的数值表示⁞FKAPR与次优的结果相比提升的百分比⁞表5.3和图5.3分别给出了所有方法在四个数据集上CTR预测的AUC、F1值⁞和Top-K推荐的Recall@K指标值。</p>
	                    <div class="textFrom">——中国科学技术大学博士论文 张金斗-《知识图谱分布式表示学习方法及应用研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第 5 章 面向车载嵌入式设备的本地智能语音对话系统</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_28" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于端到端学习的自动驾驶决策算法研究" target="_blank">基于端到端学习的自动驾驶决策算法研究</a></span>
                      <p>王奎霖 -
                        《吉林大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2.7%(29字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向危险化学品的知识图谱构建研究" target="_blank">面向危险化学品的知识图谱构建研究</a></span>
                      <p>程钊 -
                        《常州大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">2.5%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=应用残差稠密网络的无监督单幅图像深度估计" target="_blank">应用残差稠密网络的无监督单幅图像深度估计</a></span>
                      <p> -
                        《小型微型计算机系统
                        》- 2019 
                      </p>
                    </div></td>
                  <td><span class="green">2.4%(26字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>接着将论文第3章、<em class='similar'>第4章提出的模型分别在驾驶数据集上进行训练,</em>最后集成、移植网络模型至 TX2并围绕搭建全套硬件平台。</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>与对应化学品有&quot;避免接触条件&quot;关系⁞图5-4甲醛溶液的相关特性⁞5.1.2应用模型进行风险信息补全⁞为构建更加全面的含有风险信息的危险化学品知识图谱,<em class='similar'>利用第4章提出的模型,</em><em class='similar'>在第3章建立的数据集上进行训练,</em>并提取出语料中的风险信息语句补全知识图谱。⁞值得注意的是,对于识别出的实体,需要对其进行关系拼接,以&quot;甲醛溶液&quot;的风险信息&quot;其蒸汽与空气可形成爆炸性混合物,遇明火、</p>
	                    <div class="textFrom">——常州大学硕士论文 程钊-《面向危险化学品的知识图谱构建研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>实现神经网络的无监督训练.通过将预测图像输入网络模型得到对应的视差图,再根据视差图与深度图之间的几何关系,得到图像的深度图.<em class='similar'>本文所提出的网络模型在 KITTI 驾驶数据集上进行训练,</em>在测试集上得到了优于现存的大部分方法的误差值和准确率,以及更为清晰的物体边缘轮廓信息,从而验证了本文所提出方法在单幅图像深度估计中的有效性和优异性.⁞关键词:深度估计;</p>
	                    <div class="textFrom">——小型微型计算机系统 -《应用残差稠密网络的无监督单幅图像深度估计》-2019 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>通过注意力机制(AttentionMechanism)对卷积网络提取的高维特征信息进行加权,通过两组长短期记忆神经网络和全连接网络分别对车辆下一时刻速度和方向盘转角进行预测。<em class='similar'>本文中所提出的模型使用 Comma.</em><em class='similar'>ai驾驶数据集进行训练,</em>训练结果表明基于深度神经网络的端到端驾驶决策模型对车速、方向盘转角可以取得较好的预测效果,并能够有效降低模型预测的平均绝对误差(Mean Absolute Error,MAE)。⁞(2)</p>
	                    <div class="textFrom">——吉林大学硕士论文 王奎霖-《基于端到端学习的自动驾驶决策算法研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
                <h2 style="width:100%;text-align:center;margin-top:15px;">第6章 总结与展望</h2>
              	<h3 style="line-height:40px;">相似文献列表</h3>
                 <table width="960" id="reportTable_29" class="reportTable">
                <tr>
                  <th width="*">文献名</th>
                  <th width="122">复制比</th>
                  <th width="64">是否引证</th>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">1.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度编解码器的语音识别" target="_blank">基于深度编解码器的语音识别</a></span>
                      <p>程家伟 -
                        《个人自建库
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">8.4%(213字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">2.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于改进滑模控制器的永磁直驱风力发电系统MPPT方法研究" target="_blank">基于改进滑模控制器的永磁直驱风力发电系统MPPT方法研究</a></span>
                      <p>袁声远 -
                        《江南大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">4.1%(104字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">3.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于云平台的智能家居系统设计" target="_blank">基于云平台的智能家居系统设计</a></span>
                      <p>俞凌丽 -
                        《浙江工业大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">3.2%(81字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">4.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于胶囊神经网络的知识图谱补全模型研究" target="_blank">基于胶囊神经网络的知识图谱补全模型研究</a></span>
                      <p>李俊 -
                        《重庆邮电大学硕士论文
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">2%(50字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:">
                  <td>
                    <div class="literName"><strong class="tableNum">5.</strong> <span><a href="http://xueshu.baidu.com/s?wd=北斗三号RTK定位教学实践" target="_blank">北斗三号RTK定位教学实践</a></span>
                      <p>姚佶[1];李厚朴[1];余德荧[1] -
                        《教育教学论坛
                        》- 2021 
                      </p>
                    </div></td>
                  <td><span class="green">1.5%(39字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">6.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于注采联作的滑套阀系列结构设计" target="_blank">基于注采联作的滑套阀系列结构设计</a></span>
                      <p>赵伟 -
                        《西安科技大学硕士论文
                        》- 2013 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(36字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">7.</strong> <span><a href="http://xueshu.baidu.com/s?wd=铂—钌电催化剂中助剂钌的形态及稳定性研究" target="_blank">铂—钌电催化剂中助剂钌的形态及稳定性研究</a></span>
                      <p>马俊红 -
                        《大连理工大学博士论文
                        》- 2010 
                      </p>
                    </div></td>
                  <td><span class="green">1.4%(35字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">8.</strong> <span><a href="http://xueshu.baidu.com/s?wd=回归测试中测试用例优先级排序技术研究" target="_blank">回归测试中测试用例优先级排序技术研究</a></span>
                      <p>王一婷 -
                        《西南大学硕士论文
                        》- 2016 
                      </p>
                    </div></td>
                  <td><span class="green">1.3%(33字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">9.</strong> <span><a href="http://xueshu.baidu.com/s?wd=自学考试上网磨枪" target="_blank">自学考试上网磨枪</a></span>
                      <p>郑丽 -
                        《网络与信息
                        》- 2003 
                      </p>
                    </div></td>
                  <td><span class="green">1.1%(28字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">10.</strong> <span><a href="http://xueshu.baidu.com/s?wd=便携式相位光栅轮廓全貌测量技术研究" target="_blank">便携式相位光栅轮廓全貌测量技术研究</a></span>
                      <p>陈新禹 -
                        《大连海事大学博士论文
                        》- 2014 
                      </p>
                    </div></td>
                  <td><span class="green">1.1%(27字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">11.</strong> <span><a href="http://xueshu.baidu.com/s?wd=根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响" target="_blank">根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响</a></span>
                      <p>黄毅 -
                        《中国农业科学院硕士论文
                        》- 2017 
                      </p>
                    </div></td>
                  <td><span class="green">1%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">12.</strong> <span><a href="http://xueshu.baidu.com/s?wd=面向海量数据检索的矢量空间索引" target="_blank">面向海量数据检索的矢量空间索引</a></span>
                      <p>韦祎 -
                        《中国矿业大学硕士论文
                        》- 2022 
                      </p>
                    </div></td>
                  <td><span class="green">1%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">13.</strong> <span><a href="http://xueshu.baidu.com/s?wd=合成甲醇催化剂的研究及合成反应优化操作" target="_blank">合成甲醇催化剂的研究及合成反应优化操作</a></span>
                      <p>赵忠尧 -
                        《大庆石油大学硕士论文
                        》- 2006 
                      </p>
                    </div></td>
                  <td><span class="green">1%(25字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">14.</strong> <span><a href="https://baike.baidu.com/history/%E9%87%8D%E5%BA%86%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2/1408432/36639684" target="_blank">重庆邮电大学自动化学院_百度百科</a></span>
                      <p> -
                        《网页
                        》-  
                      </p>
                    </div></td>
                  <td><span class="green">1%(24字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
                <tr class="trLike" style="display:none">
                  <td>
                    <div class="literName"><strong class="tableNum">15.</strong> <span><a href="http://xueshu.baidu.com/s?wd=基于深度学习的素描人脸合成技术研究" target="_blank">基于深度学习的素描人脸合成技术研究</a></span>
                      <p>李凯旋 -
                        《北京信息科技大学硕士论文
                        》- 2020 
                      </p>
                    </div></td>
                  <td><span class="green">0.9%(23字)</span></td>
                  <td class="bdrNo">否</td>
                </tr>
            	</table>
            	<div id="simMore_29" class="simMore"><a href="javascript:$ShowMore(29);">查看更多相似文献<span class="icons inlineBlock simDown"></span></a></div>
            	<h3 style="line-height:40px;">全文对照</h3>
                <table width="960" class="reportTable">
                <tr>
                  <th width="50%">原文内容</th>
                  <th width="50%">相似内容来源</th>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>1.</strong>和自然语言理解技术的研究现状,<em class='similar'>然后分析现有方法存在的问题,</em><em class='similar'>提出了相应的改进方案,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>本章介绍了测量系统中多视数据拼接的方法,在相较各方法的基础上,本文选用基⁞于粘性标记点的多视拼接技术。详细介绍了基于粘性标记点数据拼接方法涉及到的关键⁞技术,<em class='similar'>同时分析了现有方法存在的缺点,</em><em class='similar'>并提出了相应的改进方案。</em>本章主要研究内容⁞如下:⁞(1)详细介绍了现有特征点立体视觉匹配算法,分析了现有方法的优缺点,同时针⁞对本文研发系统的测量特点,提出了一种同时适用于动态和静态测量过程的特征点立体</p>
	                    <div class="textFrom">——大连海事大学博士论文 陈新禹-《便携式相位光栅轮廓全貌测量技术研究》-2014 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>脸合成方法改善了合成素描人脸图像的纹理效果,提高了素描人脸图像的真实性,但是合成结果仍然存在面部细节丢失、清晰度低等问题。本文通过对现有的素描人脸合成方法进行分析,<em class='similar'>针对现有方法中所存在的问题,</em><em class='similar'>提出一些改进方案,</em>主要贡献概括⁞如下:⁞1、提出一种基于双层生成对抗网络的素描人脸合成方法。传统的素描人脸合成方法存在复杂的图像分块、拼接步骤,容易导致合成结果出现栅格现象,缺乏纹理真实性,</p>
	                    <div class="textFrom">——北京信息科技大学硕士论文 李凯旋-《基于深度学习的素描人脸合成技术研究》-2020 （是否引证：否）</div>
						<p class="paragraph"><strong>3.</strong>QRB+树相比常用空间索引有显著的性能提升,⁞可为大规模矢量/空间数据的高效组织提供技术支撑。本文主要工作如下:⁞(1)梳理了空间索引中树状索引、网格索引、混合索引和精细查询策略的发展现状,<em class='similar'>并分析了现有方法存在的问题;</em>依据对研究现状的分析,制定本文的研究内容和研究路线,并说明了本文的组织结构,为后续研究奠定基础。⁞(2)针对 QR 树索引在空间查询中存在的 R 树冗余检索问题,</p>
	                    <div class="textFrom">——中国矿业大学硕士论文 韦祎-《面向海量数据检索的矢量空间索引》-2022 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>2.</strong><em class='similar'>针对基于深度编—解码器的模型参数量庞大的问题,</em><em class='similar'>提出了一种基于残差分组线性变换的解码器结构。</em><em class='similar'>该结构关键模块为&quot;钻石&quot;型缩放单元,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>通过研究全局注意力机制和局部注意力机制在不同拓扑结构下的识别效果,提出了效果最优的&quot;局部—全局&quot;级联结构的融合注意力机制;提出了基于该融合注意力机制的编码器网络结构。⁞3.<em class='similar'>基于分层分组线性变换的解码器⁞针对编码器-解码器模型参数量庞大、</em><em class='similar'>计算复杂度高的问题,</em><em class='similar'>提出了基于分层分组线性变换的扩张缩放单元,</em>该单元内部采用稀疏连接,同组神经元共享同一权值矩阵,在实现较低计算量的同时大幅降低网络参数量;</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>3.</strong>的应用场景中可能会导致体验性降低。<em class='similar'>下一步可以考虑使用分块技术对编码器中的注意力机制进行优化,</em><em class='similar'>以建立当前输入时刻语音帧和历史信息之间的联系,</em><em class='similar'>从而实现流式的自动语音识别。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>改进Transformer模型目前还不支持流式的语音识别,仅能在完整语音信号输入完毕后开始输出识别结果,不能做到在输入部分语音信号的同时进行识别,在对实时性要求较高的某些场景中会一定程度降低语音识别的体验。<em class='similar'>下一步,</em><em class='similar'>可以考虑使用分块技术对编码器网络中的注意力机制进行改进,</em><em class='similar'>使得其能够建立当前输入时刻语音帧和历史信息之间的联系,</em><em class='similar'>进而实现对流式语音识别的支持。</em>⁞2.对非自回归语音识别的支持。目前采用的是自回归式解码,在进行识别时,解码器将逐个输出识别字符。</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>4.</strong>可能会影响模型推理效率。<em class='similar'>下一步可以考虑采用非自回归的训练方式对模型进行训练,</em><em class='similar'>以进一步提高模型的预测速度。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>解码器将逐个输出识别字符。随着文本长度逐渐增加,采用自回归式解码方式的计算复杂度会以平方的速度增加,在某些极端情况下,会严重影响语音识别系统的识别效率。<em class='similar'>下一步的研究内容是考虑采用非自回归的训练方式对模型进行训练,</em><em class='similar'>进一步提高模型的识别速度。</em>⁞ ⁞参考文献⁞[1]叶硕,褚钰,王祎,李田港.语音识别中声学模型研究综述[J].计算机技术与发展,2020,30(03):181-186.⁞[2]俞栋,邓力,俞凯,等.解析深度学习:语音识别实践[M]</p>
	                    <div class="textFrom">——个人自建库 程家伟-《基于深度编解码器的语音识别》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>5.</strong><em class='similar'>重庆邮电大学自动化学院/工业互联网学院控制科学与工程专业2020级硕士研究生。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>军工程大学电气工程学院副教授(通信作者),硕士生导师,主要从事卫星导航⁞研究;余德荧(1998—),男,广东潮州人,<em class='similar'>海军工程大学电气工程学院2020级控制科学与工程专业硕士研究生,</em>研究方⁞向为卫星导航。⁞[中图分类号]G642.0[文献标识码]A [文章编号]1674-9324(2021)33-0045-04[收稿日期]</p>
	                    <div class="textFrom">——教育教学论坛 姚佶[1]；李厚朴[1]；余德荧[1]-《北斗三号RTK定位教学实践》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>6.</strong><em class='similar'>2016.09~2020.06重庆邮电大学自动化学院/工业互联网学院,</em><em class='similar'>本科,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>重点培养自动化仪器仪表、机电一体化系统、汽车电子技术等方向的专业人才。⁞就业去向:⁞毕业生主要在自动化与仪器仪表、汽车与装备、IT制造等行业从事产品设计、生产制造、维修维护与生产管理等工作。<em class='similar'>⁞重庆邮电大学自动化学院⁞物联网工程专业⁞</em><em class='similar'>(本科,</em>标准学制四年,授予工学学士学位,招收理工类)⁞培养目标:⁞以自动化、计算机、通信和光电等为支撑,培养适应&quot;感知中国&quot;和物联网产业发展需要,突出专业知识结构中的&quot;感知与融合(传感网与移</p>
	                    <div class="textFrom">——网页 -《重庆邮电大学自动化学院_百度百科》- （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>7.</strong>Mandarin Speech Recognition<em class='similar'>[C]//202234th Chinese Control and Decision Conference </em><em class='similar'>(CCDC).</em><em class='similar'> IEEE,2022:</em>2816-2820.</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong> Maximum power tracking control method of permanent magnet direct drive wind power system based on improved sliding mode controller<em class='similar'>[C].⁞Control and Decision Conference </em><em class='similar'>(CCDC),202234th Chinese.</em><em class='similar'> IEEE,2022.</em>(CCDC 会⁞议,EI 检索,IEEE 收录,已录用)⁞[2] Shengyuan Yuan, Yanxia Shen.</p>
	                    <div class="textFrom">——江南大学硕士论文 袁声远-《基于改进滑模控制器的永磁直驱风力发电系统MPPT方法研究》-2022 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>⁞[44] Zhang T, Li Q, Ma F. Remote control system of smart appliances based on wireless sensor ⁞network<em class='similar'>[C]//201325th Chinese Control and Decision Conference </em><em class='similar'>(CCDC),</em> Guiyang, China: IEEE,2013:3705-3710.⁞[45]史治国,陈积明,楼东武,等. DIY 智慧小屋—带你玩转物联网[EB/OL](2019-12-13)[2020-4-30]. https www.</p>
	                    <div class="textFrom">——浙江工业大学硕士论文 俞凌丽-《基于云平台的智能家居系统设计》-2020 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>8.</strong><em class='similar'>[1]</em><em class='similar'>语音智能对话系统</em><em class='similar'>(MCM20180404)</em>,教育部-中国移动科研基金研发项目,</p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>我非常感谢他们对我的信任与认可。⁞重庆邮电大学硕士学位论文攻读硕士学位期间从事的科研工作及取得的成果⁞攻读硕士学位期间从事的科研工作及取得的成果⁞科研项目:<em class='similar'>⁞[1]</em><em class='similar'>语音智能对话系统,</em><em class='similar'>MCM20180404,</em>教育部,2019.01-2020.12⁞发表论文:<em class='similar'>⁞[1]</em> Jun Li, Jie Hou, Chunyu Zhou.</p>
	                    <div class="textFrom">——重庆邮电大学硕士论文 李俊-《基于胶囊神经网络的知识图谱补全模型研究》-2021 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>9.</strong><em class='similar'>在即将完成学位论文之际,</em><em class='similar'>我想要借此机会表达我最深切的感激之情。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>转眼间又将是一个毕业季,在与西南大学相处的7年里,我过得⁞特别充实,感触也是颇多。期间,老师和同学们的引导、帮助和激励,都让我受⁞益匪浅,<em class='similar'>所以在学位论文即将完成之际,</em><em class='similar'>我想借此机会向他们表达我心中的感激⁞之情。</em>⁞首先,我想感谢的是我的导师丁晓明副教授。丁老师不仅是我学习上的导师,⁞他也是我生活中的朋友,他幽默风趣、待人宽厚,在研究生的这三年里,</p>
	                    <div class="textFrom">——西南大学硕士论文 王一婷-《回归测试中测试用例优先级排序技术研究》-2016 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>的治学态度深深的影响了我,对我今后的学习和工作有着指引作用,使我终生受益。感⁞谢于老师三年来对我生活和学习上的关心和指导,感谢于老师给我提供了一个锻炼的平⁞台,在我研究生即将毕业之际,<em class='similar'>借此机会向于老师和魏老师表达我最深切的感激之情,</em>⁞同时也感谢各位指导和关心我的老师。⁞感谢实验室的各位同学,对我学习上的帮助和生活上的关心,感谢郭威、何旻烨等⁞</p>
	                    <div class="textFrom">——西安科技大学硕士论文 赵伟-《基于注采联作的滑套阀系列结构设计》-2013 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>10.</strong><em class='similar'>您的教诲将对我今后的学术生涯产生深远的影响,</em><em class='similar'>我将终生铭记。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>易近人的人格魅力给我留下了深刻的印象。徐老师扎实的学术功底、严谨⁞的治学态度和对科学前沿敏锐的洞察力使我受益匪浅。<em class='similar'>在清华大学三年多来徐老⁞师给我的培养和教诲将会对我未来的学术生涯和人生之路产生深远的影响。</em>在论⁞文完成之际,在此向两位恩师表示由衷的感谢。⁞衷心感谢清华大学化学系的孙科强老师在工作和生活中曾给予的帮助和关⁞怀,</p>
	                    <div class="textFrom">——大连理工大学博士论文 马俊红-《铂—钌电催化剂中助剂钌的形态及稳定性研究》-2010 （是否引证：否）</div>
						<p class="paragraph"><strong>2.</strong>、创造性的思维方式和献身事业的敬业精神令我终身难忘,这不仅使我在研究生⁞学习和论文工作中受益匪浅,<em class='similar'>同时也将对我未来的学术生涯和人生之路产生深远影响,</em><em class='similar'>我⁞将终生铭记。</em>在此向导师表示深深的敬意和衷心的感谢。⁞在完成学业期间,得到单位领导和同事的大力支持和帮助,在此向他们表示深深的谢⁞意。同时,对在论文中给予帮助的博2005李金环同学,</p>
	                    <div class="textFrom">——大庆石油大学硕士论文 赵忠尧-《合成甲醇催化剂的研究及合成反应优化操作》-2006 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>11.</strong><em class='similar'>你们的意见和建议帮助我不断完善研究内容和论文质量。</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>提出许多的宝贵意见,让我受益匪浅,并且在生活中给予我最大的帮助,向李老师致以衷心的感⁞谢!⁞也感谢在开题报告、中期检查和毕业答辩中为我的论文提出宝贵意见和建议的老师等。<em class='similar'>您们⁞的意见和建议使我不断完善课题研究,</em><em class='similar'>提高了论文质量。</em>⁞感谢在我研究工作中提供帮助的课题组贺超兴老师、闫妍老师、邢师傅;感谢已经毕业的慕⁞英师姐、马俊师姐、郭允娜师姐、于二敏师姐、常蕊师姐、张小翠师姐、</p>
	                    <div class="textFrom">——中国农业科学院硕士论文 黄毅-《根施萘乙酸钠和聚天门冬氨酸对黄瓜生长、生理特性和产量的影响》-2017 （是否引证：否）</div>
                  </td>
                </tr>
                <tr>
                  <td valign="top"><p class="paragraph"><strong>12.</strong><em class='similar'>给予我接受高等教育的机会和平台。</em><em class='similar'>在我接受教育的过程中,</em></p></td>
                  <td>
						<p class="paragraph"><strong>1.</strong>公立大学或成人高校的学生希过自考拿到双学历;还有的考生希自考的基础上进一步发展(考研或);甚至有些考生就是从丰富知识度出发而参加自考的这种多到底意味着什么?那就是自考不仅仅是简简单单的拿文凭。<em class='similar'>自考给了我们一个接受高等教育的机会,</em><em class='similar'>在接受教育的过程中,</em>我们学到的不仅仅是教科书上的东西。每一次考试就等于一次挑战,成功的喜悦与失败的悲伤夹杂在一起,使我们在不知不觉中成熟起来,这种感觉恐怕只有自考生才能体会到。</p>
	                    <div class="textFrom">——网络与信息 郑丽-《自学考试上网磨枪》-2003 （是否引证：否）</div>
                  </td>
                </tr>
            	</table>
          	</div>
          	<div class="report_explain2">
              <div class="repExp_left">说明：</div>
              <div class="repExp_rig">
                <p>1.指标是由系统根据《学术论文不端行为的界定标准》自动生成的</p>
                <p>2.本报告单仅对您所选择比对资源范围内检测结果负责</p>
              </div>
            </div>
            <div class="clear"></div>
            <div class="report_footer">
			    <div class="assist_tool">
			      <h2>写作辅助工具</h2>
			      <ul>
			        <li>
			          <div class="asst icons asst1"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommendtitle/">选题分析</a>
			            <p>帮您选择合适的论文题目</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst2"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommenddata/">资料搜集</a>
			            <p>提供最全最好的参考文章</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst3"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/recommendoutline/">提纲推荐</a>
			            <p>辅助生成文章大纲</p>
			          </div>
			        </li>
			        <li>
			          <div class="asst icons asst4"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/writing/">在线写作</a>
			            <p>规范写作，提供灵感</p>
			          </div>
			        </li>
			        <li class="bgNo">
			          <div class="asst icons asst5"></div>
			          <div class="asstRig"> <a target="_blank" href="https://www.bigan.net/reference/">参考文献</a>
			            <p>规范参考文献，查漏补缺</p>
			          </div>
			        </li>
			      </ul>
			    </div>
			    <div class="repFot_bot">
			      <div class="reportCopy inlineBlock">版权所有：笔杆 www.bigan.net</div>
			      <div class="shareTo inlineBlock"><span>分享到：</span> <a href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https%3A%2F%2Fwww.bigan.net&title=%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%EF%BC%8C%E6%8B%BF%E8%B5%B7%E7%AC%94%E6%9D%86%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E5%BF%AB%E4%B9%90%E7%9A%84%E5%AD%A6%E6%9C%AF%E5%B8%9D%E3%80%82&summary=%E7%AC%94%E6%9D%86%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%86%99%E4%BD%9C%E5%B9%B3%E5%8F%B0%E3%80%82%E7%AC%94%E6%9D%86%E4%B8%BA%E4%BD%A0%E6%89%AB%E6%B8%85%E5%86%99%E4%BD%9C%E6%80%9D%E8%B7%AF%E7%9A%84%E9%98%B4%E9%9C%BE%EF%BC%8C%E6%89%BE%E5%88%B0%E6%89%8D%E6%80%9D%E6%B3%89%E6%B6%8C%EF%BC%8C%E7%81%B5%E6%84%9F%E8%BF%B8%E5%8F%91%E7%9A%84%E5%BF%AB%E6%84%9F%EF%BC%8C%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BF%A1%E6%89%8B%E6%8B%88%E6%9D%A5%E3%80%82www.bigan.net&pics=https%3A%2F%2Fwww.bigan.net%2Flogo_80_80.png" target="_blank" title="QQ空间" class="inlineBlock sitem1 icons pngfix"></a> <a href="#" title="微信" class="inlineBlock sitem2 icons pngfix"></a> <a href="http://service.weibo.com/share/share.php?url=https%3A%2F%2Fwww.bigan.net&title=%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%EF%BC%8C%E6%8B%BF%E8%B5%B7%E7%AC%94%E6%9D%86%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E5%BF%AB%E4%B9%90%E7%9A%84%E5%AD%A6%E6%9C%AF%E5%B8%9D%E3%80%82%EF%BC%88%E7%AC%94%E6%9D%86%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%86%99%E4%BD%9C%E5%B9%B3%E5%8F%B0%E3%80%82%E7%AC%94%E6%9D%86%E4%B8%BA%E4%BD%A0%E6%89%AB%E6%B8%85%E5%86%99%E4%BD%9C%E6%80%9D%E8%B7%AF%E7%9A%84%E9%98%B4%E9%9C%BE%EF%BC%8C%E6%89%BE%E5%88%B0%E6%89%8D%E6%80%9D%E6%B3%89%E6%B6%8C%EF%BC%8C%E7%81%B5%E6%84%9F%E8%BF%B8%E5%8F%91%E7%9A%84%E5%BF%AB%E6%84%9F%EF%BC%8C%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BF%A1%E6%89%8B%E6%8B%88%E6%9D%A5%E3%80%82%40%E7%AC%94%E6%9D%86%E7%BD%91%EF%BC%89" target="_blank" title="新浪微博" class="inlineBlock sitem3 icons pngfix"></a> </div>
			    </div>
			  </div>
      	   </div>
  	   </div>
  </div>
</div>
</div>
</body>
</html>